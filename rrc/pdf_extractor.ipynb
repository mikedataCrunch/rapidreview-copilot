{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "from text_extraction import PDFExtractor\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'extracted_text': ['Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Diagnostic and\\nhttps://doi.org/10.1186/s41512-019-0060-y\\nPrognostic Research\\nREVIEW Open Access\\nMethodological standards for the\\ndevelopment and evaluation of clinical\\nprediction rules: a review of the literature\\nLaura E. Cowley* , Daniel M. Farewell, Sabine Maguire and Alison M. Kemp\\nAbstract\\nClinicalpredictionrules(CPRs)thatpredicttheabsoluteriskofaclinicalconditionorfutureoutcomeforindividualpatients\\nare abundant in the medical literature; however, systematic reviews have demonstrated shortcomings in the\\nmethodologicalqualityandreportingofpredictionstudies.TomaximisethepotentialandclinicalusefulnessofCPRs,they\\nmust be rigorously developed and validated, and their impact on clinical practice and patient outcomes must be\\nevaluated. This review aims to present a comprehensive overview of the stages involved in the development, validation\\nand evaluation of CPRs, and to describe in detail the methodological standards required at each stage, illustrated with\\nexampleswhereappropriate.Importantfeaturesofthestudydesign,statisticalanalysis,modellingstrategy,datacollection,\\nperformanceassessment,CPRpresentationandreportingarediscussed,inadditiontoother,oftenoverlookedaspectssuch\\nas the acceptability, cost-effectiveness and longer-term implementation of CPRs, and their comparison with clinical\\njudgement. Although the development and evaluation of a robust, clinically useful CPR is anything but straightforward,\\nadherencetotheplethoraofmethodologicalstandards,recommendationsandframeworksateachstagewillassistinthe\\ndevelopment of a rigorous CPR that has the potential to contribute usefully to clinical practice and decision-making and\\nhaveapositiveimpactonpatientcare.\\nKeywords:Clinicalpredictionrule,Predictionmodel,Riskmodel,Modeldevelopment,Modelvalidation,Impactstudies,\\nModelreporting,Implementation,Diagnosis,Prognosis,Studydesign\\nBackground whilstothersaimto‘ruleout’aconditionbyidentifyingpa-\\nThe aim of a clinical prediction rule (CPR) is to estimate tientswhoareveryunlikelytohaveacondition,thusredu-\\nthe probability of a clinical condition or a future outcome cing unnecessary testing without compromising patient\\nbyconsideringasmallnumberofhighlyvalidindicators[1, care [2, 4]. CPRs that aim to predict the probability of a\\n2]. CPRs include three or more predictors, from patients’ condition being present are termed diagnostic or screening\\nclinical findings, history or investigation results [3]. Their rules; those that aim to predict the probability of a future\\npurpose is to assist clinicians in making decisions under outcomearetermedprognosticrules;andthosethataimto\\nconditionsofuncertaintyandenhancediagnostic,prognos- predicttheprobabilitythataspecifictreatmentorinterven-\\ntic or therapeutic accuracy and decision-making, with the tionwillbeeffectivearetermedprescriptiverules[2].\\nultimate aim of improving the quality of patient care [1, 2, To maximise the predictive accuracy and clinical util-\\n4]. The predicted probabilities from a CPR allow clinicians ity of CPRs, it is vital that they are rigorously developed,\\ntostratifypatientsintoriskgroupsandhelpthemtodecide validated and evaluated. However, numerous systematic\\nwhether further assessment or treatment is necessary [5]. reviews have demonstrated shortcomings in the meth-\\nSome CPRs can help to ‘rule in’a condition by identifying odological quality and reporting of prediction studies,\\npatients who are very likely to have a condition and who which restricts the CPR’s usefulness in practice [6–15].\\nthus require additional diagnostic testing or treatment, Methodological standards for the development of CPRs\\nwere originally outlined by Wasson and colleagues [16].\\n*Correspondence:CowleyLE@cardiff.ac.uk With the increase in popularity of CPRs inspired by the\\nDivisionofPopulationMedicine,SchoolofMedicine,NeuaddMeirionnydd, evidence-based medicine movement, these standards\\nHeathPark,CardiffUniversity,WalesCF144YS,UK\\n©TheAuthor(s).2019OpenAccessThisarticleisdistributedunderthetermsoftheCreativeCommonsAttribution4.0\\nInternationalLicense(http://creativecommons.org/licenses/by/4.0/),whichpermitsunrestricteduse,distribution,and\\nreproductioninanymedium,providedyougiveappropriatecredittotheoriginalauthor(s)andthesource,providealinkto\\ntheCreativeCommonslicense,andindicateifchangesweremade.TheCreativeCommonsPublicDomainDedicationwaiver\\n(http://creativecommons.org/publicdomain/zero/1.0/)appliestothedatamadeavailableinthisarticle,unlessotherwisestated.', 'Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page2of23\\nhave since been modified and updated by a number of Stages in the development of clinical prediction\\nauthors over the years [3, 4, 17–19]. Experts have pro- rules\\nvided thorough and accessible overviews of the princi- It is widely acknowledged in the literature that there are\\nples and methods involved in conducting diagnostic and three main stages in the development of CPRs (Fig. 1);\\nprognostic research [20–32] and devised frameworks to derivation;externalvalidation;andimpactanalysistode-\\nenhance the conduct and interpretation of prediction termine their impact on patient care [4, 20, 22–25, 32,\\nstudies [33–35]. They have also provided guidance and 33]. Stiell and Wells [17] identified a further three im-\\nrecommendations for researchers to consider when de- portant stages, namely identifying the need for a CPR,\\nveloping and evaluating CPRs, without aiming to dictate determining the cost-effectiveness of a CPR and\\nhow analyses should be conducted. These recognise that long-term dissemination and implementation of a CPR.\\nthere is no clear consensus on many aspects of model Therefore all six stages are summarised in Table 1 and\\ndevelopment, that the field is continually evolving and discussedindetail below.\\nthat methodological standards will therefore require up- Detailedmethodologicalandpracticalrecommendations\\ndating accordingly [36]. Guidelines for the reporting of pertaining to the three main stages of development have\\nclinical prediction research have also been developed, been published, as each requires a different methodo-\\nnamely the Transparent Reporting of a multivariable logicalapproach[3,4,16–36].Thesethreestagesalsocor-\\nprediction model for Individual Prognosis or Diagnosis respond to increasing hierarchies of evidence, as outlined\\n(TRIPOD) guidelines[36]. in Table 2 [4, 32, 33]. A CPR that has been derived, but\\nThis review aims to outline the stages and methodo- notexternallyvalidated,correspondstothelowestlevelof\\nlogical standards involved in the development and evalu- evidenceandisnotrecommendedforuseinclinicalprac-\\nationofCPRs,illustratedwithexampleswhereappropriate. tice, except arguably in rare instances when a CPR is de-\\nveloped for use in only one setting. It has been suggested\\nTerminologyusedinthisreview thata CPR thathasbeensuccessfullyexternally validated\\nIn the literature, the term ‘clinical prediction rule’ is used in a setting, or population, similar to the one from which\\ninterchangeably with the terms clinical prediction tool itwasderived(‘narrow’validation),canbeusedcautiously\\n[37], clinical decision rule [17], clinical decision tool [38], insimilarfuturepatients[32].Similarly,itisproposedthat\\nclinical prediction algorithm [39], prognostic score [40], a CPR should be consistently successfully externally vali-\\nprognostic model [21], risk prediction model [23], risk dated in multiple settings or populations (‘broad’ valid-\\nmodel [30], risk score [41], scoring tool [42], scoring sys- ation),beforeclinicianscanuseitspredictionsconfidently\\ntem [43] or risk index [44]. Reilly and Evans [32] distin- in future patients [32]. Finally, it is recommended that an\\nguish between assistive prediction rules that simply impact analysis is conducted and that the CPR demon-\\nprovide clinicians with diagnostic or prognostic predicted stratesimprovementstopatientcare,beforeitcanbeused\\nprobabilities without recommending a specific clinical as a decision rule for the management and treatment of\\ncourseofaction,anddirectivedecisionrulesthatexplicitly patients [32]. Ideally, the impact of a CPR should also be\\nsuggest additional diagnostic tests or treatment in line tested in multiple settings. Impact analysis studies corres-\\nwith the obtained score. Decision rules intend to directly pondtothehighestlevelofevidence[32].\\ninfluenceclinicianbehaviour,whilepredictionrulesintend\\nto help clinicians predict risk without providing recom- Stage1:identifyingtheneedforaclinicalpredictionrule\\nmendations, with the assumption that accurate predic- Before developing a CPR, researchers need to ensure\\ntions will lead to better decisions [32]. Some researchers that there is a clinical need for the rule. CPRs are most\\nalso distinguish between prediction models that provide valuable when decision-making is challenging, when\\npredicted probabilities along the continuum between cer- there is evidence that clinicians are failing to accurately\\ntified impossibility (Pi=0) and absolute certainty (Pi=1) diagnose a condition, and when there are serious conse-\\n[45], and prediction rules that classify patients into risk quences associated with an incorrect diagnosis [2, 4].\\ngroups, by applying a clinically relevant cut-off that bal- CPRs are also valuable when there is a need to simplify\\nancesthelikelihoodof benefitwiththelikelihoodofharm or speed up the diagnostic or triage process, for example\\n[19, 46]. Such cut-offs are known as ‘decision thresholds’; inpatientspresentingtotheemergency departmentwith\\na threshold mustbe appliedifa prediction model aimsto chest pain and suspected acute cardiac ischaemia [49].\\ninfluence decision-making [19]. In this review, the term CPRs are most likely to be adopted into clinical practice,\\n‘clinical prediction rule’ is used to refer to diagnostic, and to demonstrate improvements in patient care and\\nprognosticorprescriptiverules/modelsderivedfrommul- reductions in health care costs, when they improve the\\ntivariablestatisticalanalyses, whichpredicttheprobability overall efficiency of clinical practice [17]. For example,\\nof a condition or outcome, with or without the use of a ankle injuries are frequently seen in the emergency de-\\nclinicalcut-offorrecommendationforfurtheraction. partment. Prior to the implementation of the Ottawa', 'Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page3of23\\nValidation\\nEvidence of reproducible\\naccuracy\\nNarrow Validation Impact Analysis\\nDerivation\\nApplication of rule in a similar Evidence that rule\\nIdentification of clinical setting and population as changes physician\\nfactors with in the derivation stage behaviour and improves\\npredictive power patient outcomes and/or\\nBroad Validation\\nreduces costs\\nApplication of rule in multiple\\nclinical settings with varying\\nprevalence and outcomes of\\ndisease\\nFig.1Thethreemainstagesinthedevelopmentandevaluationofclinicalpredictionrules.AdaptedfromMcGinn,2016[47]\\nAnkleRule,clinicians ordered ahighproportion of radio- protocol and registering the study prior to the derivation\\ngraphs that were negative for fracture, when the majority ofanewCPR,intheinterestsoftransparency[67,68].\\nof them believed that a fracture was highly unlikely [50].\\nTherulewasfound tolead toareductioninbothradiog- Studydesignforthederivationofaclinicalpredictionrule\\nraphy [51] and health care costs [52], and in one survey The first stage in the development of a CPR is the deriv-\\n70% of Canadian and UK emergency department clini- ation of the rule. This involves an examination of the\\nciansreportedfrequentuseoftherule[53]. ability of multiple potential variables from the clinical\\nBefore developing a CPR, researchers should consider findings, history or investigation results to predict the\\nwhether a new CPR is needed, as many are developed for target outcome of interest. Predicted probabilities are\\nthe same target population or to predict the same out- derived from the statistical analysis of patients with\\ncome [8, 10, 11, 54–57]. The characteristics, performance known outcomes, and the outcome of interest serves as\\nandlevelofevidenceofexistingCPRsshouldbesystemat- the reference standard by which the performance of the\\nically reviewed using validated search filters for locating CPRisassessed.TheperformanceofaCPRisdependent\\npredictionstudies,andtheCriticalAppraisalandDataEx- upon the quality of the underlying data, and the dataset\\ntraction for Systematic Reviews of prediction modelling used to derive the CPR should be representative of the\\nstudies (CHARMS) checklist [58, 59]. The recently pub- target populationitisintended for[17,30,69,70].\\nlished Prediction model Risk Of Bias ASsessment Tool Theoptimalstudydesignforthederivationofadiagnos-\\n(PROBAST)canbeusedtoassesstheriskof biasandap- ticCPRisacross-sectionalcohortstudy,whileforprognos-\\nplicability of CPRs [60]. Researchers can also assess the ticCPRs,thepreferreddesignisalongitudinalcohortstudy\\nperformanceofexistingCPRs ontheirowncollecteddata [30]. In general, case-control studies are inappropriate, as\\n[61].ExistingCPRswithpotentialshouldbeupdated,vali- they do not allow for the estimation of absolute outcome\\ndatedortestedinanimpactstudybeforeanewCPRisde- risk [21, 23, 71]; however, nested case-control or\\nveloped [54, 62, 63]. If a new CPR is derived, researchers case-cohortstudiescanbeused[71,72].Prospectivecohort\\nshould clearly justify why it is required, with reference to studiesarepreferredtoretrospectivecohort studies,toop-\\nexisting CPRs, to avoid research waste and duplication of timise measurement and documentation of predictive and\\nefforts [64]. Qualitative research with clinicians can be outcomevariables[21,23].ForprescriptiveCPRs,studyde-\\nusefulindeterminingwhetheraproposedCPRisclinically signsthatincludeacontrolgroup,suchasrandomisedcon-\\nrelevant,andtoassessthe credibilityoftheproposedpre- trolled trials (RCTs), are essential to ensure that treatment\\ndictorvariables[65,66]. effect modifiers and non-specific prognostic predictors are\\ndistinguishablefromoneanother[73,74].Thestudydesign\\nStage2:derivationofaclinicalpredictionruleaccording shouldbeadequatelydetailedandincludethestudysetting,\\ntomethodologicalstandards inclusion and exclusion criteria and patient demographics\\nOnce a need for a new CPR is established, and a re- and characteristics [17].To enhance generalisability,multi-\\nsearcherhasanappropriate clinical question,a CPRmust centrestudiesarerecommended[30].\\nbe derived according to strict methodological standards\\n[23].Therearevariouselementstoconsider,pertainingto Statisticalanalysis\\nthe study design, statistical techniques employed and the Commonly used statistical methods for the derivation of\\nassessment, presentation and reporting of the CPR. Re- CPRs include multivariable regression techniques, and\\nsearchers should consider writing and publishing a study recursive partitioning techniques, such as classification', 'Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page4of23\\nTable1Stagesinthedevelopmentandevaluationofclinical Table1Stagesinthedevelopmentandevaluationofclinical\\npredictionrules predictionrules(Continued)\\nStageofdevelopment Methodologicalstandards Stageofdevelopment Methodologicalstandards\\nStage1.Identifyingtheneedfora (cid:129)Considerconductingqualitativeresearch (cid:129)Considerdecisioncurveanalysisto\\nCPR withclinicianstodetermineclinical estimatetheclinicalutilityoftheCPR\\nrelevanceandcredibilityofCPR\\nPresentationofaCPR\\n(cid:129)Conductasystematicreviewofthe\\n(cid:129)Reporttheregressioncoefficientsofthe\\nliteraturetoidentifyandevaluateexisting\\nfinalmodel,includingtheinterceptor\\nCPRsdevelopedforthesamepurpose\\nbaselinehazard\\n(cid:129)Considerupdating,validatingortesting\\n(cid:129)ConsideraclinicalcalculatoriftheCPRis\\ntheimpactofexistingCPRs\\ncomplex\\nStage2.DerivationofaCPR StudydesignforthederivationofaCPR\\nReportingthederivationofaCPR\\naccordingtomethodological\\n(cid:129)Considerregisteringthestudyand\\nstandards (cid:129)AdheretotheTRIPODguidelines[36]\\npublishingaprotocol\\n(cid:129)Ensurethedatasetisrepresentativeofthe Stage3.Externalvalidationand Studydesignfortheexternalvalidationofa\\nrefinementofaCPR CPR\\npopulationforwhomtheCPRisintended\\n(cid:129)Conductaprospectivemulticentrecohort\\n(cid:129)Conductaprospectivemulticentrecohort\\nstudy\\nstudy\\n(cid:129)Aimforasamplesizewithaminimumof\\nStatisticalanalysis\\n100outcomeevents,preferably200\\n(cid:129)Conductmultivariableregressionanalysis\\n(cid:129)Considerusingaframeworkof\\n(logisticforbinaryoutcomes,Coxfor\\ngeneralisabilitytoenhancethe\\nlong-termprognosticoutcomes)\\n(cid:129)Identifythemodeltobeused,plus interpretationofthefindings[34]\\nrationaleifothermethodsused Typesofexternalvalidation\\nMissingdata (cid:129)Conducttemporal,geographicaland\\n(cid:129)Usemultipleimputation domainvalidationstudiestoensure\\nmaximumgeneralisability\\nSelectionofcandidatepredictorsfor\\n(cid:129)Ifmultiplevalidationshavebeen\\ninclusioninamultivariablemodel\\nperformed,conductameta-analysisto\\n(cid:129)Onlyincluderelevantpredictorsbasedon summarisetheoverallperformanceofthe\\nevidenceintheliterature/clinical CPR,usingapublishedframework[35]\\nexperience\\nRefinementofaCPR:modelupdatingor\\n(cid:129)Aimforasamplesizewithaminimumof adjustment\\nteneventsperpredictor,preferablymore\\n(cid:129)Considerupdating,adjustingor\\n(cid:129)Avoidselectionbasedonunivariable recalibratingtheCPRifpoorperformance\\nsignificancetesting isfoundinanexternalvalidationstudy\\n(cid:129)Avoidcategorisingcontinuouspredictors (cid:129)Considerfurtherexternalvalidationof\\nupdatedCPRs\\nSelectionofpredictorsduringmultivariable\\nmodelling ComparingtheperformanceofCPRs\\n(cid:129)Backwardeliminationofpredictorsis (cid:129)ComparetheCPRwithotherexistingCPRs\\npreferred forthesamecondition\\n(cid:129)Avoiddata-drivenselectionandincorpor- (cid:129)Ensurethestatisticalproceduresusedfor\\natesubject-matterknowledgeintothese- comparisonareappropriate;considera\\nlectionprocess decision-analyticapproach\\nDefinitionandassessmentofpredictorand ReportingtheexternalvalidationofaCPR\\noutcomevariables\\n(cid:129)AdheretotheTRIPODguidelines[36]\\n(cid:129)Definepredictorandoutcomevariables\\nclearly Stage4.ImpactofaCPRonclinical Studydesignforanimpactanalysis\\npractice\\n(cid:129)ConsiderwhethertheCPRisreadyfor\\n(cid:129)Considerinter-raterreliabilityofpredictor\\nimplementation\\nmeasurementandpotentialmeasurement\\nerror (cid:129)Conductaclusterrandomisedtrialwith\\ncentresasclusters,orabefore–afterstudy\\n(cid:129)Aimforblindassessmentofpredictorand\\noutcomevariables (cid:129)Performappropriatesamplesize\\ncalculations\\nInternalvalidation\\n(cid:129)Considerdecision-analyticmodellingasan\\n(cid:129)Usecross-validationorbootstrappingand\\nintermediatesteppriortoaformalimpact\\nadjustforoptimism\\nstudy\\n(cid:129)Ensuretorepeateachstepofmodel\\nMeasuresofimpactofaCPR\\ndevelopmentifusingbootstrapping\\n(cid:129)ReportthesafetyandefficacyoftheCPR\\nCPRperformancemeasures\\n(cid:129)ReporttheimpactoftheCPRonclinician\\n(cid:129)Assessandreportbothcalibrationand\\nbehaviourifassessed\\ndiscrimination', 'Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page5of23\\nTable1Stagesinthedevelopmentandevaluationofclinical enabling improved assessment of the association of the\\npredictionrules(Continued) predictorswiththetargetoutcome[76].\\nStageofdevelopment Methodologicalstandards In the case of multivariable regression, logistic regres-\\nAcceptabilityofaCPR sion models are required to predict binary events such as\\n(cid:129)EvaluatetheacceptabilityoftheCPRusing the presence or absence of a condition, while Cox regres-\\nthevalidatedOADRI[48],orusing sionmodelsaresuitablefortime-to-eventoutcomes.Such\\nqualitativeorvignettemethods\\nmodels estimate regression coefficients (e.g. log odds or\\nComparisonofaCPRwithunstructured\\nclinicaljudgement hazard ratios) of each predictor. Regression coefficients\\n(cid:129)Comparethesensitivityandspecificityof are mutually adjusted for the other predictors, and thus\\ntheCPRwithcliniciansownpredictions/ represent the contribution of each predictor to the prob-\\ndecisions\\nabilityoftheoutcome[23].Theprobabilityofanoutcome\\nThefourphasesofimpactanalysisforCPRs\\ncanbecomputedforapatientbycombiningtheobserved\\n(cid:129)Followtheframeworkfortheimpact\\nvalues of the predictors and their corresponding regres-\\nanalysisofCPRs[33]\\nsion coefficients with the model intercept, or estimated\\n(cid:129)Ensureextensivepreparatoryand\\nfeasibilityworkisconductedpriortoa baselinehazard [23].For logisticmodels, the modelinter-\\nformalimpactstudy cept and the weighted values applicable to each patient\\nReportingtheimpactanalysisofaCPR aresummed[16].Specificvaluesareassignedtoeachpre-\\n(cid:129)Therearecurrentlynopublishedreporting dictor, which are multiplied by the corresponding coeffi-\\nguidelinesforimpactstudiesofCPRs;this\\ncients.Inthe caseofa model withonly binary categorical\\nisanareaforfutureresearch\\npredictors, the predictors are multiplied by 0 or 1, de-\\nStage5.Cost-effectiveness (cid:129)Conductaformaleconomicevaluation,\\nwithsensitivityanalysestoexaminethe pending on whether they are absent (0) or present (1), as\\nuncertaintyofthemodelprojections perthemodelinTable3[77].Exponentiatingthefinalrisk\\nStage6.Long-termimplementation (cid:129)Deviseandevaluatetargeted score gives the odds, and the probability (absolute risk) is\\nanddissemination implementationstrategiestoensure\\nmaximumuptake calculatedbyuse ofthe inverselogistic link function[78].\\nIn this way, the probability of an outcome can be esti-\\nBarriersandfacilitatorstotheuseofCPRs\\nmated from any combination of the predictor values [36].\\n(cid:129)AssessbarrierstotheuseoftheCPRand\\ndevisestrategiestoovercomethese Theestimatedprobabilityforanindividualwithoutanyof\\nCPRclinicalpredictionrule,TRIPODTransparentReportingofamultivariable the predictors depends only on the intercept [23]. In this\\npredictionmodelforIndividualPrognosisorDiagnosis,OADRIOttawa case, the value for each of the predictors will be 0; when\\nAcceptabilityofDecisionRulesInstrument\\neach of these is multiplied by its relevant coefficient the\\nand regression tree analysis [75]. Methods based on uni- valueof0isretained[78].ForCoxregressionmodels,the\\nvariable analysis, where individual risk factors are simply baselinehazardisestimatedseparately[26,29].\\ntotalled and assigned arbitrary weightings, should be Recursive partitioning involves repeatedly splitting\\navoided, as they are much less accurate than methods patients into subpopulations including only individ-\\nbased on multivariable analysis [76]. This is because the uals with a specific outcome [79], and was the\\nfinal model may include predictors that are potentially method used to derive the Ottawa Ankle Rule [80].\\nrelated to each other and not independently associated CPRs can also be derived using discriminant function\\nwith the outcome ofinterest [76]. Multivariablemethods analysis [3], and machine learning algorithms based\\novercome the limitations of univariable analysis by onartificialneuralnetworks[1].Artificialintelligenceand\\nTable2Hierarchiesofevidenceinthedevelopmentandevaluationofclinicalpredictionrules\\nLevelofevidence Definitionsandstandardsofevaluation Implicationsforclinicians\\nLevel1:DerivationofCPR Identificationofpredictorsusingmultivariablemodel;blinded Needsvalidationandfurtherevaluationbeforeit\\nassessmentofoutcomes. isusedclinicallyinactualpatientcare.\\nLevel2:Narrowvalidationof ValidationofCPRwhentestedprospectivelyinonesetting; Needsvalidationinvariedsettings;mayuseCPR\\nCPR blindedassessmentofoutcomes. cautiouslyinpatientssimilartoderivationsample.\\nLevel3:Broadvalidationof ValidationofCPRinvariedsettingswithwidespectrumof Needsimpactanalysis;mayuseCPRpredictions\\nCPR patientsandclinicians. withconfidenceintheiraccuracy.\\nLevel4:Narrowimpactanalysis ProspectivedemonstrationinonesettingthatuseofCPR Mayusecautiouslytoinformdecisionsinsettings\\nofCPRusedfordecision- improvesclinicians’decisions(qualityorcost-effectivenessofpa- similartothatstudied.\\nmaking tientcare).\\nLevel5:Broadimpactanalysis ProspectivedemonstrationinvariedsettingsthatuseofCPR Mayuseinvariedsettingswithconfidencethat\\nofCPRusedfordecision- improvesclinicians’decisionsforwidespectrumofpatients. itsusewillbenefitpatientcarequalityor\\nmaking effectiveness.\\nAdaptedfromReillyandEvans2016[32].CPRclinicalpredictionrule', 'Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page6of23\\nTable3Clinicalpredictionruleforpostoperativenauseaand thesecondstage,standardstatisticaltechniquesareusedto\\nvomiting(PONV)[77] fitthemodelsthatareofinterestinthesubstantiveanalysis\\nRiskofPONV=1/(1+exp.−[2.28+1.27×femalesex+0.65×historyof to each of the imputed datasets. Estimated associations in\\nPONVormotionsickness+0.72×non-smoking+0.78×postoperative each of the imputed datasets will be different, due to the\\nopioiduse])\\nvariability introduced in stage one. In the third and final\\nstage,themultipleresultsareaveragedtogether,andstand-\\nmachine learning approaches are becoming increasingly ard errors are calculated using Rubin’s combination rules\\nmorecommon[81,82]. [91], which account for both within-and between-imput-\\nation variability and the number of imputed datasets, and\\nMissingdata therefore the uncertainty of the imputed values. Multiple\\nInclinical research, investigatorsalmost alwaysencounter imputation typically assumes that data are MAR [93]. Im-\\nmissingobservationsinvolvingpredictororoutcome vari- portantly,theMARassumptionisjustthat;anassumption,\\nables, even in carefully designed studies and in spite of rather than a property of the data [85]. The MCAR as-\\ntheir best efforts to maximise data quality [83]. There are sumptioncanbetested,butitisnotpossibletodifferentiate\\nthreetypesofmissingdatamechanisms:(1)missingcom- betweenMARandMNARfromtheobserveddata[26,85].\\npletelyatrandom(MCAR),(2)missingatrandom(MAR) MostmissingdataareexpectedtobeatleastpartlyMNAR\\nand (3) missing not at random (MNAR) [84]. When data [85, 94, 95]. Sensitivity analyses can help to determine the\\nareMCAR,thismeansthattherearenosystematicdiffer- effect of different assumptions about the missing data\\nences between the missing and observed values; for ex- mechanism; work in this area is ongoing [96–100]. Other\\nample, laboratory tests may be missing because of a statistically principled approaches to dealing with missing\\ndropped test tube or broken equipment. When data are datahavebeendeveloped,basedonrandomeffectsmodels\\nMAR, this means that the probability of a missing value [101, 102], Bayesian methods or maximum likelihood esti-\\ndepends on the observed values of other variables (but mation [103] or, where data are longitudinal, joint models\\nnot the unobserved values); for example, missing blood [104, 105]. Guidelines for reporting on the treatment of\\npressuremeasurementsmaybelowerthanobservedmea- missingdatainclinicalandepidemiologicalresearchstudies\\nsurements because younger people may be more likely to have been suggested by Sterne and colleagues [85]. Guid-\\nhavemissing measurements; inthis case, data can besaid ance also exists for handling missing data when deriving\\nto be MAR given age [85]. When data are MNAR, this and validating CPRs [83, 106, 107]. It has been demon-\\nmeans that the probability of a missing value depends on strated that the outcome should be used for imputation of\\nthe unobserved values or other unobserved predictors, missing predictor values [87]. It is also becoming increas-\\nconditionalontheobserveddata;forexample,peoplewith ingly apparent that a real-time strategy to impute missing\\nhighblood pressuremaybemorelikelytomissadoctor’s valuesisdesirablewhenapplyingaCPRinclinicalpractice\\nappointment due to headaches [85]. Missing values are [108–110].Thisisbecauseoneormorepredictor variables\\nrarelyMCAR,thatis,their‘missingness’isusuallydirectly may be unobserved for a particular patient, and thus the\\nor indirectly related to other subject or disease character- CPRs risk prediction cannot be estimated at the time of\\nistics, including the outcome [23, 25]. Missing data is fre- decision-making [108]. Real-time multiple imputation is\\nquentlyaddressedwithcase-wisedeletion,whichexcludes not typically straightforward, as it requires access to the\\nall participantswithmissing valuesfrom theanalysis[85]. derivationdatasetvia,forexample,awebsite[108,110].Of\\nHowever,whendataareplausiblyMAR,thisreducessam- note, although multiple imputation is a widely advocated\\nple size and statistical power and biases the results [85], approachforhandlingmissingdatainCPRstudies,arecent\\nleadingtoinaccurateestimatesofpredictor-outcomerela- study showed that implementing simpler imputation\\ntionships and the predictive performance of the model, methods resulted in similar predictive utility of a CPR to\\nsince the participants with complete data are not a ran- predict undiagnosed diabetes, when compared to multiple\\ndomsubsampleoftheoriginalsample[84,86,87]. imputation[111].\\nMultiple imputation is a popular approach to the prob-\\nlem of missing data[83, 85, 86, 88–91], asit quantifies the Selectionofcandidatepredictorsforinclusionina\\nuncertainty in the imputed values, by generating multiple multivariablemodel\\ndifferentplausibleimputeddatasets,andpoolingtheresults Candidate predictors are variables that are preselected\\nobtained from each of them [85, 91]. Multiple imputation for consideration in a multivariable model, and differ\\ninvolvesthreestages[85,89,91–93].First,asthenamesug- from those that are subsequently selected for inclusion\\ngests, multiple imputed datasets are created, based on the in the final model [23]. Candidate predictors should be\\ndistribution of the observed data. This first stage accounts selected without studying the predictor-outcome rela-\\nfor uncertainty in estimating the missing values by adding tionship in the data; in other words, predictors should\\nvariability into the values across the imputed datasets. In not be excluded as candidates solely because they are', 'Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page7of23\\nnot statistically significant in univariable analysis [25, 26, measure in the target setting, and selecting predictors\\n29,112–114].Predictor variablesdonothavetobecaus- that are relatively easy to measure and demonstrate high\\nally related to the outcome of interest [21, 115]. Effects inter-raterreliabilitybetweenclinicians[17,21].Interms\\nmodelled in studies examining causality are expressed of handling continuous predictors, researchers strongly\\nwith relative risk estimates such as odds ratios, while advise against converting continuous variables into cat-\\nrisk predictions are presented as probabilities on an ab- egorical variables, due to information loss and reduced\\nsolute scale between 0 and 1. Relative risk estimates are predictive accuracy [125–128]. Similarly, it should not\\nused in prediction research to calculate an absolute be assumed that continuous variables have a linear rela-\\nprobability of an outcome for a patient, as described tionship [127]. Instead, methods that permit more flexi-\\nabove, and can also be reported alongside risk predic- bility in the functional form of the association between\\ntions. All variables thought to be related to the target the predictors and outcome should be considered [127,\\noutcome can be selected as candidate predictors for in- 129]; two common approaches are fractional polyno-\\nclusion in a multivariable model; however, when the mials and restricted cubic splines [130, 131]. However, if\\nnumber of outcome events in the dataset is small, there sample size is limited, assuming a linear relationship be-\\nis a risk of overfitting the data when a large number of tween continuous variables may make a model less sen-\\npredictor variables are included. Thus the CPR will per- sitive toextreme observations.\\nform well onthe derivation data,butpoorlyonnewdata Penalised regression can be used to alleviate the prob-\\n[29, 69, 113, 116]. CPRs with a smaller number of pre- lem of overfitting [116]. This approach involves placing a\\ndictors are also easier to use in practice. To overcome constraintonthevaluesoftheestimatedregressioncoeffi-\\nthis problem, only the most clinically relevant candidate cients in order to shrink them towards zero [116]. This\\npredictors should be chosen from the larger pool of po- hastheeffectofyieldinglessextremeriskpredictions,and\\ntential predictor variables, without looking into the data thus may improve the accuracy of predictions when the\\n[5, 117]. In addition, sample size recommendations for CPR is applied in new patients [113, 132]. The two most\\nstudies deriving CPRs are often based on the concept of popular penalised methods are ridge regression [133] and\\nevents-per-variable (EVP), whereby the researcher con- lasso regression [134]. Unlike ridge regression, lasso re-\\ntrols the ratio of the number of outcome events to the gression also selects predictors as a consequence of its\\nnumber of coefficients estimated prior to any data- penalisation [116]. Ridge regression is usually preferred\\ndriven variable selection [31]. A rule-of-thumb of ten when a set of pre-specified predictors is available, while\\nEPV has been suggested [29, 31, 114, 118]. Simulation lasso regression may be preferred if a simpler model with\\nstudies examining the effect of this rule-of-thumb have fewerpredictorsisrequired[116,132].\\nyielded conflicting results [119–123]. One study found\\nthat when the EPV was less than ten, there were a range Selectionofpredictorsduringmultivariablemodelling\\nofcircumstances inwhich coverage andbiaswere within There is no consensus regarding how predictors should\\nacceptable levels [119]. Another found that 20 EPV or be selected while developing the final model [25]. Two\\nmore are required when low-prevalence predictors are common strategies include the ‘full model approach’and\\nincluded in a model [123], while another suggested that the ‘predictor selection approach’ [23]. An alternative\\nproblems may arise even when the EPV exceeds ten, as approach, known as ‘all possible subsets regression’, is\\nCPR performance may depend on many other factors less commonly used [28]. In the full model approach, all\\n[120]. Research in this area continues to evolve, as new previously identified candidate predictors are included,\\nguidance is clearly needed to support sample size con- and no further analysis is performed. Although this ap-\\nsiderations for the derivation of CPRs [121]. Recently, proach precludes selection bias and overfitting, it re-\\nvan Smeden and colleagues have suggested that sample quires in-depth knowledge about the most relevant\\nsize should be guided by three influential parameters: candidate predictors [26, 29]. In the predictor selection\\nthe number of predictors, total sample size and the approach, predictors are chosen either by ‘backward\\neventsfraction[122]. elimination’ or ‘forward selection’, based on pre-defined\\nRelevant predictors may be chosen based on a com- criteria. Backward elimination begins with all predictors\\nbination of clinical experience, expert opinion surveys, in the model and removes predictors, while forward se-\\nqualitative studies and formal systematic reviews and lection begins with an empty model, and predictors are\\nmeta-analyses of the literature [26, 33, 36, 65, 124]. added successively. All possible subsets regression can\\nStrategies for reducing the number of candidate predic- build models with combinations of predictors not gener-\\ntors include removing those that are highly correlated ated by the standard forward or backward procedures,\\nwith others, and combining similar predictors [29]. because every conceivable combination of predictors is\\nOther considerations include selecting predictors that assessed to find the best fitting model [135]. With all\\nwill be readily available for clinicians to observe or methods, a series of statistical tests are performed to', 'Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page8of23\\nassess the ‘goodness of fit’ between the different models. possible, particularly for conditions that require a con-\\nModelscanbe comparedbysettingapre-definedsignifi- sensus diagnosis based on all available patient informa-\\ncance level and using the log likelihood ratio test, or tion [143]. It is well known that misclassification in the\\nusing other model selection criterion such as the Akaike outcome variable may cause serious problems with pre-\\ninformationcriterion,ortheBayesian informationcriter- diction accuracy[144,145].\\nion [23, 25]. Backward elimination is favoured, as it al-\\nlows for the assessment of the effects of all predictors Internalvalidation\\nconcurrently, and can take into account all correlations Predictionmodelsareknowntoperformbetterinthedata-\\nbetween predictors [136, 137]. Multiple testing in all setfromwhichtheyarederived,incomparisontoapplying\\npossible subsets regression can easily lead to overfitting. them in new but plausibly related patients [146, 147].\\nHowever, with all methods, the choice of significance ‘Plausiblyrelatedpatients’maybedefinedasthosewhoare\\nlevel impacts upon the number of final predictors; the suspected of having the same condition or who are at risk\\nuse of smaller significance levels (e.g. p<0.05) produces of the same outcome examined in the derivation study\\nmodels with fewerpredictors at therisk ofexcluding po- [148].Thisenhancedperformanceoccurssimplybecausea\\ntentially important predictors, while the use of larger model is designed to optimally fit the available data [23].\\nsignificance levels (e.g. p<0.25) may result in the inclu- The performance of a model is most likely to be overesti-\\nsionoflessimportantpredictors[25]. matedwhenthederivationdatasetissmall,andusesalarge\\nPredictor selection by so-called automated, data- number of candidate predictors. Therefore, regardless of\\ndependent significance testing may generate overfitted, theapproachesusedinthederivationstageofdevelopment,\\n‘optimistic’ models, particularly when the derivation data- internal validation is required to examine and correct the\\nsetissmall[23,28,128,138,139].Thus,theAkaikeinfor- amountofoverfittingor ‘optimism’inthemodel, and thus\\nmation criterion is preferred, as it discourages overfitting thestabilityofthemodel[23].\\nby comparing models based on their fit to the data and Internal validation does not validate a model itself, but\\npenalising for the complexity of the model [25]. In theprocessusedtofitthemodel[26,29].Optimismises-\\naddition, it may be acceptable to retain a non-significant timatedusingtheoriginalderivationdatasetonly.Anum-\\npredictor in a model, if there is substantialevidence of its ber of methods are available for this purpose, including\\npredictiveabilityintheliterature[26]. split-sampling, cross-validation and bootstrapping.\\nSplit-sampling is the simplest method, and is performed\\nDefinitionandassessmentofpredictorandoutcome by dividing the derivation dataset into a ‘training’sample\\nvariables anda‘test’samplepriortomodelling.TheCPRisthende-\\nTo ensure that the CPR can be accurately applied in rived using the training sample, and its performance is\\npractice, predictor and outcome variables should be assessedusingthetestsample[20].However,thetestsam-\\nclearly defined, and outcome variables should be clinic- ple usually comprises one-third of the original derivation\\nally important [17]. Predictor variables must be reliable dataset and islikely toberelativelysmall, resulting in im-\\nto enable their assessment in clinical practice; reliability precise performance estimates [149, 150]. This approach\\nrefers to the reproducibility of the findings by the same also squanders the test data that could have been used in\\nclinician (intra-rater reliability) or between different cli- the derivation of the CPR [23, 150]. In cross-validation,\\nnicians (inter-rater reliability). Some researchers recom- theCPRisderivedusingthewholederivationdataset,and\\nmend that the reliability of predictor variables be the whole dataset is then reused to assess performance\\nexplicitly evaluated, and that only those demonstrating [20]. It is randomly split into equal samples: five or ten\\ngood agreement beyond that expected by chance alone samples are commonly used. In the case of five samples,\\nshould be considered for inclusion [17]. A recent study themodelisrefittedusing fourofthefivesamplesandits\\nfound that measurement error of predictor variables is performancetestedusingthefifth;thisprocessisrepeated\\npoorly reported, and that researchers seldom state expli- five times until each of the five samples has been used as\\ncitly when the predictors should be measured, and the thetestdata,andanaverageoftheestimatedperformance\\nCPR applied [140]. Another study demonstrated that is taken. To improve stability, the overall procedure can\\npredictor measurement heterogeneity across settings can be replicated several times, using different random sub-\\nhave a detrimental impact on the performance of a CPR samples[149].Thepreferredinternalvalidationmethodis\\nat external validation [141]. Ideally, the outcome variable bootstrapping, particularly when the derivation dataset is\\nshould be assessed independently of the predictor vari- small or a large number of candidate predictors are\\nables to avoid circular reasoning or ‘incorporation bias’, assessed [23, 29]. The idea is to mimic random sampling\\nwhen the results of the CPR or its predictor variables fromthetargetpopulationbyrepeatedlydrawingsamples\\nare used in the determination of the outcome [142]. of the same size with replacement from the derivation\\nHowever, it is acknowledged that this is not always dataset [151]. Sampling with replacement renders', 'Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page9of23\\nbootstrapsamplessimilar,butnotidentical,totheoriginal of interest. The predicted probabilities for patients with\\nderivationsample[23].Eachstepofmodeldevelopmentis the outcome should be higher than the predicted prob-\\nrepeated in each bootstrap sample (typically 500), most abilities for those who do not have the outcome [46].\\nlikely yielding different models with varying performance. Theeasiest way to assess discrimination is by calculation\\nEachbootstrapmodelisthenappliedtotheoriginalderiv- of the discrimination slope, which is simply the absolute\\nation sample, yielding a difference in model performance. difference in the average predicted probabilities for pa-\\nTheaverageofthesedifferencesindicatestheoptimismin tients with and without the outcome [26]. Discrimin-\\nthe performance metrics of the model that was initially ation can also be visualised with a simple box plot. The\\nderivedinthederivationdataset[23,26,29,151],anden- most widely used measure to assess discrimination is the\\nablingadjustmentoftheoverallperformancetobetterap- concordance index (c-index) [156], or, for logistic\\nproximate the expected model performance in novel models its equivalent, the area under the receiver oper-\\nsamples [23]. Bootstrapping also estimates a uniform ating characteristic curve (AUROC) [157]. These mea-\\nshrinkagefactortoenableadjustmentoftheestimatedre- sures represent the chance that, given one patient with\\ngression coefficients for over-fitting [26, 29, 151]. How- the outcome and one without, the CPR will assign a\\never, nointernal validation procedurescan bea substitute higher predictive probability to the patient with the out-\\nfor external validation; internal validation only addresses come compared to the one without. A c-index or\\nsampling variability, while external validation considers AUROC of 0.5 indicates predictions that are no better\\nvariationinthepatientpopulation[147]. than random predictions, and a value of 1 represents\\nperfect discrimination between patients with and with-\\nClinicalpredictionruleperformancemeasures outtheoutcome[29].Intheory,aCPRmaydemonstrate\\nCPR predictive performance can be assessed in terms of good discrimination (classifying patients into the correct\\noverall performance, calibration and discrimination [26]. risk categories), but poor calibration (inaccurately esti-\\n‘Overall performance’ can be quantified by calculating mating the absolute probability of an outcome), and vice\\nthe distance between observed and predicted outcomes, versa [158]. A model that cannot discriminate between\\nusingmeasures such asR2ortheBrierscore [152].‘Cali- patients with and without the outcome has little use as a\\nbration’ reflects the agreement between the predicted CPR; however, poor calibration can be corrected without\\nprobabilities produced by the model and the observed compromising discriminatory performance [19, 114].\\noutcome frequencies [23]. For example, if a model pre- Van Calster and Vickers [159] found that poorly cali-\\ndicts a 20% probability of residual tumour for a testicu- brated models diminish the clinical usefulness of a CPR,\\nlar cancer patient, residual tumour should be observed and can be harmful for clinical decision-making under\\nin about 20 out of 100 of these patients [46]. ‘Internal certain circumstances, emphasising the importance of\\ncalibration’ refers to agreement between predicted prob- developing well-calibrated CPR’s. On the other hand, a\\nabilities and observed outcome frequencies in the deriv- CPR with poor calibration but good discrimination at a\\nation dataset, where poor calibration may indicate lack particular risk threshold may be appropriate if the aim is\\nof model fit or model misspecification [153]. ‘External to prioritise patients for assessment or treatment, by\\ncalibration’ refers to agreement between predicted prob- identifying those with a very low risk of the target out-\\nabilities and observed outcome frequencies in novel comerelativetotherestofthepopulation[160].\\ndatasets external to the one from which the model was Performance measures such as sensitivity, specificity,\\nderived, where poor calibration may indicate an over- positive and negative predictive values and positive and\\nfitted model [153]. Calibration can be visualised by cate- negative likelihood ratios are used to assess performance\\ngorising individuals into quantiles based on their following the application of a risk threshold. Choosing a\\npredicted probabilities, and plotting the observed out- riskthresholdcanoftenbearbitrary,anditcanthereforebe\\ncome frequencies against the mean predicted probabil- usefultoconsiderarangeofthresholdswhenassessingper-\\nities [25]. Such a plot is the graphical equivalent of the formance[19].Ideally,aCPRwillhavebothahighsensitiv-\\nHosmer and Lemeshow goodness-of-fit test [154], ity and a high specificity, and therefore correctly identify\\nwhich, although frequently used, may lack statistical the majority of patients who truly have the condition, as\\npower to identify overfitting [25, 26]. Alternatively, bin- well as correctly exclude the majority of patients who do\\nary outcomes can be regressed on the predicted prob- not actually have the condition. However, this scenario\\nabilities of the fitted model to estimate the observed rarely occurs in clinical practice. More often than not, the\\noutcome probabilities using smoothing techniques such definition of a threshold is based on clinical considerations\\nas the loess algorithm [29, 153]. A comprehensive over- about the relative consequences of false positive and false\\nview ofcalibration isgiveninVanCalster etal.[155]. negative classifications. Sensitivity and specificity are in-\\nDiscrimination reflects the ability of a CPR to discrim- verselyproportional,sothatassensitivityincreases,specifi-\\ninate between patients with, and without, the outcome city decreases and vice versa [161]. Defining a high cut-off', 'Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page10of23\\npoint will result in good specificity and few false positives, understanding of a CPR [168]; however, these must be\\nbutpoorsensitivityandmanyfalsenegatives.Atestwitha presented alongside the full model formula. Scoring sys-\\nhigh specificity is useful for ruling in a disease if a person tems are often used to simplify CPRs and facilitate use,\\ntests positive. This is because it rarely misdiagnoses those where regression coefficients are converted to integer\\nwho do not have the condition of interest. Defining a low point values that can be easily totalled and related back\\ncut-off point will result in good sensitivity and few false to the predicted probabilities [169]. However, this trans-\\nnegatives, but poor specificity and many false positives. A formation leads to a loss of information and therefore\\ntestwithahighsensitivityisusefulforrulingout diseaseif reduced predictiveaccuracy[170].\\na person tests negative. This is because it rarely misdiag-\\nnoses those who have the condition of interest [161]. Re- Reportingthederivationofaclinicalpredictionrule\\nceiver operating characteristic (ROC) curves display the Numerous systematic reviews have shown that reporting\\nsensitivity and specificity of a CPR across the full range of of the derivation of CPRs is deficient [6–8]. As a result,\\ncut-offvalues,andcanbeusedtochooseanoptimalcut-off the TRIPOD guidelines were produced [36], and should\\nthreshold [162]. Other approaches to determining clinical befollowed byallresearchersworkinginthisfield.\\ncut-offshavealsobeenproposed[163].\\nIn recent years, some novel model performance mea- Stage3:externalvalidationandrefinementofaclinical\\nsures have been proposed that quantify the clinical use- predictionrule\\nfulness of a CPR, by taking into account the costs and As previously noted, CPRs perform better in the dataset\\nbenefits of clinical decisions. These measures include from which they are derived compared to their application\\nrelativeutility curves and decision curves [164, 165]. De- in plausibly related or ‘similar but different’ individuals,\\ncision curves in particular are becoming a popular even after internal validation and adjustment [24]. Dimin-\\nmethod of evaluating whether clinical decisions based ished performance can be due to overfitting, unsatisfactory\\nonCPRswoulddomoregoodthanharm[166].Decision model derivation, the absence of important predictors, dif-\\ncurve analysis assumes that a given probability threshold ferences in how the predictor variables are interpreted and\\nis directly related to the cost to benefit ratio, and uses measured, differences in the patient samples (‘case mix’)\\nthis threshold to weight false positive and false negative and differences in the prevalence of the disease [26, 148].\\npredictions. The cost to benefit ratio thus defines the There is no guarantee that even well-developed CPRs will\\nrelative weight of false-positive decisions to true-positive be generalisable to new individuals. In one external valid-\\ndecisions [164]. Model performance can subsequently be ation study, a CPR to detect serious bacterial infections in\\nsummarised as a net benefit, by subtracting the propor- children with fever of unknown source demonstrated con-\\ntion of false-positive patients from the proportion of siderably worse predictive performance, such that it was\\ntrue-positive patients, weighting by the relative costs of rendereduselessforclinicalcare[146].Itisthereforeessen-\\na false-positive and a false-negative result. The net bene- tial to assess the performance of a CPR in individuals out-\\nfit of a CPR can be derived across and plotted against side the derivation dataset; this process is known as\\nthe whole range of threshold probabilities, yielding a de- externalvalidation[28].\\ncision curve, similar to ROC curves that plot the full External validation is not simply repeating the steps\\nrangeofcut-offs fora sensitivity/specificity pair [164]. involved at the derivation stage in a new sample to\\nexamine whether the same predictors and regression co-\\nPresentationofaclinicalpredictionrule efficients are obtained; neither is it refitting the model in\\nThe final step in the derivation of a CPR is to consider a new sample and comparing the performance to that\\nthe format in which it should be presented. It is impera- observed in the derivation sample [24, 31]. External val-\\ntive that the regression coefficients and intercept of a idation involves taking the original fully specified model,\\nfinal model are presented, and confidence intervals with its predictors and regression coefficients as esti-\\naround predicted probabilities can also be provided [23, mated from the derivation study; measuring and docu-\\n26]. If the final regression formula (as in Table 3) is not menting the predictor and outcome variables in a new\\nprovided, a CPR could not be applied by future users patient sample; applying the original model to these data\\n[36]. A model can be developed into a simple web-based to predict the outcome of interest; and quantifying the\\ncalculator or application to enhance the usability of a predictive performance of the model by comparing the\\nCPR. This may be beneficial for complex CPRs, and predictions with the observed outcomes [20]. Perform-\\nwould facilitate their integration into the electronic ance should be assessed using calibration, discrimination\\nhealth record, allowing them to be used at the point of and measures to quantify clinical usefulness such as de-\\nclinical care [167]. Nomograms, graphical decision trees cision curve analysis [164]. A CPR can also be refined if\\nand other novel visualisation techniques could also be it demonstrates poor performance in an external valid-\\nused [26, 168], which may aid in the interpretation and ationstudy.Regrettably,fewCPRsareexternallyvalidated', 'Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page11of23\\n[27, 171, 172]. A systematic review of CPRs for children derivation study [26]. The greater the differences be-\\nidentified 101 CPRs addressing 36 conditions; of these, tween the patients in the derivation and validation\\nonly 17% had narrow validation and only 8% had broad samples, the stronger the test of generalisability of\\nvalidation[171]. the CPR [24]. Three types of external validation have\\nreceived the most attention, namely temporal valid-\\nStudydesignfortheexternalvalidationofaclinical ation, geographical validation and domain validation\\npredictionrule [148].\\nIdeally,avalidation studyshould be conducted prospect- In temporal validation studies, the CPR is tested on\\nively,byenrollingnewindividualsina specificallyprede- patients in the same centre(s) but over a different time\\nsigned study, and the CPR should be applied to all period [147]. Geographical validation studies examine\\npatients meeting the study inclusion criteria [17, 23]. the generalisability of the CPR to other centres, insti-\\nHowever, validation studies can be conducted retro- tutes, hospitals or countries [147]. Patient characteristics\\nspectively, using existing datasets. If adequate data on are likely to vary between locations, and predictor and\\nthe predictor and outcome variables is available [23]. In- outcome variables are likely to be interpreted and mea-\\nvestigators conducting a validation study should receive sured differently in different places, leading to greater\\nbrief training on the accurate application of the CPR. If differences between the derivation and validation popu-\\npossible,allpatientsshouldbesubjected tothereference lations than in a temporal validation study [24, 148]. In\\nstandard, to establish their true outcome and enable domainvalidation,theCPRistested inverydifferentpa-\\ncomparison with the CPR prediction. However, in some tients than those from whom it was derived, for example\\ncases, this may not be feasible or practical, and an ap- in patients from a different setting (e.g. primary or sec-\\npropriate and sensible proxy outcome may be used in- ondary care), or in patients of different ages (e.g. adults\\nstead [173]. Stiell and Wells [17] recommend that the vs. children). The case mix of patients included in a\\ninter-rater reliability of the interpretation of the CPR re- domain validation study will clearly differ from the der-\\nsult is assessed, to determine if the CPR is being applied ivation population [148]. Differences between the deriv-\\naccurately and consistently. In terms of sample size, for ationandvalidation populationsaregenerallysmallestin\\na logistic regression model with six predictors, a mini- a temporal validation study, and greatest in a domain\\nmum of 100 patients with the outcome of interest and validation study; therefore, good performance of a CPR\\n100 patients without the outcome of interest has been in a temporal validation study may only provide weak\\nsuggested [174]. Other authors propose that external evidence that the CPR can be generalised to new pa-\\nvalidation studies require a minimum of 100 events, but tients, while good performance in a domain validation\\nideally 200 events [175]. A minimum of 200 events and study can be considered as the strongest evidence of\\n200 non-events has been suggested in order to reliably generalisability [148]. Other types of external validation\\nassess moderate calibration and produce useful calibra- studies include methodologic validation which refers to\\ntion plots [155]. The characteristics of patients included testing using data collected via different methods,\\nin a validation study should be described in detail, and spectrum validation which refers to testing in patients\\ncompared with those included in the derivation study. with different disease severity or prevalence of the out-\\nTo enhance the interpretation of external validation come of interest and fully independent validation which\\nstudies, it is possible to quantify the degree of relatedness refers to testing by independent investigators at different\\nbetween derivation and validation datasets, to determine sites [26, 147]. A recent study of cardiovascular risk\\nthe extent to which the CPR can be generalised to differ- CPRs found that very few were externally validated by\\nent populations [34]. Authors have also proposed bench- independent researchers; to increase the chance of fully\\nmark values to distinguish between a case-mix effect and independent validation, researchers should report all the\\nincorrect regression coefficients in external validation information required for risk calculation, to ensure rep-\\nstudies, and therefore assist in the interpretation of a licability [178]. Some authors have found that CPRs\\nCPR’s performance in validation samples [176]. Similarly, demonstrate worse performance in fully independent\\na model-based concordance measure has recently been external validation studies compared to temporal or\\nderivedthatenablesquantificationoftheexpectedchange geographical external validation studies [26, 28], while\\ninaCPR’sdiscriminativeabilityowingtocase-mixhetero- others have found no difference [179]. When multiple\\ngeneity[177]. external validations of a CPR have been performed, it is\\nuseful to conduct a formal meta-analysis to summarise\\nTypesofexternalvalidation its overall performance across different settings and to\\nMany types of external validation are recognised in assessthecircumstancesunderwhichtheCPRmayneed\\nthe literature, but all types consider patients that dif- adjusting; a recently published framework provides guid-\\nfer in some respect from the patients included in the anceonhowtodothis [35].', 'Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page12of23\\nRefinementofaclinicalpredictionrule:modelupdatingor statistics cannot be recommended [192]. Decision-analytic\\nadjustment methodsareincreasinglyrecommendedastheyincorporate\\nWhen researchers encounter an inferior performance of misclassification costs and therefore indicate the clinical\\na CPR in an external validation study compared with usefulness of CPRs [186]. A systematic review of compari-\\nthat found in the derivation study, there is a temptation sons of prediction models for cardiovascular disease found\\nto reject the CPR and derive an entirely new one in the that formal and consistent statistical testing of the differ-\\noften considerably smaller validation dataset [148, 180]. encesbetweenmodelswaslackingandthatappropriaterisk\\nThis approach leads to a loss of scientific information reclassification measures were rarely reported [193]. A re-\\ncaptured in the derivation study and an abundance of cent commentary provides a useful and comprehensive\\nCPRs developed for the same clinical situation, leaving overviewoftheadvantagesanddisadvantagesofthevarious\\nclinicians in a quandary over which one to use [24, 148]. methods available for quantifying the added value of new\\nHowever, a reduction in performance is to be expected biomarkers[194].\\nin an external validation study [24, 26, 148]. The recom-\\nmended alternative is to update, adjust or recalibrate the Reportingtheexternalvalidationofaclinicalprediction\\nCPR using the validation data, thereby combining infor- rule\\nmation captured in the original CPR with information External validation studies of CPRs are often poorly re-\\nfrom new patients and improving generalisability [22, ported [9]; researchers should adhere to the TRIPOD\\n181, 182]. Several methods for updating CPRs are avail- checklist andaccompanyingguidelines[36].\\nable. When the outcome prevalence in the validation\\nstudy is different to that in the derivation study, calibra- Stage4:impactofaclinicalpredictionruleonclinical\\ntion in the validation sample will be affected, but can be practice\\nimproved by adjusting the baseline risk (intercept) of the Since the ultimate aim of a CPR is to improve the qual-\\noriginal model to the patients in the validation sample ity of patient care, the effect of a validated CPR on clin-\\n[180]. If the CPR is overfitted or underfitted, calibration ician behaviour and patient outcomes should be\\ncan be improved by simultaneously adjusting all of the examined in what are known as impact analysis studies\\nregression coefficients [24]. To improve discrimination, [22, 24]. It is increasingly recognised that CPR’s should\\nindividual regression coefficients can be re-estimated, or be regarded as complex interventions, as the introduc-\\nadditional predictors can be added [24, 180]. Ideally, up- tion of a CPR into clinical practice with subsequent\\ndated CPRs that are adjusted to validation samples management decisions consists of multiple interacting\\nshould themselves be externally validated, just like newly components [108, 195–201]. The impact of a CPR on\\nderivedCPRs[148]. clinical practice will depend on several interacting fac-\\ntors, including theaccuracy andapplicability ofthe CPR,\\nComparingtheperformanceofclinicalpredictionrules clinicians’ interpretation of probabilities and clinicians’\\nOnce a CPR has been externally validated, it is useful to adherence to and acceptance of the CPR [196]. Evaluat-\\ncompare its performance with the performance of other ing the impact of a CPR has been described as ‘the next\\nexisting CPRs for the same condition [61]. Improve- painful step’ in the development process [202]. Impact\\nments in discrimination can be assessed by quantifying analysis studies clearly differ from validation studies as\\nthe difference in the AUROC or equivalent c-index be- they must be comparative, typically requiring a control\\ntween two CPRs [183]; however, this approach is in- group of clinicians providing usual care [22, 24, 32]. It is\\nappropriate in the case of nested models that are fitted possible to assess the impact of both assistive CPRs that\\nin the same data set [184]. Novel metrics have been pro- simply provide predicted probabilities, and directive de-\\nposed that quantify the extent to which a new CPR im- cision rules that suggest a specific course of action based\\nproves the classification of individuals with and without onprobability categories [32].AssistiveCPRsrespectcli-\\nthe outcome of interest into predefined risk groups [46]. nicians’ individual judgement and leave room for intu-\\nThese include the net reclassification improvement ition, whereas directive rules may be more likely to\\n(NRI), and the integrated discrimination improvement influence clinician behaviour [32, 203, 204]. However, it\\n(IDI) [185]. Various decision-analytic approaches to is not guaranteed that clinicians will follow CPR, or the\\nmodel comparison have also been proposed [186]. All of recommendations provided by directive rules [32].\\nthese measures can be used for comparing both nested Therefore, an impact study must demonstrate that clin-\\nand non-nested models. However, both the NRI and IDI ical behaviour can be altered and patient care improved\\nstatistics have come under intense scrutiny in the litera- by the CPR, prior to widespread dissemination and im-\\nture and many researchers caution against their use, as plementation[17].\\npositive values may arise simply due to poorly fitted Unfortunately,evenfewerCPRsundergoanimpactas-\\nmodels [30, 187–191]. Therefore, the NRI and IDI sessment than undergo external validation. In the', 'Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page13of23\\nsystematic review of 101 CPRs for children, none had Given the significant practical, logistic and economic\\nimpact analysis performed [171]. An evaluation of 434 challenges associated with cluster randomised trials,\\nprimary care CPRs found that only 12 had undergone non-randomised approaches are possible and are often\\nimpact analysis [172]. A subsequent systematic review of used. Cluster randomised trials can be expensive and\\nthe impact of primary care CPRs found 18 studies relat- time-consuming and it may be difficult to recruit an ad-\\ningto14CPRs,with10/18studiesdemonstratinganim- equate number of clusters [24, 108]. A suggested\\nprovement in primary outcome when the CPR was used rule-of-thumb is to regard four clusters per arm as the\\ncomparedtousualcare[205].Thisreviewcautionedthat absolute minimum number required [211]; however,\\nthe small number of impact analysis studies found pre- methods for determining sample size in cluster rando-\\ncluded the possibility of drawing firm conclusions about mised trials have been proposed by a number of authors\\nthe overall effectiveness of CPRs in primary care, with [212–214]. A popular design is a before–after study, in\\nthe authors pointing out that the methodological quality which outcomes are assessed in a time period before a\\nof the included studies was unclear due to incomplete CPR is available and compared with outcomes measured\\nreporting [205]. Another recent systematic review of the in a time period after it is introduced; this design is sus-\\nimpact of CPRs found that the intermediate conse- ceptible to temporal confounding [24]. Finally, a rela-\\nquences of a CPR such as clinical management decisions tively low-cost and simple design is a before–after study\\nwere the primary outcome in the majority of studies, within the same clinicians. In this design, clinicians are\\nwhile few studies aimed to establish the effect of a CPR asked to indicate their treatment or management deci-\\non patient outcomes [206]. In addition, in many of the sion or perceived risk of disease for the same patient\\nincluded studies, the risk of bias was either high or un- both before, and after, receiving the CPR prediction [24].\\nclear [206]. Finally, a study describing the distribution of Single centreimpactstudiesarerecommendedtoinform\\nderivation, validation and impact studies in four reviews the planning of multicentre randomised trials [32]. As\\nof leading medical journals since 1981 demonstrated with derivation and validation studies, a sample size cal-\\nthat a minority of studies concerned CPR impact (10/ culation should be performed, with consideration of all\\n201),with thepattern remainingstable overtime[27]. relevant impact measures, and where possible assess-\\nment of outcome measures should be blinded to the\\nStudydesignforanimpactanalysis CPR predictions and recommendations [32, 33]. Clini-\\nBefore carrying out a formal impact study, researchers cians must undergo training in order to correctly inter-\\nmust consider whether the CPR is ready for implemen- pretandusetheCPR[17].\\ntation [108, 207]. If possible, the predictive performance The impact of CPRs can also be estimated indirectly\\nofthe CPR should be verified inthenewsetting,and the usingdecisionanalyticmodelling,whichintegratesinfor-\\nCPR tailored to the new setting to enhance performance mation on CPR predictions and information about the\\n[108]. The optimal study design for an impact analysis is effectivenessof treatmentsfrom therapeuticintervention\\na cluster randomised trial with centres as clusters [22]. studies [215, 216]. Such studies cost less, and take less\\nRandomising individual patients is not recommended as time,thanRCTs;however,theyarelimited bythequality\\ncliniciansmaylearn theruleandapply ittopatientsran- of available evidence, and only provide theoretical indi-\\ndomised to the control group [22]. Randomising clini- cations of the impact CPRs may have on patient out-\\ncians is preferable but requires more patients, and may comes. Thus it has been suggested that they should not\\nlead to contamination of experience between clinicians replace RCTs but rather be performed as an intermedi-\\nin the same centre [24, 208]. An attractive variant of a atesteppriortoanRCT[217].\\ncluster randomised trial is the stepped-wedge cluster\\nrandomised trial. In a stepped-wedge design, all centres Measuresofimpactofaclinicalpredictionrule\\napply care-as-usual, and then use the CPR at different, Duringanimpactanalysisstudy,thesensitivityandspeci-\\nrandomly allocated time periods [209]. Thisdesignallows ficity of the CPR should be recalculated to determine its\\nfor the comparison of outcomes both within and between accuracyinthenewstudypopulation[17].However,mea-\\nhospitals, generates a wealth of data regarding potential suresofCPRaccuracyarenotsynonymouswithmeasures\\nbarriers to implementation and is particularly beneficial if of impact, and only represent the potential impact of the\\nthe CPR turns out to have a promising effect [210]. When CPR [32]. This is because clinicians are unlikely to follow\\nthe outcome of interest in an impact study is clinician be- thelogicoftheCPRoritsrecommendationsineverycase;\\nhaviour or decision-making, a cross-sectional randomised they may not use the CPR at all, they may not use it cor-\\nstudy without patient follow-up is sufficient, with random- rectly, they may deliberately disregard its predictions or\\nisation at either the patient or clinician level. However, to suggestions or they may be unable touse it for other rea-\\ndetermine the impact of a CPR on patient outcomes or sons [32]. Measures that are assessed in traditional RCTs\\ncost-effectiveness,follow-upofpatientsisessential[22]. includesafety,whichreferstoanyadverseeventsresulting', 'Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page14of23\\nfrom the implementation of an intervention, and efficacy, with and without the condition of interest should be su-\\nwhich relates to the extent that an intervention helps to perior to that of unstructured clinical judgement alone.\\nimprove patient outcomes, for example by reducing mor- Therefore,avitalmetricisthecomparisonoftheaccuracy\\ntality rates [218]. In addition, Reilly and Evans [32] of the CPR-predicted probabilities of disease, or recom-\\npropose that the impact of a CPR is assessed in terms of mendeddecisions,withtheaccuracyofcliniciansownes-\\nits ‘safety’ and ‘efficiency’, where safety is defined as the timated disease probabilities or management decisions\\nproportionofpatientsfoundtohavetheoutcomeofinter- [18]. The sensitivity and specificity of clinicians’ predic-\\nestandwhoreceivedtheappropriateintervention,andef- tions or decisions are generally measured under usual\\nficiency is defined as the proportion of patients without practice,andcomparedtothesensitivityandspecificityof\\ntheoutcomeofinterestandwhodidnotreceivetheinter- the CPR predictions or decisions when applied to the\\nvention. The sensitivity and specificity of a CPR will only same patients [226, 227]. Some studies have used clinical\\nbe the same as its safety and efficiency if clinicians follow vignettes[228]whileothershaveusedmultivariablelogis-\\nthe logic and recommendations of the CPR exactly [32]. tic models to assess the added value of a CPR over and\\nTherefore,inanimpactanalysisstudy,aCPRmaydemon- above clinical judgement alone [229]. If it can be demon-\\nstrate more, or less, actual impact than its potential im- strated that the performance of a CPR is superior to un-\\npact. The effect of clinicians’ incorrect use of the CPR, or aided clinician judgement, this may aid clinicians’\\ntheir deviations from its logic or suggestions can provide acceptanceanduseoftheCPR[32].Althoughcomparison\\nimportant insights into its impact under specific circum- ofaCPRtocliniciansuspicionregularlytakesplaceatthe\\nstances,andmayrevealcomplexinteractionsbetweencli- impact analysis stage, some researchers have recom-\\nnicians and the CPR [32]. For example, Reilly and mended that this is carried out during the derivation or\\ncolleagues [219] found that when clinicians did not con- validation stages, arguing that if the CPR does not add\\nsult a CPR for suspected acute cardiac ischemia at all, or anything beyond clinical judgement, then the use of the\\noverruled its recommendations, their decisions were less CPR and an impact study would not be warranted [230].\\nefficientthaniftheyhadfollowedtheCPRineverycase. In addition, Finnerty and colleagues [231] recommend\\nthat comparison is undertaken in multiple settings, as the\\nAcceptabilityofaclinicalpredictionrule performance of a CPR may be superior to clinical judge-\\nIf the use of a CPR is warranted but it is not used, the ment in certain settings, but inferior or no different in\\nconsiderable time, money and effort that goes into its other settings. A recent systematic review comparing\\ndevelopment and evaluation is wasted. Assessing the ac- CPRs with clinical judgement concluded that the differ-\\nceptability of a CPR is therefore crucial for successful ences between the two methods of judgement are likely\\nimplementation. Even valid and reliable CPRs may not due to different diagnostic thresholds, and that the pre-\\nbe accepted or used by clinicians [17]. Impact studies ferred judgement method in a given situation would\\nallow researchers to evaluate the acceptability of a CPR therefore depend on the relative benefits and harms\\nto clinicians, patients or others who may use it, as well resulting from true positive and false positive diagnoses\\nas its ease ofuseandbarriers toitsuptake[22]. If aCPR [232].Brownandcolleagues’[200]foundthattheuseand\\nproves to be acceptable, its long-term and widespread potential advantages of a CPR may be much more com-\\ndissemination and implementation would be justified; if plexthanoriginallythought,andthatCPRsmaybeuseful\\nnot, the CPR could undergo modification and further for purposes not previously reported, such as enhancing\\nevaluation [48]. Acceptability of a CPR and attitudes to- communicationwithcolleaguesandpatients,andmedico-\\nwards it can be determined via survey, qualitative, simu- legalpurposes.Recent studiesinthe childprotectionfield\\nlation or clinical vignette studies [33, 48, 220–222]. The havedemonstratedthatCPRs mayprovideclinicians with\\nvalidated Ottawa Acceptability of Decision Rules survey additional confidence in their decision-making, even if\\ninstrument can be used both to measure the overall ac- they do not alter their management actions based on the\\nceptability of a CPR, and to assess specific barriers to its CPRsriskprediction[220,233].\\nuse, which can inform potential improvements to the\\nCPR as well as the design of dedicated implementation Thefourphasesofimpactanalysisforclinicalprediction\\nstrategies [48]. Qualitative studies can be invaluable for rules\\ndetermining the acceptability of a CPR but are relatively Despite the abundance of methodological guidelines for\\nrare[200,220,222–225]. thederivationandvalidationofCPRs[26],thereisalack\\nof clear guidance for the design, conduct and reporting\\nComparisonofaclinicalpredictionrulewithunstructured of impact analysis studies of CPRs. To this end, Wallace\\nclinicaljudgement and colleagues [33] formulated an iterative four-phased\\nFor a CPR to improve the diagnostic accuracy of clini- framework for the impact analysis of CPRs, specifying\\ncians, its performance in distinguishing between patients the importance of substantial preparatory and feasibility', 'Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page15of23\\nwork prior to the conduct of a full-scale formal experi- Stage5:cost-effectivenessoftheclinicalpredictionrule\\nmental study (Fig. 2). Phase 1 involves determining If an impact analysis study shows that a CPR demon-\\nwhether the CPR is ready for impact analysis, i.e. strates safety and efficiency, alters clinician behaviour\\nwhether it has been rigorously derived and broadly vali- andimproves clinical care,aformaleconomicevaluation\\ndated according to pre-defined methodological stan- can be carried out to determine the cost-effectiveness of\\ndards. Phase 2 includes assessing the acceptability of the the CPR. The aim is to establish the health care savings\\nCPR and identifying potential barriers to its uptake and associated with routine use of the CPR in clinical prac-\\nimplementation, as well as assessing the feasibility of tice [17]. Economic evaluation is usually based on deci-\\nconducting an impact study. Evaluating the feasibility of sion analytic models [234]. Any economic evaluation\\ncarrying out an impact study involves consideration of must make reasonable assumptions about the accuracy\\nmultiple factors including the most appropriate study and effectiveness of the CPR and the costs involved [17].\\ndesign for measuring relevant outcomes, and how the Sensitivity analyses should be performed by re-running\\nCPR will be delivered at the point of care or integrated models with alternative assumptions, to examine the un-\\nintotheclinicalworkflow.Phase3involvesformallytest- certainty of the model projections [234]. In reality, many\\ning the impact of the CPR usinga comparative study de- economic evaluations are conducted prior to an impact\\nsign. Phase 4 involves long-term dissemination and analysis study or even an external validation study, per-\\nimplementation of the CPR, which corresponds to stage haps because they are relatively quick and low cost to\\n6inthedevelopmentofCPRs,discussedbelow. perform, and provide a significant part of the justifica-\\ntion forthedevelopment andimplementation ofaCPR.\\nReportingtheimpactanalysisofaclinicalpredictionrule Stage6:long-termimplementationanddisseminationof\\nThere are currently no published reporting guidelines theclinicalpredictionrule\\nfor studies analysing the impact of CPRs. This is a gap The gap between evidence and practice has been con-\\nin the literature, and a priority for future research. How- sistently demonstrated in health services research [235],\\never, researchers assessing the impact of CPRs in an and there is no guarantee that a CPR will be widely dis-\\nRCT may refer to guidelines on the reporting of clinical seminated or used, even if it is shown to have a positive\\ntrials, such as the Consolidated Standards of Reporting impact on clinical care and cost benefits. Therefore, in\\nTrials (CONSORT)statement[218]. order to maximise the uptake of a CPR, an active\\nFig.2Thefourphasesofimpactanalysisforaclinicalpredictionrule.ReproducedwithpermissionfromWallaceetal.2011[33]', 'Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page16of23\\nTable4Barrierstotheuseofclinicalpredictionrulesinpractice Table4Barrierstotheuseofclinicalpredictionrulesinpractice\\nidentifiedintheliterature identifiedintheliterature(Continued)\\nTheme Subtheme Barrier Theme Subtheme Barrier\\nKnowledge Awareness Unaware: (cid:129)TheCPRisnotgeneralisabletotheclinician’s\\npatient\\n(cid:129)ThatCPRexists\\n(cid:129)TheCPRisstaticanddoesnotconsiderthe\\n(cid:129)Ofclinicalproblemorburdenofclinical\\ndynamicnatureofclinicalpractice\\nproblemtowhichCPRapplies\\n(cid:129)OverrulingtheCPRisoftenjustified\\nUnabletochoosefrommultipleCPRs\\nDatarequiredfortheCPRisdifficulttoobtain\\nFamiliarity UnfamiliarwithCPR\\nEnvironmental Lackof:\\nUnderstanding Lackofknowledgeandunderstandingofthe\\nfactors\\npurpose,developmentandapplicationofCPRsin (cid:129)Time\\ngeneral\\n(cid:129)Organisationalsupport\\nForgetting ClinicianforgetstouseCPRdespitebest\\n(cid:129)Peersupportforuse\\nintentions\\nPerceivedincreasedriskoflitigation\\nAttitudes Negativebeliefs Beliefthat:\\naboutCPRs (cid:129)CPRsthreatenautonomy Insufficientincentivesorreimbursementforuse\\noftheCPR\\n(cid:129)CPRsaretoo‘cook-book’,andoversimplifythe\\nAdaptedfromSanders2015[253].CPRclinicalpredictionrule\\nclinicalassessmentprocess\\n(cid:129)ClinicaljudgementissuperiortoCPRs\\n(cid:129)Clinicaljudgementisnoterrorprone dissemination and implementation plan must be in\\nplace. Simple passive diffusion of study results via publi-\\n(cid:129)UseofCPRscausesintellectuallaziness\\ncation in journals or presentations at conferences is un-\\n(cid:129)ThedevelopmentoftheCPRwasbiased\\nlikely to significantly change clinical practice [236].\\n(cid:129)Patientswilldeemclinicianslesscapableif\\nusingaCPR Examplesofdisseminationincludeactivelytargetingspe-\\n(cid:129)CPRsonlyapplytothelessexperienced cific audiences via direct mail or the press, while imple-\\nmentation involves the use of local administrative,\\n(cid:129)Probabilitiesarenothelpfulfordecision-making\\neducational, organisational and behavioural strategies to\\nDislikeoftheterm‘rule’\\nput the CPR into effect in clinical practice [236]. Active\\nClinicianhadafalsenegativeresultwhenusinga\\nCPRinthepast broad dissemination of the widely accepted Ottawa ankle\\nrule via an educational intervention found no impact of\\nExistingCPRsarenotreadyforclinicalapplication\\ntheruleonclinicians’useofankleradiography[237],lead-\\nOutcome Beliefthat:\\nexpectancy ing the authors to recommend implementation strategies\\n(cid:129)CPRswillnotleadtoimprovedpatientor\\nprocessoutcomes at the local level instead. Some implementation strategies\\n(cid:129)TheinformationprovidedbytheCPRisnot havebeenfoundtobemoreeffectivethanothersinchan-\\nsufficienttoalterclinicaldecisions ging clinician behaviour. A systematic review found the\\nClinician: most effective approaches to be reminders in the form of\\n(cid:129)Fearsunintendedconsequencesofuse posters, pocket cards, sheets or computer-embedded\\n(cid:129)IsuncertainaboutusingtheCPRinpatients prompts,face-to-facelocalclinicianeducationandtheuse\\nwithanatypicalpresentation of multiple interventions simultaneously [238]. Incorpor-\\n(cid:129)Worriesthatimprovingefficiencythreatens ationofCPRsintoclinicalguidelinesmayalsobeof bene-\\npatientsafety\\nfit; a recent study found that clinical guidelines and local\\nSelf-efficacy BeliefthattheCPRistoodifficulttouse\\npolicies that mandated the use of CPRs were effective in\\nClinicianuncertainhowtointerpretoruseCPR increasing their adoption in clinical practice [200]. In\\noutput\\naddition, the integration of CPRs into the clinical work-\\nMotivation ClinicianlacksmotivationtousetheCPR\\nflow via electronic health records may promote their use\\nBehaviour Patientfactors Patientsexpectationsarenotconsistentwiththe\\nCPR [239]. Since impact in a research study does not ensure\\nimpact in real-world clinical practice, follow-up of clini-\\nFeaturesofthe Clinician:\\nCPR cianscanbeconductedtoassessthelong-termuseandef-\\n(cid:129)FindsCPRtoocomplicated\\nfectoftheCPR[17,33].\\n(cid:129)FindsCPR‘toomuchtrouble’toapply\\nPerceptionthat:\\nBarriersandfacilitatorstotheuseofclinicalprediction\\n(cid:129)TheCPRisnotanefficientuseoftime\\n(cid:129)TheCPRdoesnothavefacevalidityorthat rules\\nimportantpredictorsaremissing Clearly,identifyingthebarriersandfacilitatorstotheimple-\\n(cid:129)TheCPRdoesnotfitinwithusualworkflowor mentation of CPRs is crucial for the development of tar-\\napproachtodecision-making geted implementation strategies that may encourage', 'Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page17of23\\nclinicianstousetheCPR.TheadoptionofCPRsintoclinical impact analysis of existing ones [33]. The CPR must be\\npractice is influenced by various factors including clinician presented in full, and the study methods reported ad-\\ncharacteristics,patientfactors,featuresoftheCPRitselfand equately,toensureitsquality,riskofbiasandclinicalutil-\\nenvironmentalfactors[32,66,221,224,225,240–252]. ity can be evaluated; the TRIPOD guidelines should be\\nTable4providesanoverviewofthebarrierstotheadop- followed to ensure completeness of reporting require-\\ntionofCPRsidentifiedintheliterature[253],groupedac- ments[36].Feasibilityandpreparatoryworkisessentialto\\ncordingtotheireffectonclinicianknowledge,attitudesor determine whether a formal impact study of the CPR is\\nbehaviours [254]. Barriers relating to knowledge include warranted [33, 108], and survey and qualitative work\\nlackofawarenessoftheCPRortheburdenoftheclinical shouldbeundertakentoverifywhethertheCPRisaccept-\\nproblem it applies to, unfamiliarity with the CPR and a able and relevantto clinicians [48, 65, 220, 222]. If a CPR\\nlack of understanding of the purpose of CPRs in general isfoundtohaveapositiveimpactonpatientoutcomes,its\\n[225, 240–242]. Clinicians may also be unaware of a CPR cost-effectiveness should be evaluated, and a targeted im-\\ndue to the increasing volume of CPRs, particularly when plementation and dissemination strategy devised, with\\ntheyaredevelopedforthesamecondition[61,243].Com- consideration of possible barriers to implementation, to\\nmon barriers relating to clinician attitude include a con- maximiseuptake[17].\\nvictionthatclinicaljudgementissuperiortotheCPR,and In summary, the development and evaluation of a ro-\\ndistrustoftheaccuracyoftheCPR[32,224,240,241,244, bust, clinically useful CPR with high predictive accuracy\\n245]. Barriers relating to behaviour include organisational is challenging, and research in the field concerning der-\\nfactors [251], the complexity of the CPR and the time it ivation, validation and impact evaluation continues to\\ntakestoapply;surveystudiessuggestthatcliniciansmuch evolve.However,adheringtotheexistingmethodological\\nprefer a CPR that is simple to use, memorable and saves standards and recommendations in the literature at\\ntime[221,246,247].Complexmodelssuchasthosebased every step will help to ensure a rigorous CPR that has\\non machine and artificial learning algorithms may intro- the potential to contribute usefully to clinical practice\\nduce additional barriers relating to applicability and us- anddecision-making.\\nability, due to their potential lack of reproducibility and\\ntransparency [60, 82]. Other studies have demonstrated Abbreviations\\nAUROC:Areaunderthereceiveroperatingcharacteristiccurve;CPR:Clinical\\nthat clinicians will be unlikely to use a CPR if there are\\npredictionrule;EPV:Eventspervariable;IDI:Integrateddiscrimination\\npredictors missing which are deemed to be important, or improvement;MAR:Missingatrandom;MCAR:Missingcompletelyat\\nif the predictor variables are not logically related to the random;MNAR:Missingnotatrandom;NRI:Netreclassification\\nimprovement;RCT:Randomisedcontrolledtrial;ROC:Receiveroperating\\noutcome variable [32, 225]. Reilly and Evans [32] offer a\\ncharacteristiccurve;TRIPOD:TransparentReportingofamultivariable\\nnumberofstrategiesforovercomingbarrierstotheuseof predictionmodelforIndividualPrognosisorDiagnosis\\nCPRs. These includeemphasising the discretionaryuse of\\nthe CPR, comparing clinical judgement with the CPR, Acknowledgements\\nWewouldliketothankHealthandCareResearchWalesforfundingthis\\ncheckingwhetheranyexcludedfactorsaffecttheCPRpre-\\nwork.\\ndictions, performing a simulatedimpact analysis and soli-\\nciting clinicians input regarding the logic and format of Funding\\ntheCPR,amongothers[32]. ThisworkwassupportedbyHealthandCareResearchWales(grantnumber\\nHS-14-24).Thefundershadnoinvolvementinthestudydesign,thecollec-\\ntion,analysisorinterpretationofthedata,thewritingofthemanuscriptor\\nSummary\\nthedecisiontosubmitthemanuscriptforpublication.\\nFor CPRs to be useful in clinical practice, they must be\\nproperlyplanned[67],derivedusingappropriatestatistical Availabilityofdataandmaterials\\ntechniques [23] and externally validated in multiple set- Notapplicable.\\ntings and by independent investigators to determine their\\nAuthors’contributions\\npredictiveaccuracy[148].Inaddition,CPRsmustundergo\\nLECconductedtheliteraturesearch,draftedthemanuscript,producedthe\\nimpact analysis to determine their effect on clinician be- tables,boxesandfiguresandeditedthemanuscript.DMF,SMandAMK\\nhaviourandrelevantpatientoutcomes[22].Therearenu- criticallyrevisedthemanuscriptforimportantintellectualcontent.Allauthors\\napprovedthefinalversionsubmittedforpublication.\\nmerous factors to consider when deriving, validating and\\nassessing the impact of a CPR including the study design,\\nEthicsapprovalandconsenttoparticipate\\npreparatory work, statistical analysis, modelling strategy, Notapplicable.\\nperformance/impact measures, the presentation of the\\nCPR and the reporting of the study methodology. New Consentforpublication\\nNotapplicable.\\nCPRsshouldonlybederivedwhenthereisaclearclinical\\nneedforthem[17].Thereisanurgentneedtochangethe\\nCompetinginterests\\nfocus from the derivation of CPRs, to the validation and Theauthorsdeclarethattheyhavenocompetinginterests.', \"Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page18of23\\nPublisher’s Note 26. SteyerbergE.Clinicalpredictionmodels:apracticalapproachto\\nSpringerNatureremainsneutralwithregardtojurisdictionalclaimsin development,validationandupdating.NewYork:Springer-Verlag;2009.\\npublishedmapsandinstitutionalaffiliations. 27. SteyerbergEW,MoonsKG,vanderWindtDA,HaydenJA,PerelP,Schroter\\nS,etal.Prognosisresearchstrategy(PROGRESS)3:prognosticmodel\\nReceived:13August2018Accepted:12May2019 research.PLoSMed.2013;10(2):e1001381.\\n28. AltmanDG,RoystonP.Whatdowemeanbyvalidatingaprognostic\\nmodel?StatMed.2000;19(4):453–73.\\n29. HarrellF.Regressionmodelingstrategies:withapplicationstolinearmodels,\\nReferences\\nlogisticregression,andsurvivalanalysis.NewYork:Springer;2001.\\n1. AdamsST,LevesonSH.Clinicalpredictionrules.BMJ.2012;344:d8312.\\n30. WynantsL,CollinsGS,VanCalsterB.Keystepsandcommonpitfallsin\\n2. BeattieP,NelsonR.Clinicalpredictionrules:whataretheyandwhatdo developingandvalidatingriskmodels.BJOG.2017;124(3):423–32.\\ntheytellus?AustJPhysiother.2006;52(3):157–63.\\n31. CollinsGS,MaJ,GerryS,OhumaE,OdondiLO,TrivellaM,etal.Risk\\n3. LaupacisA,SekarN,StiellIG.Clinicalpredictionrules.Areviewandsuggested\\npredictionmodelsinperioperativemedicine:methodological\\nmodificationsofmethodologicalstandards.JAMA.1997;277(6):488–94.\\nconsiderations.CurrAnesthesiolRep.2016;6(3):267–75.\\n4. McGinnTG,GuyattGH,WyerPC,NaylorCD,StiellIG,RichardsonWS.Users'\\n32. ReillyBM,EvansAT.Translatingclinicalresearchintoclinicalpractice:impactof\\ng ruu leid se .Es vt io deth ne cem -be ad si ec dal mlit ee dra ictu inr ee: wX oX rII k: ih no gw grt oo uu ps .e JAa Mrti Acl .e 2s 0a 0b 0o ;2u 8t 4c (1li )n :7ic 9a –l 8d 4e .cision usingpredictionrulestomakedecisions.AnnInternMed.2006;144(3):201–9.\\n33. WallaceE,SmithSM,Perera-SalazarR,VaucherP,McCowanC,CollinsG,et\\n5. HendriksenJM,GeersingGJ,MoonsKG,deGrootJA.Diagnosticand\\nprognosticpredictionmodels.JThrombHaemost.2013;11(Suppl1):129–41. al.Frameworkfortheimpactanalysisandimplementationofclinical\\npredictionrules(CPRs).BMCMedInformDecisMak.2011;11:62.\\n6. BouwmeesterW,ZuithoffNP,MallettS,GeerlingsMI,VergouweY,\\n34. DebrayTP,VergouweY,KoffijbergH,NieboerD,SteyerbergEW,MoonsKG.\\nSteyerbergEW,etal.Reportingandmethodsinclinicalpredictionresearch:\\nasystematicreview.PLoSMed.2012;9(5):1–12. Anewframeworktoenhancetheinterpretationofexternalvalidation\\nstudiesofclinicalpredictionmodels.JClinEpidemiol.2015;68(3):279–89.\\n7. MallettS,RoystonP,DuttonS,WatersR,AltmanDG.Reportingmethodsin\\n35. DebrayTP,DamenJA,RileyRD,SnellK,ReitsmaJB,HooftL,etal.A\\nstudiesdevelopingprognosticmodelsincancer:areview.BMCMed.2010;8:20.\\nframeworkformeta-analysisofpredictionmodelstudieswithbinaryand\\n8. CollinsGS,MallettS,OmarO,YuL-M.Developingriskprediction\\ntime-to-eventoutcomes.StatMethodsMedRes.2018.https://doi.org/10.\\nmodelsfortype2diabetes:asystematicreview ofmethodologyand\\n1177/0962280218785504.\\nreporting.BMCMed.2011;9:103.\\n36. MoonsKG,AltmanDG,ReitsmaJB,IoannidisJP,MacaskillP,SteyerbergEW,\\n9. CollinsGS,deGrootJA,DuttonS,OmarO,ShanyindeM,TajarA,etal.External\\netal.Transparentreportingofamultivariablepredictionmodelfor\\nvalidationofmultivariablepredictionmodels:asystematicreviewof\\nindividualprognosisordiagnosis(TRIPOD):explanationandelaboration.\\nmethodologicalconductandreporting.BMCMedResMethodol.2014;14:40.\\nAnnInternMed.2015;162(1):W1–W73.\\n10. KleinrouwelerCE,Cheong-SeeFM,CollinsGS,KweeA,ThangaratinamS,\\n37. LoBWY,FukudaH,NishimuraY,FarrokhyarF,ThabaneL,LevineMAH.\\nKhanKS,etal.Prognosticmodelsinobstetrics:available,butfarfrom\\napplicable.AmJObstetGynecol.2016;214(1):79–90e36. Systematicreviewofclinicalpredictiontoolsandprognosticfactorsin\\naneurysmalsubarachnoidhemorrhage.SurgNeurolInt.2015;6:135.\\n11. EttemaRG,PeelenLM,SchuurmansMJ,NierichAP,KalkmanCJ,MoonsKG.\\nPredictionmodelsforprolongedintensivecareunitstayaftercardiacsurgery: 38. HopperAD,CrossSS,HurlstoneDP,McAlindonME,LoboAJ,Hadjivassiliou\\nsystematicreviewandvalidationstudy.Circulation.2010;122(7):682–9. M,etal.Pre-endoscopyserologicaltestingforcoeliacdisease:evaluationof\\n12. CollinsGS,OmarO,ShanyindeM,YuLM.Asystematicreviewfindsprediction aclinicaldecisiontool.BMJ.2007;334:729.\\nmodelsforchronickidneydiseasewerepoorlyreportedandoftendeveloped 39. LaValleyMP,LoGH,PriceLL,DribanJB,EatonCB,McAlindonTE.\\nusinginappropriatemethods.JClinEpidemiol.2013;66(3):268–77. Developmentofaclinicalpredictionalgorithmforkneeosteoarthritis\\n13. NayakS,EdwardsDL,SalehAA,GreenspanSL.Performanceofrisk structuralprogressioninacohortstudy:valueofaddingmeasurementof\\nassessmentinstrumentsforpredictingosteoporoticfracturerisk:a subchondralbonedensity.ArthritisResTher.2017;19:95.\\nsystematicreview.OsteoporosInt.2014;25(1):23–49. 40. SteyerbergEW,MushkudianiN,PerelP,ButcherI,LuJ,McHughGS,etal.\\n14. AltmanDG.Prognosticmodels:amethodologicalframeworkandreviewof Predictingoutcomeaftertraumaticbraininjury:developmentand\\nmodelsforbreastcancer.CancerInvestig.2009;27(3):235–43. internationalvalidationofprognosticscoresbasedonadmission\\n15. CollinsGS,MichaelssonK.Fractureriskassessment:stateoftheart, characteristics.PLoSMed.2008;5(8):e165.\\nmethodologicallyunsound, orpoorlyreported?CurrOsteoporosRep. 41. FerroJM,Bacelar-NicolauH,RodriguesT,Bacelar-NicolauL,CanhãoP,\\n2012;10(3):199–207. CrassardI,etal.Riskscoretopredicttheoutcomeofpatientswithcerebral\\nveinandduralsinusthrombosis.CerebrovascDis.2009;28(1):39–44.\\n16. WassonJH,SoxHC,NeffRK,GoldmanL.Clinicalpredictionrules.Applications\\nandmethodologicalstandards.NEnglJMed.1985;313(13):793–8. 42. WooJ,LeungJ,WongS,KwokT,LeeJ,LynnH.Developmentofasimple\\n17. StiellI,WellsG.Methodologicstandardsforthedevelopmentofclinical scoringtoolintheprimarycaresettingforpredictionofrecurrentfallsin\\ndecisionrulesinemergencymedicine.AnnEmergMed.1999;33(4):437–47. menandwomenaged65yearsandoverlivinginthecommunity.JClin\\nNurs.2009;18(7):1038–48.\\n18. GreenSM,SchrigerDL,YealyDM.Methodologicstandardsforinterpreting\\nclinicaldecisionrulesinemergencymedicine:2014update.AnnEmerg 43. ScholzNN,BäslerKK,SaurPP,BurchardiHH,FelderSS.Outcomeprediction\\nMed.2014;64(3):286–91. incriticalcare:physicians'prognosesvs.scoringsystems.EurJAnaesthesiol.\\n2004;21(8):606–11.\\n19. SteyerbergEW,VergouweY.Towards better clinicalpredictionmodels:\\nseven steps fordevelopmentandan ABCDforvalidation.EurHeartJ. 44. KheterpalS,TremperKK,HeungM,RosenbergAL,EnglesbeM,ShanksAM,\\n2014;35(29):1925–31. CampbellDA.Developmentandvalidationofanacutekidneyinjuryrisk\\n20. AltmanDG,VergouweY,RoystonP,MoonsKG.Prognosisandprognostic indexforpatientsundergoinggeneralsurgeryresultsfromanationaldata\\nresearch:validatingaprognosticmodel.BMJ.2009;338:b605. set.Anesthesiology.2009;110(3):505–15.\\n21. MoonsKG,RoystonP,VergouweY,GrobbeeDE,AltmanDG.Prognosisand 45. PaceN,EberhartL,KrankeP.Quantifyingprognosiswithriskpredictions.Eur\\nprognosticresearch:what,why,andhow?BMJ.2009;338:b375. JAnaesthesiol.2012;29(1):7–16.\\n22. MoonsKG,AltmanDG,VergouweY,RoystonP.Prognosisandprognostic 46. SteyerbergEW,VickersAJ,CookNR,GerdsT,GonenM,ObuchowskiN,etal.\\nresearch:applicationandimpactofprognosticmodelsinclinicalpractice. Assessingtheperformanceofpredictionmodels:aframeworkforsome\\nBMJ.2009;338:b606. traditionalandnovelmeasures.Epidemiology.2010;21(1):128–38.\\n23. MoonsKG,KengneAP,WoodwardM,RoystonP,VergouweY,AltmanDG, 47. McGinnT.Puttingmeaningintomeaningfuluse:aroadmaptosuccessful\\nGrobbeeDE.Riskpredictionmodels:I.development,internalvalidation,and integrationofevidenceatthepointofcare.JMIRMedInform.2016;4(2):e16.\\nassessingtheincrementalvalueofanew(bio)marker.Heart.2012;98(9):683–90. 48. BrehautJC,GrahamID,WoodTJ,TaljaardM,EaglesD,LottA,etal.\\n24. MoonsKG,KengneAP,GrobbeeDE,RoystonP,VergouweY,AltmanDG, Measuringacceptabilityofclinicaldecisionrules:validationoftheOttawa\\nWoodwardM.Riskpredictionmodels:II.Externalvalidation,model acceptabilityofdecisionrulesinstrument(OADRI)infourcountries.Med\\nupdating,andimpactassessment.Heart.2012;98(9):691–8. DecisMak.2010;30(3):398–408.\\n25. RoystonP,MoonsKGM,AltmanDG,VergouweY.Prognosisandprognostic 49. SarasinFP,ReymondJM,GriffithJL,BeshanskyJR,SchifferliJA,UngerPF,et\\nresearch:developingaprognosticmodel.BMJ.2009;338:b604. al.Impactoftheacutecardiacischemiatime-insensitivepredictive\", \"Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page19of23\\ninstrument(ACI-TIPI)onthespeedoftriagedecisionmakingforemergency 75. LabarèreJ,RenaudB,FineMJ.Howtoderiveandvalidateclinicalprediction\\ndepartmentpatientspresentingwithchestpain:acontrolledclinicaltrial.J modelsforuseinintensivecaremedicine.IntensiveCareMed.2014;40(4):513–27.\\nGenInternMed.1994;9(4):187–94. 76. GrobmanWA,StamilioDM.Methodsofclinicalprediction.AmJObstet\\n50. StiellIG,McDowellI,NairRC,AetaH,GreenbergG,McKnightRD,AhujaJ. Gynecol.2006;194(3):888–94.\\nUseofradiographyinacuteankleinjuries:physicians'attitudesandpractice. 77. vandenBoschJE,KalkmanCJ,VergouweY,VanKleiWA,BonselGJ,Grobbee\\nCMAJ.1992;147(11):1671–8. DE,MoonsKG.Assessingtheapplicabilityofscoringsystemsforpredicting\\n51. StiellIG,McKnightR,GreenbergGH,McDowellI,NairRC,WellsGA,etal. postoperativenauseaandvomiting.Anaesthesia.2005;60(4):323–31.\\nImplementationoftheOttawaanklerules.JAMA.1994;271(11):827–32. 78. HilbeJ.Logisticregressionmodels.BocaRaton:Chapman&Hall/CRC;2009.\\n52. AnisAH,StiellIG,StewartDG,LaupacisA.Cost-effectivenessanalysisofthe 79. MarshallRJ.Theuseofclassificationandregressiontreesinclinical\\nOttawaanklerules.AnnEmergMed.1995;26(4):422–8. epidemiology.JClinEpidemiol.2001;54(6):603–9.\\n53. GrahamID,StiellIG,LaupacisA,McAuleyL,HowellM,ClancyM,etal. 80. StiellIG,GreenbergGH,McKnightRD,NairRC,McDowellI,WorthingtonJR.\\nAwarenessanduseoftheOttawaankleandkneerulesin 5countries: Astudytodevelopclinicaldecisionrulesfortheuseofradiographyin\\ncanpublicationalonebeenough tochangepractice?AnnEmergMed. acuteankleinjuries.AnnEmergMed.1992;21(4):384–90.\\n2001;37(3):259–66. 81. TopolEJ.High-performancemedicine:theconvergenceofhumanand\\n54. DamenJA,HooftL,SchuitE,DebrayTP,CollinsGS,TzoulakiI,etal. artificialintelligence.NatMed.2019;25(1):44–56.\\nPredictionmodelsforcardiovasculardiseaseriskinthegeneralpopulation: 82. VollmerS,MateenBA,BohnerG,KirályFJ,GhaniR,JonssonP,etal.Machine\\nsystematicreview.BMJ.2016;353:i2416. learningandAIresearchforpatientbenefit:20criticalquestionson\\n55. ShariatSF,KarakiewiczPI,MargulisV,KattanMW.Inventoryofprostate transparency,replicability,ethicsandeffectiveness.CoRR.2018;abs/1812.10404.\\ncancerpredictivetools.CurrOpinUrol.2008;18(3):279–96. 83. VergouweY,RoystonP,MoonsKG,AltmanDG.Developmentand\\n56. PerelP,EdwardsP,WentzR,RobertsI.Systematicreviewofprognostic validationofapredictionmodelwithmissingpredictordata:apractical\\nmodelsintraumaticbraininjury.BMCMedInformDecisMak.2006;6:38. approach.JClinEpidemiol.2010;63(2):205–14.\\n57. WesslerBS,LaiYhL,KramerW,CangelosiM,RamanG,LutzJS,KentDM. 84. LittleRJA,RubinDB.Statisticalanalysiswithmissingdata.NewYork:Wiley;2002.\\nClinicalpredictionmodelsforcardiovasculardisease:tuftspredictive 85. SterneJAC,WhiteIR,CarlinJB,SprattM,RoystonP,KenwardMG,etal.\\nanalyticsandcomparativeeffectivenessclinicalpredictionmodeldatabase. Multipleimputationformissingdatainepidemiologicalandclinical\\nCircCardiovascQualOutcomes.2015;8(4):368–75. research:potentialandpitfalls.BMJ.2009;338:b2393.\\n58. GeersingGJ,BouwmeesterW,ZuithoffP,SpijkerR,LeeflangM,MoonsKG. 86. DondersART,vanderHeijdenGJMG,StijnenT,MoonsKGM.Review:a\\nSearchfiltersforfindingprognosticanddiagnosticpredictionstudiesin gentleintroductiontoimputationofmissingvalues.JClinEpidemiol.\\nMedlinetoenhancesystematicreviews.PLoSOne.2012;7(2):e32844. 2006;59(10):1087–91.\\n59. MoonsKG,deGrootJA,BouwmeesterW,VergouweY,MallettS, 87. MoonsKGM,DondersRART,StijnenT,HarrellFE.Usingtheoutcomefor\\nAltmanDG,etal. Criticalappraisalanddataextractionforsystematic imputationofmissingpredictorvalueswaspreferred.JClinEpidemiol.\\nreviewsofpredictionmodellingstudies:theCHARMSchecklist.PLoS 2006;59(10):1092–101.\\nMed. 2014;11(10):e1001744. 88. JanssenKJM,DondersART,HarrellFE,VergouweY,ChenQ,GrobbeeDE,\\n60. MoonsKM,WolffRF,RileyRD,WhitingPF,WestwoodM,CollinsGS,etal. MoonsKGM.Missingcovariatedatainmedicalresearch:toimputeisbetter\\nPROBAST:atooltoassessriskofbiasandapplicabilityofpredictionmodel thantoignore.JClinEpidemiol.2010;63(7):721–7.\\nstudies:explanationandelaboration.AnnInternMed.2019;170(1):W1–W33. 89. PedersenAB,MikkelsenEM,Cronin-FentonD,KristensenNR,PhamTM,\\n61. CollinsGS,MoonsKG.Comparingriskpredictionmodels.BMJ.2012;344:e3186. PedersenL,PetersenI.Missingdataandmultipleimputationinclinical\\n62. DekkerFW,RamspekCL,vanDiepenM.Con:mostclinicalriskscoresare epidemiologicalresearch.ClinEpidemiol.2017;9:157–66.\\nuseless.NephrolDialTransplant.2017;32(5):752–5. 90. vanderHeijdenGJMG,DondersAR,StijnenT,MoonsKGM.Imputationof\\n63. MasconiK,MatshaT,ErasmusR,KengneA.Recalibrationinvalidation missingvaluesissuperiortocompletecaseanalysisandthemissing-\\nstudiesofdiabetesriskpredictionmodels:asystematicreview.IntJStat indicatormethodinmultivariablediagnosticresearch:aclinicalexample.J\\nMedRes.2015;4(4):347–69. ClinEpidemiol.2006;59(10):1102–9.\\n64. BanJW,WallaceE,StevensR,PereraR.Whydoauthorsderivenew 91. RubinDB.Multipleimputationfornonresponseinsurveys.NewYork:Wiley;1987.\\ncardiovascularclinicalpredictionrulesinthepresenceofexistingrules?A 92. vanBuurenS,Groothuis-OudshoornK.Mice:multivariateimputationby\\nmixedmethodsstudy.PLoSOne.2017;12(6):e0179102. chainedequationsinR.JStatSoftw.2011;45(3):1–67.\\n65. deSalisI,WhitingP,SterneJA,HayAD. Usingqualitativeresearchto 93. WhiteIR,RoystonP,WoodAM.Multipleimputationusingchained\\ninformdevelopmentofadiagnosticalgorithmforUTIinchildren.Fam equations:issuesandguidanceforpractice.StatMed.2011;30(4):377–99.\\nPract.2013;30(3):325–31. 94. CollinsLM,SchaferJL,KamCM.Acomparisonofinclusiveandrestrictivestrategies\\n66. HaskinsR,OsmotherlyPG,SouthgateE,RivettDA.Australian inmodernmissingdataprocedures.PsycholMethods.2001;6(4):330–51.\\nphysiotherapists'prioritiesforthedevelopmentofclinicalpredictionrules 95. GrahamJW.Missingdataanalysis:makingitworkintherealworld.Annu\\nforlowbackpain:aqualitativestudy.Physiotherapy.2015;101(1):44–9. RevPsychol.2009;60:549–76.\\n67. PeatG,RileyRD,CroftP,MorleyKI,KyzasPA,MoonsKG,etal.Improving 96. CarpenterJR,KenwardMG,WhiteIR.Sensitivityanalysisaftermultiple\\nthetransparencyofprognosisresearch:theroleofreporting,datasharing, imputationundermissingatrandom:aweightingapproach.StatMethods\\nregistration,andprotocols.PLoSMed.2014;11(7):e1001671. MedRes.2007;16(3):259–75.\\n68. AltmanDG.Thetimehascometoregisterdiagnosticandprognostic 97. DemirtasH,SchaferJL.Ontheperformanceofrandom-coefficientpattern-\\nresearch.ClinChem.2014;60(4):580–2. mixturemodelsfornon-ignorabledrop-out.StatMed.2003;22(16):2553–75.\\n69. HanK,SongK,ChoiBW.Howtodevelop,validate,andcompareclinical 98. LeurentB,GomesM,FariaR,MorrisS,GrieveR,CarpenterJR.Sensitivity\\npredictionmodelsinvolvingradiologicalparameters:studydesignand analysisfornot-at-randommissingdataintrial-basedcost-effectiveness\\nstatisticalmethods.KoreanJRadiol.2016;17(3):339–50. analysis:atutorial.Pharmacoeconomics.2018;36(8):889–901.\\n70. LeeY-h,BangH,KimDJ.Howtoestablishclinicalpredictionmodels. 99. LeacyFP,FloydS,YatesTA,WhiteIR.Analysesofsensitivitytothemissing-\\nEndocrinolMetab(Seoul).2016;31(1):38–44. at-randomassumptionusingmultipleimputationwithdeltaadjustment:\\n71. BiesheuvelCJ,VergouweY,OudegaR,HoesAW,GrobbeeDE,MoonsKG. applicationtoatuberculosis/HIVprevalencesurveywithincompleteHIV-\\nAdvantagesofthenestedcase-controldesignindiagnosticresearch.BMC statusdata.AmJEpidemiol.2017;185(4):304–15.\\nMedResMethodol.2008;8:48. 100. Héraud-BousquetV,LarsenC,CarpenterJ,DesenclosJ-C,LeStratY.\\n72. SandersonJ,ThompsonSG,WhiteIR,AspelundT,PennellsL.Derivationand Practicalconsiderationsforsensitivityanalysisaftermultipleimputation\\nassessmentofriskpredictionmodelsusingcase-cohortdata.BMCMedRes appliedtoepidemiologicalstudieswithincompletedata.BMCMedRes\\nMethodol.2013;13:113. Methodol.2012;12:73.\\n73. NeeRJ,CoppietersMW.Interpretingresearchonclinicalpredictionrulesfor 101. CarpenterJR,KenwardMG.MARmethodsforquantitativedata.In:missing\\nphysiotherapytreatments.ManTher.2011;16(2):105–8. datainrandomisedcontrolledtrials—apracticalguide.Birmingham:\\n74. HancockM,HerbertRD,MaherCG.Aguidetointerpretationofstudies NationalInstituteforHealthResearch;2008.\\ninvestigatingsubgroupsofresponderstophysicaltherapyinterventions. 102. GoldsteinH,CarpenterJ,KenwardMG,LevinKA.Multilevelmodelswith\\nPhysTher.2009;89(7):698–704. multivariatemixedresponsetypes.StatModel.2009;9(3):173–97.\", 'Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page20of23\\n103. SchaferJL.Analysisofincompletemultivariatedata.London:Chapman 128. SteyerbergEW,UnoH,IoannidisJPA,vanCalsterB,UkaegbuC,DhingraT,\\n&Hall; 1997. etal.Poorperformanceofclinicalpredictionmodels:theharmof\\n104. DobsonA,DiggleP,HendersonR.Jointmodellingoflongitudinal commonlyappliedmethods.JClinEpidemiol.2018;98:133–43.\\nmeasurementsandeventtimedata.Biostatistics.2000;1(4):465–80. 129. RoystonP,SauerbreiW.Multivariablemodel-building:apragmaticapproach\\n105. RizopoulosD.Jointmodelsforlongitudinalandtime-to-eventdatawith toregressionanalysisbasedonfractionalpolynomialsformodelling\\napplicationsinR.NewYork:ChapmanandHall/CRC;2012. continuousvariables.Chichester:Wiley;2009.\\n106. MarshallA,AltmanDG,HolderRL,RoystonP.Combiningestimatesof 130. HarrellFEJ,LeeKL,PollockBG.Regressionmodelsinclinicalstudies:\\ninterestinprognosticmodellingstudiesaftermultipleimputation:current determiningrelationshipsbetweenpredictorsandresponse.JNatlCancer\\npracticeandguidelines.BMCMedResMethodol.2009;9:57. Inst.1988;80(15):1198–202.\\n107. MarshallA,AltmanDG,HolderRL.Comparisonofimputationmethodsfor 131. RoystonP,AltmanDG.Regressionusingfractionalpolynomialsof\\nhandlingmissingcovariatedatawhenfittingaCoxproportionalhazards continuouscovariates:parsimoniousparametricmodelling.JRStatSocSer\\nmodel:aresamplingstudy.BMCMedResMethodol.2010;10:112. CApplStat.1994;43(3):429–67.\\n108. KappenTH,vanKleiWA,vanWolfswinkelL,KalkmanCJ,VergouweY, 132. Ambler G,SeamanS,OmarRZ.Anevaluationofpenalisedsurvival\\nMoonsKGM.Evaluatingtheimpactofpredictionmodels:lessonslearned, methodsfordevelopingprognosticmodelswithrareevents.StatMed.\\nchallenges,andrecommendations.BMCDiagnPrognRes.2018;2:11. 2012;31(11–12):1150–61.\\n109. KappenTH,VergouweY,vanKleiWA,vanWolfswinkelL,KalkmanCJ, 133. LeCessieS,VanHouwelingenJC.Ridgeestimatorsinlogisticregression.JR\\nMoonsKGM.Adaptationofclinicalpredictionmodelsforapplicationin StatSocSerCApplStat.1992;41(1):191–201.\\nlocalsettings.MedDecisMak.2012;32(3):E1–E10. 134. TibshiraniR.Regressionshrinkageandselectionviathelasso.JRStatSoc\\n110. JanssenKJM,VergouweY,DondersART,HarrellFE,ChenQ,GrobbeeDE, SeriesBStatMethodol.1996;58(1):267–88.\\nMoonsKGM.Dealingwithmissingpredictorvalueswhenapplyingclinical 135. HosmerDW,JovanovicB,LemeshowS.Bestsubsetslogisticregression.\\npredictionmodels.ClinChem.2009;55(5):994–1001. Biometrics.1989;45(4):1265–70.\\n111. MasconiKL,MatshaTE,ErasmusRT,KengneAP.Effectsofdifferentmissing 136. MantelN.Whystepdownproceduresinvariableselection.\\ndataimputationtechniquesontheperformanceofundiagnoseddiabetes Technometrics.1970;12(3):621–5.\\nriskpredictionmodelsinamixed-ancestrypopulationofSouthAfrica.PLoS 137. MoonsKG,BiesheuvelCJ,GrobbeeDE.Testresearchversusdiagnostic\\nOne.2015;10(9):e0139210. research.ClinChem.2004;50(3):473–6.\\n112. SunGW,ShookTL,KayGL.Inappropriateuseofbivariableanalysistoscreen 138. SteyerbergEW,EijkemansMJC,HabbemaJDF.Stepwiseselectioninsmall\\nriskfactorsforuseinmultivariableanalysis.JClinEpidemiol.1996;49(8):907–16. datasets:asimulationstudyofbiasinlogisticregressionanalysis.JClin\\n113. SteyerbergEW,EijkemansMJC,HarrellFE,HabbemaJDF.Prognostic Epidemiol.1999;52(10):935–42.\\nmodelingwithlogisticregressionanalysis:insearchofasensiblestrategyin 139. SteyerbergEW,SchemperM,HarrellFE.Logisticregressionmodelingand\\nsmalldatasets.MedDecisMak.2001;21(1):45–56. thenumberofeventspervariable:selectionbiasdominates.JClin\\n114. HarrellFEJ,LeeKL,MarkDB.Multivariableprognosticmodels:issuesin Epidemiol.2011;64(12):1464–5.\\ndevelopingmodels,evaluatingassumptionsandadequacy,andmeasuring 140. WhittleR,PeatG,BelcherJ,CollinsGS,RileyRD.Measurementerrorandtiming\\nandreducingerrors.StatMed.1996;15(4):361–87. ofpredictorvaluesformultivariableriskpredictionmodelsarepoorlyreported.\\n115. ShmueliG.Toexplainortopredict?StatSci.2010;25(3):289–310. JClinEpidemiol.2018.https://doi.org/10.1016/j.jclinepi.2018.05.008.\\n116. PavlouM,AmblerG,SeamanSR,GuttmannO,ElliottP,KingM,OmarRZ. 141. LuijkenK,GroenwoldRHH,vanCalsterB,SteyerbergEW,vanSmedenM.\\nHowtodevelopamoreaccurateriskpredictionmodelwhentherearefew Impactofpredictormeasurementheterogeneityacrosssettingson\\nevents.BMJ.2015;351:h3868. performanceofpredictionmodels:ameasurementerrorperspective.arXiv:\\n117. HeinzeG,DunklerD. Fivemythsaboutvariableselection.TransplInt. 180610495[statME].2018:arXiv:1806.10495.\\n2017;30(1):6–10. 142. WorsterA,CarpenterC.Incorporationbiasinstudiesofdiagnostictests:\\n118. PeduzziP,ConcatoJ,KemperE,HolfordTR,FeinsteinAR.Asimulationstudy howtoavoidbeingbiasedaboutbias.CJEM.2008;10(2):174–5.\\nofthenumberofeventspervariableinlogisticregressionanalysis.JClin 143. MoonsKG,GrobbeeDE.When shouldweremainblindandwhen\\nEpidemiol.1996;49(12):1373–9. shouldoureyes remainopenindiagnosticstudies?JClinEpidemiol.\\n119. VittinghoffE,McCullochCE.Relaxingtheruleofteneventspervariablein 2002;55(7):633–6.\\nlogisticandcoxregression.AmJEpidemiol.2007;165(6):710–8. 144. WangLE,ShawPA,MathelierHM,KimmelSE,FrenchB.Evaluatingrisk-\\n120. Courvoisier DS, Combescure C, Agoritsas T, Gayet-Ageron A, Perneger predictionmodelsusingdatafromelectronichealthrecords.AnnApplStat.\\nTV. Performanceof logistic regression modeling: beyond thenumber 2016;10(1):286–304.\\nof events per variable, therole of data structure. J Clin Epidemiol. 145. vanDoornS,BrakenhoffTB,MoonsKGM,RuttenFH,HoesAW,\\n2011;64(9):993–1000. GroenwoldRHH,GeersingGJ.Theeffectsofmisclassificationinroutine\\n121. van Smeden M, deGroot JAH, Moons KGM, Collins GS, Altman DG, healthcaredatabases ontheaccuracyofprognosticpredictionmodels:\\nEijkemans MJC, Reitsma JB. No rationale for 1 variableper 10 events acasestudy oftheCHA2DS2-VAScscorein atrialfibrillation.BMC\\ncriterion for binary logistic regression analysis. BMC Med Res DiagnPrognRes.2017;1:18.\\nMethodol. 2016;16:163. 146. BleekerSE,MollHA,SteyerbergEW,DondersAR,Derksen-LubsenG,\\n122. vanSmedenM,MoonsKGM,deGrootJAH,CollinsGS,AltmanDG, GrobbeeDE,MoonsKG.Externalvalidationisnecessaryinprediction\\nEijkemansMJC,ReitsmaJB.Samplesizeforbinarylogisticprediction research:aclinicalexample.JClinEpidemiol.2003;56(9):826–32.\\nmodels:beyondeventspervariablecriteria.StatMethodsMedRes.2018. 147. JusticeAC,CovinskyKE,BerlinJA.Assessingthegeneralizabilityof\\nhttps://doi.org/10.1177/0962280218784726. prognosticinformation.AnnInternMed.1999;130(6):515–24.\\n123. OgundimuEO,AltmanDG,CollinsGS.Adequatesamplesizefordeveloping 148. TollDB,JanssenKJ,VergouweY,MoonsKG.Validation,updatingandimpact\\npredictionmodelsisnotsimplyrelatedtoeventspervariable.JClin ofclinicalpredictionrules:areview.JClinEpidemiol.2008;61(11):1085–94.\\nEpidemiol.2016;76:175–82. 149. SteyerbergEW,HarrellFEJr,BorsboomGJ,EijkemansMJ,VergouweY,\\n124. BattleCE,HutchingsH,EvansPA.Expertopinionoftheriskfactorsfor HabbemaJD.Internalvalidationofpredictivemodels:efficiencyofsome\\nmorbidityandmortalityinbluntchestwalltrauma:resultsofanational proceduresforlogisticregressionanalysis.JClinEpidemiol.2001;54(8):774–81.\\npostalquestionnairesurveyofemergencydepartmentsintheUnited 150. SteyerbergEW.Validationinpredictionresearch:thewastebydata-splitting.\\nKingdom.Injury.2013;44(1):56–9. JClinEpidemiol.2018.https://doi.org/10.1016/j.jclinepi.2018.07.010.\\n125. SauerbreiW,RoystonP,BinderH.Selectionofimportantvariablesand 151. EfronB,TibshiraniR.Anintroductiontothebootstrap.BocaRaton:\\ndeterminationoffunctionalformforcontinuouspredictorsinmultivariable Chapman&Hall/CRC;1993.\\nmodelbuilding.StatMed.2007;26(30):5512–28. 152. GerdsTA,CaiT,SchumacherM.Theperformanceofriskpredictionmodels.\\n126. RoystonP,AltmanDG,SauerbreiW.Dichotomizingcontinuouspredictorsin BiomJ.2008;50(4):457–79.\\nmultipleregression:abadidea.StatMed.2006;25(1):127–41. 153. AustinPC,SteyerbergEW.Graphicalassessmentofinternalandexternal\\n127. CollinsGS,OgundimuEO,CookJA,ManachYL,AltmanDG.Quantifyingthe calibrationoflogisticregressionmodelsbyusingloesssmoothers.StatMed.\\nimpactofdifferentapproachesforhandlingcontinuouspredictorsonthe 2014;33(3):517–35.\\nperformanceofaprognosticmodel.StatMed.2016;35(23):4124–35. 154. HosmerDW,LemeshowS.Appliedlogisticregression.NewYork:Wiley;2000.', \"Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page21of23\\n155. VanCalsterB,NieboerD,VergouweY,DeCockB,PencinaMJ,Steyerberg 181. IvanovJ,TuJV,NaylorCD.Ready-made,recalibrated,orremodeled?Issues\\nEW.Acalibrationhierarchyforriskmodelswasdefined:fromutopiato intheuseofriskindexesforassessingmortalityaftercoronaryarterybypass\\nempiricaldata.JClinEpidemiol.2016;74:167–76. graftsurgery.Circulation.1999;99(16):2098–104.\\n156. PencinaMJ,D'AgostinoRBS.Evaluatingdiscriminationofriskprediction 182. SteyerbergEW,BorsboomGJ,vanHouwelingen HC,EijkemansMJ,\\nmodels:theCstatistic.JAMA.2015;314(10):1063–4. HabbemaJD.Validationandupdatingofpredictivelogisticregression\\n157. HanleyJA,McNeilBJ.Themeaninganduseoftheareaunderareceiver models:astudyonsamplesizeandshrinkage.StatMed.2004;23(16):\\noperatingcharacteristic(ROC)curve.Radiology.1982;143(1):29–36. 2567–86.\\n158. BaronJA,SorensenHT.Clinicalepidemiology.In:OlsenJ,SaracciR, 183. DeLongER,DeLongDM,Clarke-PearsonDL.Comparingtheareasunder\\nTrichopoulosD,editors.Teachingepidemiology:aguideforteachersin twoormorecorrelatedreceiveroperatingcharacteristiccurves:a\\nepidemiology,publichealthandclinicalmedicine.NewYork:Oxford nonparametricapproach.Biometrics.1988;44(3):837–45.\\nUniversityPress;2010.p.411–28. 184. DemlerOV,PencinaMJ,D’AgostinoRBS.MisuseofDeLongtesttocompare\\n159. VanCalsterB,VickersAJ.Calibrationofriskpredictionmodels:impacton AUCsfornestedmodels.StatMed.2012;31(23):2577–87.\\ndecision-analyticperformance.MedDecisMak.2014;35(2):162–9. 185. PencinaMJ,D'AgostinoRBSr,D'AgostinoRBJr,VasanRS.Evaluatingthe\\n160. MeurerWJ,TollesJ.Logisticregressiondiagnostics:understandinghowwell addedpredictiveabilityofanewmarker:fromareaundertheROCcurveto\\namodelpredictsoutcomes.JAMA.2017;317(10):1068–9. reclassificationandbeyond.StatMed.2008;27(2):157–72.\\n161. ParikhR,MathaiA,Parikh S,ChandraSekharG,ThomasR. 186. VanCalsterB,VickersAJ,PencinaMJ,BakerSG,TimmermanD,\\nUnderstandingandusingsensitivity,specificityandpredictivevalues. SteyerbergEW.Evaluationofmarkersandriskpredictionmodels:\\nIndianJOphthalmol.2008;56(1):45–50. overviewofrelationshipsbetweenNRIanddecision-analyticmeasures.\\n162. SøreideK.Receiver-operatingcharacteristiccurveanalysisindiagnostic, MedDecisMak.2013;33(4):490–501.\\nprognosticandpredictivebiomarkerresearch.JClinPathol.2009;62(1):1–5. 187. LeeningMJ,SteyerbergEW,VanCalsterB,D’AgostinoRBSr,PencinaMJ.\\n163. EbellMH,LocatelliI,SennN.Anovelapproachtothedeterminationof Netreclassificationimprovementandintegrateddiscrimination\\nclinicaldecisionthresholds.BMJEvidBasedMed.2015;20(2):41–7. improvementrequirecalibratedmodels:relevancefromamarkerand\\n164. VickersAJ,ElkinEB.Decisioncurveanalysis:anovelmethodforevaluating modelperspective.StatMed.2014;33(19):3415–8.\\npredictionmodels.MedDecisMak.2006;26(6):565–74. 188. LeeningMJ,VedderMM,WittemanJC,PencinaMJ, SteyerbergEW.Net\\n165. BakerSG,CookNR,VickersA,KramerBS.Usingrelativeutilitycurvesto reclassificationimprovement:computation,interpretation,and\\nevaluateriskprediction.JRStatSocSerAStatSoc.2009;172(4):729–48. controversies:aliteraturereviewandclinician'sguide. AnnInternMed.\\n166. VickersAJ,VanCalsterB,SteyerbergEW.Netbenefitapproaches tothe 2014;160(2):122–31.\\nevaluationofpredictionmodels,molecularmarkers,anddiagnostic 189. PepeMS,FanJ,FengZ,GerdsT,HildenJ.Thenetreclassificationindex\\ntests.BMJ.2016;352:i6. (NRI):amisleadingmeasureofpredictionimprovementevenwith\\n167. FeldsteinDA,HessR,McGinnT,MishurisRG,McCullaghL,SmithPD,etal. independenttestdatasets.StatBiosci.2015;7(2):282–95.\\nDesignandimplementationofelectronichealthrecordintegratedclinical 190. BurchPM,GlaabWE,HolderDJ,PhillipsJA,SauerJM,WalkerEG.Net\\npredictionrules(iCPR):arandomizedtrialindiverseprimarycaresettings. reclassificationindexandintegrateddiscriminationindexarenot\\nImplementSci.2017;12(1):37. appropriatefortestingwhetherabiomarkerimprovespredictive\\n168. VanBelleV,VanCalsterB.Visualizingriskpredictionmodels.PLoSOne. performance.ToxicolSci.2017;156(1):11–3.\\n2015;10(7):e0132614. 191. HildenJ,GerdsTA.Anoteontheevaluationofnovelbiomarkers:donot\\n169. SullivanLM,MassaroJM,D'AgostinoRB.Presentationofmultivariate relyonintegrateddiscriminationimprovementandnetreclassification\\ndataforclinicaluse:theFraminghamstudyriskscorefunctions.Stat index.StatMed.2014;33(19):3405–14.\\nMed. 2004;23(10):1631–60. 192. AntoliniL,TassistroE,ValsecchiMG,BernasconiDP.Graphical\\n170. ColeTJ.AlgorithmAS281:scalingandroundingregressioncoefficientsto representationsandsummaryindicatorstoassesstheperformanceofrisk\\nintegers.JRStatSocSerCApplStat.1993;42(1):261–8. predictors.BiomJ.2018.https://doi.org/10.1002/bimj.201700186.\\n171. MaguireJL,KulikDM,Laupacis A,KuppermannN,UlerykEM,ParkinPC. 193. Siontis GC,TzoulakiI,SiontisKC,Ioannidis JP.Comparisonsof\\nClinicalpredictionrulesforchildren:asystematicreview.Pediatrics. establishedriskpredictionmodels forcardiovasculardisease:systematic\\n2011;128(3):e666–e77. review.BMJ. 2012;344:e3318.\\n172. KeoghC,WallaceE,O'BrienKK,GalvinR,SmithSM,LewisC,etal. 194. CookNR.Quantifyingtheaddedvalueofnewbiomarkers:howandhow\\nDevelopinganinternationalregisterofclinicalpredictionrulesforusein not.BMCDiagnPrognRes.2018;2:14.\\nprimarycare:adescriptiveanalysis.AnnFamMed.2014;12(4):359–66. 195. FerrantediRuffanoL,HydeCJ,McCafferyKJ,BossuytPMM,DeeksJJ.\\n173. StiellIG,GreenbergGH,WellsGA,McDowellI,CwinnAA,SmithNA,etal. Assessingthevalueofdiagnostictests:aframeworkfordesigningand\\nProspectivevalidationofadecisionrulefortheuseofradiographyinacute evaluatingtrials.BMJ.2012;344:e686.\\nkneeinjuries.JAMA.1996;275(8):611–5. 196. WhiteH.Theory-basedimpactevaluation:principlesandpractice.JDev\\n174. Vergouwe Y, Steyerberg EW, Eijkemans MJC, Habbema JDF. Effect.2009;1(3):271–84.\\nSubstantial effective sample sizes wererequired for external validation 197. MooreGF,AudreyS,BarkerM,BondL,BonellC,HardemanW,etal.Process\\nstudies of predictive logistic regression models. J Clin Epidemiol. evaluationofcomplexinterventions:MedicalResearchCouncilguidance.\\n2005;58(5):475–83. BMJ.2015;350:h1258.\\n175. CollinsGS,OgundimuEO,AltmanDG.Samplesizeconsiderationsforthe 198. DowdingD,LichtnerV,ClossSJ.UsingtheMRCframeworkforcomplex\\nexternalvalidationofamultivariableprognosticmodel:aresamplingstudy. interventionstodevelopclinicaldecisionsupport:acasestudy.StudHealth\\nStatMed.2016;35(2):214–26. TechnolInform.2017;235:544-8.\\n176. VergouweY,MoonsKGM,SteyerbergEW.Externalvalidityofriskmodels: 199. NobleD,MathurR,DentT,MeadsC,GreenhalghT.Riskmodelsandscores\\nuseofbenchmarkvaluestodisentangleacase-mixeffectfromincorrect fortype2diabetes:systematicreview.BMJ.2011;343:d7163.\\ncoefficients.AmJEpidemiol.2010;172(8):971–80. 200. BrownB,Cheraghi-SohiS,JakiT,SuT-L,BuchanI,SperrinM.Understanding\\n177. vanKlaverenD,GönenM,SteyerbergEW,VergouweY.Anewconcordance clinicalpredictionmodelsas‘innovations’:amixedmethodsstudyinUK\\nmeasureforriskpredictionmodelsinexternalvalidationsettings.StatMed. familypractice.BMCMedInformDecisMak.2016;16:106.\\n2016;35(23):4136–52. 201. CraigP,DieppeP,MacintyreS,MichieS,NazarethI,PetticrewM.\\n178. BanJ-W,StevensR,PereraR.Predictorsforindependentexternalvalidation Developingandevaluatingcomplexinterventions:thenewMedical\\nofcardiovascularriskclinicalpredictionrules:coxproportionalhazards ResearchCouncilguidance.BMJ.2008;337:a1655.\\nregressionanalyses.BMCDiagnPrognRes.2018;2:3. 202. LeeTH.Evaluatingdecisionaids.JGenInternMed.1990;5(6):528–9.\\n179. SiontisGCM,TzoulakiI,CastaldiPJ,IoannidisJPA.Externalvalidationofnew 203. KappenTH,VergouweY,vanWolfswinkelL,KalkmanCJ,MoonsKG,vanKlei\\nriskpredictionmodelsisinfrequentandrevealsworseprognostic WA.Impactofaddingtherapeuticrecommendationstoriskassessments\\ndiscrimination.JClinEpidemiol.2015;68(1):25–34. fromapredictionmodelforpostoperativenauseaandvomiting.BrJ\\n180. JanssenKJM,MoonsKGM,KalkmanCJ,GrobbeeDE,VergouweY.Updating Anaesth.2015;114(2):252–60.\\nmethodsimprovedtheperformanceofaclinicalpredictionmodelinnew 204. MichieS,JohnstonM.Changingclinicalbehaviourbymakingguidelines\\npatients.JClinEpidemiol.2008;61(1):76–86. specific.BMJ.2004;328(7435):343–5.\", 'Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page22of23\\n205. WallaceE,UijenMJM,ClyneB,ZarabzadehA,KeoghC,GalvinR,etal. 228. ReillyBM,EvansAT,SchaiderJJ,WangY.Triageofpatientswithchestpain\\nImpactanalysisstudiesofclinicalpredictionrulesrelevanttoprimarycare:a intheemergencydepartment:acomparativestudyofphysicians\\'decisions.\\nsystematicreview.BMJOpen.2016;6(3):e009957. AmJMed.2002;112(2):95–103.\\n206. SandersSL,RathboneJ,BellKJL,GlasziouPP,DoustJA.Systematicreviewof 229. BroekhuizenBD,SachsA,JanssenK,GeersingGJ,MoonsK,HoesA,Verheij\\ntheeffectsofcareprovidedwithandwithoutdiagnosticclinicalprediction T.Doesadecisionaidhelpphysicianstodetectchronicobstructive\\nrules.BMCDiagnPrognRes.2017;1:13. pulmonarydisease?BrJGenPract.2011;61(591):e674–e79.\\n207. KappenT,PeelenLM.Predictionmodels:therighttoolfortheright 230. SchrigerDL,NewmanDH.Medicaldecisionmaking:let\\'snotforgetthe\\nproblem.CurrOpinAnesthesiol.2016;29(6):717–26. physician.AnnEmergMed.2012;59(3):219–20.\\n208. CampbellMK,ElbourneDR,AltmanDG.CONSORTstatement:extensionto 231. FinnertyN,RodriguezR,CarpenterC,SunB,TheyyunniN,OhleR,etal.\\nclusterrandomisedtrials.BMJ.2004;328(7441):702–8. Clinicaldecisionrulesfordiagnosticimagingintheemergencydepartment:\\n209. HemmingK,HainesTP,ChiltonPJ, GirlingAJ, LilfordRJ. Thestepped aresearchagenda.AcadEmergMed.2015;22(12):1406–16.\\nwedgeclusterrandomisedtrial:rationale,design,analysis,and 232. SandersS,DoustJ, GlasziouP.Asystematicreviewofstudies\\nreporting.BMJ. 2015;350:h391. comparingdiagnosticclinical predictionruleswithclinicaljudgment.\\n210. PoldervaartJM,ReitsmaJB,KoffijbergH,BackusBE,SixAJ,DoevendansPA, PLoSOne.2015;10(6):e0128233.\\nHoesAW.TheimpactoftheHEARTriskscoreintheearlyassessmentof 233. CowleyLE,FarewellDM,KempAM.Potentialimpactofthevalidated\\npatientswithacutechestpain:designofasteppedwedge,cluster predictingabusiveheadtrauma(PredAHT)clinicalpredictiontool:aclinical\\nrandomisedtrial.BMCCardiovascDisord.2013;13:77. vignettestudy.ChildAbuseNegl.2018;86:184–96.\\n211. HayesRJ,MoultonLH.Clusterrandomisedtrials.BocaRaton:CRCPress;2017. 234. PetrouS,GrayA.Economicevaluationusingdecisionanalyticalmodelling:\\n212. CampbellMK,ElbourneDR,AltmanDG.CONSORTgroup.CONSORT design,conduct,analysis,andreporting.BMJ.2011;342:d1766.\\nstatement:extensiontoclusterrandomisedtrials.BMJ.2004;328(7441): 235. GrimshawJ,ShirranL,ThomasR,MowattG,FraserC,BeroL,etal.Changing\\n702–8. providerbehavior:anoverviewofsystematicreviewsofinterventions.Med\\n213. RutterfordC,CopasA,EldridgeS.Methodsforsamplesizedeterminationin Care.2001;39(8Suppl2):II2–II45.\\nclusterrandomizedtrials.IntJEpidemiol.2015;44(3):1051–67. 236. StiellIG,BennettC.Implementationofclinicaldecisionrulesinthe\\n214. HemmingK,EldridgeS,ForbesG,WeijerC,TaljaardM.Howtodesign emergencydepartment.AcadEmergMed.2007;14(11):955–9.\\nefficientclusterrandomisedtrials.BMJ.2017;358:j3064. 237. CameronC,NaylorCD.NoimpactfromactivedisseminationoftheOttawa\\n215. SchaafsmaJD,vanderGraafY,RinkelGJ,BuskensE.Decisionanalysisto anklerules:furtherevidenceoftheneedforlocalimplementationof\\ncompletediagnosticresearchbyclosingthegapbetweentest practiceguidelines.CMAJ.1999;160(8):1165–8.\\ncharacteristicsandcost-effectiveness.JClinEpidemiol.2009;62(12):1248–52. 238. DavisDA,Taylor-VaiseyA.Translatingguidelinesintopractice.A\\n216. KoffijbergH,vanZaaneB,MoonsKG.Fromaccuracytopatientoutcome systematicreviewoftheoreticconcepts,practicalexperienceand\\nandcost-effectivenessevaluationsofdiagnostictestsandbiomarkers:an researchevidenceintheadoptionofclinicalpracticeguidelines.CMAJ.\\nexemplarymodellingstudy.BMCMedResMethodol.2013;13:12. 1997;157(4):408–16.\\n217. SiontisKC,SiontisGC,Contopoulos-IoannidisDG,IoannidisJP.Replyto 239. KatzMH.Integratingpredictionrulesintoclinicalworkflow.JAMAIntern\\nletterbyFerrantediRuffanoetal.:patientoutcomesinrandomized Med2013;173(17):1591–91.\\ncomparisonsofdiagnostictestsarestilltheultimatejudge.JClinEpidemiol. 240. BoutisK,ConstantineE,SchuhS,PecaricM,StephensD,NarayananUG.\\n2016;69:267–8. Pediatricemergencyphysicianopinionsonankleradiographclinical\\n218. MoherD,HopewellS,SchulzKF,MontoriV,GøtzschePC,DevereauxPJ,et decisionrules.AcadEmergMed.2010;17(7):709–17.\\nal.CONSORT2010explanationandelaboration:updatedguidelinesfor 241. PluddemannA,WallaceE,BankheadC,KeoghC,VanderWindtD,\\nreportingparallelgrouprandomisedtrials.BMJ.2010;340:c869. LassersonD,etal.Clinicalpredictionrulesinpractice:reviewofclinical\\n219. ReillyBM,EvansAT,Schaider JJ, DasK,CalvinJE,MoranLA,etal. guidelinesandsurveyofGPs.BrJGenPract.2014;64(621):e233–e42.\\nImpactofaclinicaldecisionruleonhospitaltriageofpatientswith 242. KappenTH,vanLoonK,KappenMA,vanWolfswinkelL,VergouweY,van\\nsuspectedacutecardiacischemiain theemergencydepartment.JAMA. KleiWA,etal.Barriersandfacilitatorsperceivedbyphysicianswhenusing\\n2002;288(3):342–50. predictionmodelsinpractice.JClinEpidemiol.2016;70:136–45.\\n220. CowleyLE,MaguireS,FarewellDM,Quinn-ScogginsHD,FlynnMO,Kemp 243. KeoghC,FaheyT.Clinicalpredictionrulesinprimarycare:whatcanbe\\nAM.Acceptabilityofthepredictingabusiveheadtrauma(PredAHT)clinical donetomaximisetheirimplementation?ClinEvid.2010.https://core.ac.uk/\\npredictiontool:aqualitativestudywithchildprotectionprofessionals.Child download/pdf/60774649.pdf.Accessed12June2018.\\nAbuseNegl.2018;81:192–205. 244. RunyonMS,RichmanPB,KlineJA.Emergencymedicinepractitioner\\n221. BallardDW,RauchwergerAS,ReedME,VinsonDR,MarkDG,OffermanSR,et knowledgeanduseofdecisionrulesfortheevaluationofpatientswith\\nal.Emergencyphysicians\\'knowledgeandattitudesofclinicaldecision suspectedpulmonaryembolism:variationsbypracticesettingandtraining\\nsupportintheelectronichealthrecord:asurvey-basedstudy.AcadEmerg level.AcadEmergMed.2007;14(1):53–7.\\nMed.2013;20(4):352–60. 245. PearsonSD,GoldmanL,GarciaTB,CookEF,LeeTH.Physicianresponsetoa\\n222. JohnsonEL,HollenLI,KempAM,MaguireS.Exploringtheacceptabilityofa predictionruleforthetriageofemergencydepartmentpatientswithchest\\nclinicaldecisionruletoidentifypaediatricburnsduetochildabuseor pain.JGenInternMed.1994;9(5):241–7.\\nneglect.EmergMedJ.2016;33(7):465–70. 246. BrehautJC,StiellIG,VisentinL,GrahamID.Clinicaldecisionrules\"inthereal\\n223. MullenS,Quinn-ScogginsHD,NuttallD,KempAM.Qualitativeanalysisof world\":howawidelydisseminatedruleisusedineverydaypractice.Acad\\nclinicianexperienceinutilisingtheBuRNtool(burnsriskassessmentfor EmergMed.2005;12(10):948–56.\\nneglectorabusetool)inclinicalpractice.Burns.2018;44(7):1759–66. 247. BrehautJC,StiellIG,GrahamID.Willanewclinicaldecisionrulebewidely\\n224. HaskinsR,OsmotherlyPG,SouthgateE,RivettDA.Physiotherapists\\' used?ThecaseoftheCanadianC-spinerule.AcadEmergMed.2006;13(4):\\nknowledge,attitudesandpracticesregardingclinicalpredictionrulesfor 413–20.\\nlowbackpain.ManTher.2014;19(2):142–51. 248. GrahamID,StiellIG,LaupacisA,O\\'ConnorAM,WellsGA.Emergency\\n225. KellyJ,SterlingM,RebbeckT,BandongAN,LeaverA,MackeyM,RitchieC. physicians\\'attitudestowardanduseofclinicaldecisionrulesfor\\nHealthpractitioners\\'perceptionsofadoptingclinicalpredictionrulesinthe radiography.AcadEmergMed.1998;5(2):134–40.\\nmanagementofmusculoskeletalpain:aqualitativestudyinAustralia.BMJ 249. EichlerK,ZollerM,TschudiP,SteurerJ.Barrierstoapplycardiovascular\\nOpen.2017;7(8):e015916. predictionrulesinprimarycare:apostalsurvey.BMCFamPract.2007;8:1.\\n226. AtabakiSM,HoyleJDJ,SchunkJE,MonroeDJ,AlpernER,QuayleKS,etal. 250. BeutelBG,TrehanSK,ShalvoyRM,MelloMJ.TheOttawakneerule:\\nComparisonofpredictionrulesandcliniciansuspicionforidentifying examininguseinanacademicemergencydepartment.WestJEmergMed.\\nchildrenwithclinicallyimportantbraininjuriesafterbluntheadtrauma. 2012;13(4):366–72.\\nAcadEmergMed.2016;23(5):566–75. 251. SheehanB,NigrovicLE,DayanPS,KuppermannN,BallardDW,\\n227. MahajanP,KuppermannN,TunikM,YenK,AtabakiSM,LeeLK,etal. AlessandriniE,etal.Informingthedesignofclinicaldecisionsupport\\nComparisonofcliniciansuspicionversusaclinicalpredictionrulein servicesforevaluationofchildrenwithminorbluntheadtraumainthe\\nidentifyingchildrenatriskforintra-abdominalinjuriesafterblunttorso emergencydepartment:asociotechnicalanalysis.JBiomedInform.\\ntrauma.AcadEmergMed.2015;22(9):1034–41. 2013;46(5):905–13.', \"Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page23of23\\n252. vanderSteenJT,AlbersG,Licht-StrunkE,MullerMT,RibbeMW.Avalidated\\nriskscoretoestimatemortalityriskinpatientswithdementiaand\\npneumonia:barrierstoclinicalimpact.IntPsychogeriatr.2011;23(1):31–43.\\n253. SandersS.Clinicalpredictionrulesforassistingdiagnosis(doctoralthesis).\\nAustralia:FacultyofHeathSciences&Medicine,BondUniversity;2015.\\n254. CabanaMD,RandCS,PoweNR,WuAW,WilsonMH,AbboudPA,RubinHR.\\nWhydon'tphysiciansfollowclinicalpracticeguidelines?Aframeworkfor\\nimprovement.JAMA.1999;282(15):1458–65.\"]}\n"
     ]
    }
   ],
   "source": [
    "# Testing extract (pdfplumber)\n",
    "src_dir = \"D:\\SingHealth\\Week 4\"\n",
    "extractor_type = \"pdfplumber\"\n",
    "pdf_path = \"41512_2019_Article_60.pdf\"\n",
    "\n",
    "# Create an instance of the PDFExtractor class\n",
    "extractor = PDFExtractor(src_dir)\n",
    "\n",
    "# Test the extract method\n",
    "result = extractor.extract(extractor_type, pdf_path)\n",
    "\n",
    "# Print or inspect the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1:\n",
      "REVIEW Open Access\n",
      "Methodological standards for the\n",
      "development and evaluation of clinical\n",
      "prediction rules: a review of the literature\n",
      "Laura E. Cowley*, Daniel M. Farewell, Sabine Maguire and Alison M. Kemp\n",
      "Abstract\n",
      "Clinical prediction rules (CPRs) that predic t the absolute risk of a clini cal condition or future outc ome for individual patients\n",
      "are abundant in the medical literature; however, syste matic reviews have demonstrated shortcomings in the\n",
      "methodological quality a nd reporting of prediction studies. To maximise t he potential and clinical usefulness of CPRs, they\n",
      "must be rigorously developed and vali dated, and their impact on clinical practice and patient outcomes must be\n",
      "evaluated. This review aims to present a comprehensive overv iew of the stages involved in the development, validation\n",
      "and evaluation of CPRs, and to describe in detail the methodol ogical standards required at each stage, illustrated with\n",
      "examples where appropriate. Important features of the study desi gn, statistical analysis, model ling strategy, data collection,\n",
      "performance assessment, CPR presentation and reporting are di scussed, in addition to other, often overlooked aspects such\n",
      "as the acceptability, cost-effectiveness and longer-term implementation of CPRs, and their comparison with clinical\n",
      "judgement. Although the development and evaluation of a robust, clinically useful CPR is anything but straightforward,\n",
      "adherence to the plethora of methodological standards, recommendations and frameworks at each stage will assist in the\n",
      "development of a rigorous CPR that has the potential to contri bute usefully to clinical prac tice and decision-making and\n",
      "have a positive impact on patient care.\n",
      "Keywords: Clinical prediction rule, Prediction model, Risk model, Model development, Model validation, Impact studies,\n",
      "Model reporting, Implementation, Diagnosis, Prognosis, Study design\n",
      "Background\n",
      "The aim of a clinical prediction rule (CPR) is to estimate\n",
      "the probability of a clinical condition or a future outcome\n",
      "by considering a small numbe r of highly valid indicators [ 1,\n",
      "2]. CPRs include three or more predictors, from patients ’\n",
      "clinical findings, history or investigation results [ 3]. Their\n",
      "purpose is to assist clinicians in making decisions under\n",
      "conditions of uncertainty and enhance diagnostic, prognos-\n",
      "tic or therapeutic accuracy an d decision-making, with the\n",
      "ultimate aim of improving the quality of patient care [ 1,2,\n",
      "4]. The predicted probabilities from a CPR allow clinicians\n",
      "to stratify patients into risk groups and help them to decide\n",
      "whether further assessment or treatment is necessary [ 5].\n",
      "Some CPRs can help to ‘rule in ’a condition by identifying\n",
      "patients who are very likely to have a condition and who\n",
      "thus require additional diagnostic testing or treatment,whilst others aim to ‘rule out ’a condition by identifying pa-\n",
      "t i e n t sw h oa r ev e r yu n l i k e l yt oh a v eac o n d i t i o n ,t h u sr e d u -\n",
      "cing unnecessary testing without compromising patient\n",
      "care [ 2,4]. CPRs that aim to predict the probability of a\n",
      "condition being present are termed diagnostic orscreening\n",
      "rules; those that aim to predict the probability of a future\n",
      "outcome are termed prognostic rules; and those that aim to\n",
      "predict the probability that a specific treatment or interven-\n",
      "tion will be effective are termed prescriptive rules [ 2].\n",
      "To maximise the predictive accuracy and clinical util-\n",
      "ity of CPRs, it is vital that they are rigorously developed,\n",
      "validated and evaluated. However, numerous systematic\n",
      "reviews have demonstrated shortcomings in the meth-\n",
      "odological quality and reporting of prediction studies,\n",
      "which restricts the CPR ’s usefulness in practice [ 6–15].\n",
      "Methodological standards for the development of CPRs\n",
      "were originally outlined by Wasson and colleagues [ 16].\n",
      "With the increase in popularity of CPRs inspired by the\n",
      "evidence-based medicine movement, these standards\n",
      "© The Author(s). 2019 Open Access This article is distributed under the terms of the Creative Commons Attribution 4.0\n",
      "International License ( http://creativecommons.org/licenses/by/4.0/ ), which permits unrestricted use, distribution, and\n",
      "reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to\n",
      "the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver\n",
      "(http://creativecommons.org/publicdomain/zero/1.0/ ) applies to the data made available in this article, unless otherwise stated.* Correspondence: CowleyLE@cardiff.ac.uk\n",
      "Division of Population Medicine, School of Medicine, Neuadd Meirionnydd,\n",
      "Heath Park, Cardiff University, Wales CF14 4YS, UKDiagnostic an d\n",
      "Prognostic ResearchCowley et al. Diagnostic and Prognostic Research            (2019) 3:16 \n",
      "https://doi.org/10.1186/s41512-019-0060-y\n",
      "\n",
      "Page 2:\n",
      "have since been modified and updated by a number of\n",
      "authors over the years [ 3,4,17–19]. Experts have pro-\n",
      "vided thorough and accessible overviews of the princi-\n",
      "ples and methods involved in conducting diagnostic and\n",
      "prognostic research [ 20–32] and devised frameworks to\n",
      "enhance the conduct and interpretation of prediction\n",
      "studies [ 33–35]. They have also provided guidance and\n",
      "recommendations for researchers to consider when de-\n",
      "veloping and evaluating CPRs, without aiming to dictate\n",
      "how analyses should be conducted. These recognise that\n",
      "there is no clear consensus on many aspects of model\n",
      "development, that the field is continually evolving and\n",
      "that methodological standards will therefore require up-\n",
      "dating accordingly [ 36]. Guidelines for the reporting of\n",
      "clinical prediction research have also been developed,\n",
      "namely the Transparent Reporting of a multivariable\n",
      "prediction model for Individual Prognosis or Diagnosis\n",
      "(TRIPOD) guidelines [ 36].\n",
      "This review aims to outline the stages and methodo-\n",
      "logical standards involved in the development and evalu-\n",
      "ation of CPRs, illustrated with examples where appropriate.\n",
      "Terminology used in this review\n",
      "In the literature, the term ‘clinical prediction rule ’is used\n",
      "interchangeably with the terms clinical prediction tool\n",
      "[37], clinical decision rule [ 17], clinical decision tool [ 38],\n",
      "clinical prediction algorithm [ 39], prognostic score [ 40],\n",
      "prognostic model [ 21], risk prediction model [ 23], risk\n",
      "model [ 30], risk score [ 41], scoring tool [ 42], scoring sys-\n",
      "tem [ 43]o rr i s ki n d e x[ 44]. Reilly and Evans [ 32]d i s t i n -\n",
      "guish between assistive prediction rules that simply\n",
      "provide clinicians with diagnostic or prognostic predicted\n",
      "probabilities without recommending a specific clinical\n",
      "course of action, and directive decision rules that explicitly\n",
      "suggest additional diagnostic tests or treatment in line\n",
      "with the obtained score. Decision rules intend to directly\n",
      "influence clinician behaviour, while prediction rules intend\n",
      "to help clinicians predict risk without providing recom-\n",
      "mendations, with the assumption that accurate predic-\n",
      "tions will lead to better decisions [ 32]. Some researchers\n",
      "also distinguish between prediction models that provide\n",
      "predicted probabilities along the continuum between cer-\n",
      "tified impossibility ( Pi= 0) and absolute certainty ( Pi=1 )\n",
      "[45], and prediction rules that classify patients into risk\n",
      "groups, by applying a clinically relevant cut-off that bal-\n",
      "ances the likelihood of benefit with the likelihood of harm\n",
      "[19,46]. Such cut-offs are known as ‘decision thresholds ’;\n",
      "a threshold must be applied if a prediction model aims to\n",
      "influence decision-making [ 19]. In this review, the term\n",
      "‘clinical prediction rule ’is used to refer to diagnostic,\n",
      "prognostic or prescriptive rules/models derived from mul-\n",
      "tivariable statistical analyses, which predict the probability\n",
      "of a condition or outcome, with or without the use of a\n",
      "clinical cut-off or recommendation for further action.Stages in the development of clinical prediction\n",
      "rules\n",
      "It is widely acknowledged in the literature that there are\n",
      "three main stages in the development of CPRs (Fig. 1);\n",
      "derivation; external validation; and impact analysis to de-\n",
      "termine their impact on patient care [ 4,20,22–25,32,\n",
      "33]. Stiell and Wells [ 17] identified a further three im-\n",
      "portant stages, namely identifying the need for a CPR,\n",
      "determining the cost-effectiveness of a CPR and\n",
      "long-term dissemination and implementation of a CPR.\n",
      "Therefore all six stages are summarised in Table 1and\n",
      "discussed in detail below.\n",
      "Detailed methodological and practical recommendations\n",
      "pertaining to the three main stages of development have\n",
      "been published, as each requires a different methodo-\n",
      "logical approach [ 3,4,16–36]. These three stages also cor-\n",
      "respond to increasing hierarchies of evidence, as outlined\n",
      "in Table 2[4,32,33]. A CPR that has been derived ,b u t\n",
      "not externally validated, corresponds to the lowest level of\n",
      "evidence and is not recommended for use in clinical prac-\n",
      "tice, except arguably in rare instances when a CPR is de-\n",
      "veloped for use in only one setting. It has been suggested\n",
      "that a CPR that has been successfully externally validated\n",
      "in a setting, or population, similar to the one from which\n",
      "it was derived ( ‘narrow ’validation), can be used cautiously\n",
      "in similar future patients [ 32]. Similarly, it is proposed that\n",
      "a CPR should be consistently successfully externally vali-\n",
      "dated in multiple settings or populations ( ‘broad ’valid-\n",
      "ation), before clinicians can use its predictions confidently\n",
      "in future patients [ 32]. Finally, it is recommended that an\n",
      "impact analysis is conducted and that the CPR demon-\n",
      "strates improvements to patient care, before it can be used\n",
      "as a decision rule for the management and treatment of\n",
      "patients [ 32]. Ideally, the impact of a CPR should also be\n",
      "tested in multiple settings. Impact analysis studies corres-\n",
      "pond to the highest level of evidence [ 32].\n",
      "Stage 1: identifying the need for a clinical prediction rule\n",
      "Before developing a CPR, researchers need to ensure\n",
      "that there is a clinical need for the rule. CPRs are most\n",
      "valuable when decision-making is challenging, when\n",
      "there is evidence that clinicians are failing to accurately\n",
      "diagnose a condition, and when there are serious conse-\n",
      "quences associated with an incorrect diagnosis [ 2,4].\n",
      "CPRs are also valuable when there is a need to simplify\n",
      "or speed up the diagnostic or triage process, for example\n",
      "in patients presenting to the emergency department with\n",
      "chest pain and suspected acute cardiac ischaemia [ 49].\n",
      "CPRs are most likely to be adopted into clinical practice,\n",
      "and to demonstrate improvements in patient care and\n",
      "reductions in health care costs, when they improve the\n",
      "overall efficiency of clinical practice [ 17]. For example,\n",
      "ankle injuries are frequently seen in the emergency de-\n",
      "partment. Prior to the implementation of the OttawaCowley et al. Diagnostic and Prognostic Research            (2019) 3:16 Page 2 of 23\n",
      "\n",
      "Page 3:\n",
      "Ankle Rule, clinicians ordered a high proportion of radio-\n",
      "graphs that were negative for fracture, when the majority\n",
      "of them believed that a fracture was highly unlikely [ 50].\n",
      "The rule was found to lead to a reduction in both radiog-\n",
      "raphy [ 51] and health care costs [ 52], and in one survey\n",
      "70% of Canadian and UK emergency department clini-\n",
      "cians reported frequent use of the rule [ 53].\n",
      "Before developing a CPR, researchers should consider\n",
      "whether a new CPR is needed, as many are developed for\n",
      "the same target population or to predict the same out-\n",
      "come [ 8,10,11,54–57]. The characteristics, performance\n",
      "and level of evidence of existing CPRs should be systemat-\n",
      "ically reviewed using validated search filters for locating\n",
      "prediction studies, and the Critical Appraisal and Data Ex-\n",
      "traction for Systematic Reviews of prediction modelling\n",
      "studies (CHARMS) checklist [ 58,59]. The recently pub-\n",
      "lished Prediction model Risk Of Bias ASsessment Tool\n",
      "(PROBAST) can be used to assess the risk of bias and ap-\n",
      "plicability of CPRs [ 60]. Researchers can also assess the\n",
      "performance of existing CPRs on their own collected data\n",
      "[61]. Existing CPRs with potential should be updated, vali-\n",
      "dated or tested in an impact study before a new CPR is de-\n",
      "veloped [ 54,62,63]. If a new CPR is derived, researchers\n",
      "should clearly justify why it is required, with reference to\n",
      "existing CPRs, to avoid research waste and duplication of\n",
      "efforts [ 64]. Qualitative research with clinicians can be\n",
      "useful in determining whether a proposed CPR is clinically\n",
      "relevant, and to assess the credibility of the proposed pre-\n",
      "dictor variables [ 65,66].\n",
      "Stage 2: derivation of a clinical prediction rule according\n",
      "to methodological standards\n",
      "Once a need for a new CPR is established, and a re-\n",
      "searcher has an appropriate clinical question, a CPR must\n",
      "be derived according to strict methodological standards\n",
      "[23]. There are various elements to consider, pertaining to\n",
      "the study design, statistical techniques employed and the\n",
      "assessment, presentation and reporting of the CPR. Re-\n",
      "searchers should consider writing and publishing a studyprotocol and registering the study prior to the derivation\n",
      "of a new CPR, in the interests of transparency [ 67,68].\n",
      "Study design for the derivation of a clinical prediction rule\n",
      "The first stage in the development of a CPR is the deriv-\n",
      "ation of the rule. This involves an examination of the\n",
      "ability of multiple potential variables from the clinical\n",
      "findings, history or investigation results to predict the\n",
      "target outcome of interest. Predicted probabilities are\n",
      "derived from the statistical analysis of patients with\n",
      "known outcomes, and the outcome of interest serves as\n",
      "the reference standard by which the performance of the\n",
      "CPR is assessed. The performance of a CPR is dependent\n",
      "upon the quality of the underlying data, and the dataset\n",
      "used to derive the CPR should be representative of the\n",
      "target population it is intended for [ 17,30,69,70].\n",
      "The optimal study design for the derivation of a diagnos-\n",
      "t i cC P Ri sac r o s s - s e c t i o n a lc o hort study, while for prognos-\n",
      "tic CPRs, the preferred design is a longitudinal cohort study\n",
      "[30]. In general, case-control studies are inappropriate, as\n",
      "they do not allow for the estimation of absolute outcome\n",
      "risk [ 21,23,71]; however, nested case-control or\n",
      "case-cohort studies can be used [ 71,72]. Prospective cohort\n",
      "studies are preferred to retrospective cohort studies, to op-\n",
      "timise measurement and documentation of predictive and\n",
      "outcome variables [ 21,23]. For prescriptive CPRs, study de-\n",
      "signs that include a control gr oup, such as randomised con-\n",
      "trolled trials (RCTs), are essential to ensure that treatment\n",
      "effect modifiers and non-specific prognostic predictors are\n",
      "distinguishable from one another [ 73,74]. The study design\n",
      "should be adequately detailed and include the study setting,\n",
      "inclusion and exclusion criteria and patient demographics\n",
      "and characteristics [ 17]. To enhance generalisability, multi-\n",
      "centre studies are recommended [ 30].\n",
      "Statistical analysis\n",
      "Commonly used statistical methods for the derivation of\n",
      "CPRs include multivariable regression techniques, and\n",
      "recursive partitioning techniques, such as classificationDerivation\n",
      "Identification of \n",
      "factors with \n",
      "predictive powerValidation\n",
      "Evidence of reproducible \n",
      "accuracy\n",
      "Narrow Validation\n",
      "Application of rule in a similar \n",
      "clinical setting and population as \n",
      "in the derivation stage\n",
      "Broad Validation\n",
      "Application of rule in multiple \n",
      "clinical settings with varying \n",
      "prevalence and outcomes of \n",
      "diseaseImpact Analysis\n",
      "Evidence that rule \n",
      "changes physician \n",
      "behaviour and improves \n",
      "patient outcomes and/or \n",
      "reduces costs\n",
      "Fig. 1 The three main stages in the development and evaluation of clinical prediction rules. Adapted from McGinn, 2016 [ 47]Cowley et al. Diagnostic and Prognostic Research            (2019) 3:16 Page 3 of 23\n",
      "\n",
      "Page 4:\n",
      "Table 1 Stages in the development and evaluation of clinical\n",
      "prediction rules\n",
      "Stage of development Methodological standards\n",
      "Stage 1. Identifying the need for a\n",
      "CPRConsider conducting qualitative research\n",
      "with clinicians to determine clinical\n",
      "relevance and credibility of CPR\n",
      "Conduct a systematic review of the\n",
      "literature to identify and evaluate existing\n",
      "CPRs developed for the same purpose\n",
      "Consider updating, validating or testing\n",
      "the impact of existing CPRs\n",
      "Stage 2. Derivation of a CPR\n",
      "according to methodological\n",
      "standardsStudy design for the derivation of a CPR\n",
      "Consider registering the study and\n",
      "publishing a protocol\n",
      "Ensure the dataset is representative of the\n",
      "population for whom the CPR is intended\n",
      "Conduct a prospective multicentre cohort\n",
      "study\n",
      "Statistical analysis\n",
      "Conduct multivariable regression analysis\n",
      "(logistic for binary outcomes, Cox for\n",
      "long-term prognostic outcomes)\n",
      "Identify the model to be used, plus\n",
      "rationale if other methods used\n",
      "Missing data\n",
      "Use multiple imputation\n",
      "Selection of candidate predictors for\n",
      "inclusion in a multivariable model\n",
      "Only include relevant predictors based on\n",
      "evidence in the literature/clinical\n",
      "experience\n",
      "Aim for a sample size with a minimum of\n",
      "ten events per predictor, preferably more\n",
      "Avoid selection based on univariable\n",
      "significance testing\n",
      "Avoid categorising continuous predictors\n",
      "Selection of predictors during multivariable\n",
      "modelling\n",
      "Backward elimination of predictors is\n",
      "preferred\n",
      "Avoid data-driven selection and incorpor-\n",
      "ate subject-matter knowledge into the se-\n",
      "lection process\n",
      "Definition and assessment of predictor and\n",
      "outcome variables\n",
      "Define predictor and outcome variables\n",
      "clearly\n",
      "Consider inter-rater reliability of predictor\n",
      "measurement and potential measurement\n",
      "error\n",
      "Aim for blind assessment of predictor and\n",
      "outcome variables\n",
      "Internal validation\n",
      "Use cross-validation or bootstrapping and\n",
      "adjust for optimism\n",
      "Ensure to repeat each step of model\n",
      "development if using bootstrapping\n",
      "CPR performance measures\n",
      "Assess and report both calibration and\n",
      "discriminationTable 1 Stages in the development and evaluation of clinical\n",
      "prediction rules (Continued)\n",
      "Stage of development Methodological standards\n",
      "Consider decision curve analysis to\n",
      "estimate the clinical utility of the CPR\n",
      "Presentation of a CPR\n",
      "Report the regression coefficients of the\n",
      "final model, including the intercept or\n",
      "baseline hazard\n",
      "Consider a clinical calculator if the CPR is\n",
      "complex\n",
      "Reporting the derivation of a CPR\n",
      "Adhere to the TRIPOD guidelines [ 36]\n",
      "Stage 3. External validation and\n",
      "refinement of a CPRStudy design for the external validation of a\n",
      "CPR\n",
      "Conduct a prospective multicentre cohort\n",
      "study\n",
      "Aim for a sample size with a minimum of\n",
      "100 outcome events, preferably 200\n",
      "Consider using a framework of\n",
      "generalisability to enhance the\n",
      "interpretation of the findings [ 34]\n",
      "Types of external validation\n",
      "Conduct temporal, geographical and\n",
      "domain validation studies to ensure\n",
      "maximum generalisability\n",
      "If multiple validations have been\n",
      "performed, conduct a meta-analysis to\n",
      "summarise the overall performance of the\n",
      "CPR, using a published framework [ 35]\n",
      "Refinement of a CPR: model updating or\n",
      "adjustment\n",
      "Consider updating, adjusting or\n",
      "recalibrating the CPR if poor performance\n",
      "is found in an external validation study\n",
      "Consider further external validation of\n",
      "updated CPRs\n",
      "Comparing the performance of CPRs\n",
      "Compare the CPR with other existing CPRs\n",
      "for the same condition\n",
      "Ensure the statistical procedures used for\n",
      "comparison are appropriate; consider a\n",
      "decision-analytic approach\n",
      "Reporting the external validation of a CPR\n",
      "Adhere to the TRIPOD guidelines [ 36]\n",
      "Stage 4. Impact of a CPR on clinical\n",
      "practiceStudy design for an impact analysis\n",
      "Consider whether the CPR is ready for\n",
      "implementation\n",
      "Conduct a cluster randomised trial with\n",
      "centres as clusters, or a before –after study\n",
      "Perform appropriate sample size\n",
      "calculations\n",
      "Consider decision-analytic modelling as an\n",
      "intermediate step prior to a formal impact\n",
      "study\n",
      "Measures of impact of a CPR\n",
      "Report the safety and efficacy of the CPR\n",
      "Report the impact of the CPR on clinician\n",
      "behaviour if assessedCowley et al. Diagnostic and Prognostic Research            (2019) 3:16 Page 4 of 23\n",
      "\n",
      "Page 5:\n",
      "and regression tree analysis [ 75]. Methods based on uni-\n",
      "variable analysis, where individual risk factors are simply\n",
      "totalled and assigned arbitrary weightings, should be\n",
      "avoided, as they are much less accurate than methods\n",
      "based on multivariable analysis [ 76]. This is because the\n",
      "final model may include predictors that are potentially\n",
      "related to each other and not independently associated\n",
      "with the outcome of interest [ 76]. Multivariable methods\n",
      "overcome the limitations of univariable analysis byenabling improved assessment of the association of the\n",
      "predictors with the target outcome [ 76].\n",
      "In the case of multivariable regression, logistic regres-\n",
      "sion models are required to predict binary events such as\n",
      "the presence or absence of a condition, while Cox regres-\n",
      "sion models are suitable for time-to-event outcomes. Such\n",
      "models estimate regression coefficients (e.g. log odds or\n",
      "hazard ratios) of each predictor. Regression coefficients\n",
      "are mutually adjusted for the other predictors, and thus\n",
      "represent the contribution of each predictor to the prob-\n",
      "ability of the outcome [ 23]. The probability of an outcome\n",
      "can be computed for a patient by combining the observed\n",
      "values of the predictors and their corresponding regres-\n",
      "sion coefficients with the model intercept, or estimated\n",
      "baseline hazard [ 23]. For logistic models, the model inter-\n",
      "cept and the weighted values applicable to each patient\n",
      "are summed [ 16]. Specific values are assigned to each pre-\n",
      "dictor, which are multiplied by the corresponding coeffi-\n",
      "cients. In the case of a model with only binary categorical\n",
      "predictors, the predictors are multiplied by 0 or 1, de-\n",
      "pending on whether they are absent (0) or present (1), as\n",
      "per the model in Table 3[77]. Exponentiating the final risk\n",
      "score gives the odds, and the probability (absolute risk) is\n",
      "calculated by use of the inverse logistic link function [ 78].\n",
      "In this way, the probability of an outcome can be esti-\n",
      "mated from any combination of the predictor values [ 36].\n",
      "The estimated probability for an individual without any of\n",
      "the predictors depends only on the intercept [ 23]. In this\n",
      "case, the value for each of the predictors will be 0; when\n",
      "each of these is multiplied by its relevant coefficient the\n",
      "value of 0 is retained [ 78]. For Cox regression models, the\n",
      "baseline hazard is estimated separately [ 26,29].\n",
      "Recursive partitioning involves repeatedly splitting\n",
      "patients into subpopulations including only individ-\n",
      "uals with a specific outcome [ 79], and was the\n",
      "method used to derive the Ottawa Ankle Rule [ 80].\n",
      "CPRs can also be derived using discriminant function\n",
      "analysis [ 3], and machine learning algorithms based\n",
      "on artificial neural networks [ 1]. Artificial intelligence andTable 1 Stages in the development and evaluation of clinical\n",
      "prediction rules (Continued)\n",
      "Stage of development Methodological standards\n",
      "Acceptability of a CPR\n",
      "Evaluate the acceptability of the CPR using\n",
      "the validated OADRI [ 48], or using\n",
      "qualitative or vignette methods\n",
      "Comparison of a CPR with unstructured\n",
      "clinical judgement\n",
      "Compare the sensitivity and specificity of\n",
      "the CPR with clinicians own predictions/\n",
      "decisions\n",
      "The four phases of impact analysis for CPRs\n",
      "Follow the framework for the impact\n",
      "analysis of CPRs [ 33]\n",
      "Ensure extensive preparatory and\n",
      "feasibility work is conducted prior to a\n",
      "formal impact study\n",
      "Reporting the impact analysis of a CPR\n",
      "There are currently no published reporting\n",
      "guidelines for impact studies of CPRs; this\n",
      "is an area for future research\n",
      "Stage 5. Cost-effectiveness Conduct a formal economic evaluation,\n",
      "with sensitivity analyses to examine the\n",
      "uncertainty of the model projections\n",
      "Stage 6. Long-term implementation\n",
      "and disseminationDevise and evaluate targeted\n",
      "implementation strategies to ensure\n",
      "maximum uptake\n",
      "Barriers and facilitators to the use of CPRs\n",
      "Assess barriers to the use of the CPR and\n",
      "devise strategies to overcome these\n",
      "CPR clinical prediction rule, TRIPOD Transparent Reporting of a multivariable\n",
      "prediction model for Individual Prognosis or Diagnosis, OADRI Ottawa\n",
      "Acceptability of Decision Rules Instrument\n",
      "Table 2 Hierarchies of evidence in the development and evaluation of clinical prediction rules\n",
      "Level of evidence Definitions and standards of evaluation Implications for clinicians\n",
      "Level 1: Derivation of CPR Identification of predictors using multivariable model; blinded\n",
      "assessment of outcomes.Needs validation and further evaluation before it\n",
      "is used clinically in actual patient care.\n",
      "Level 2: Narrow validation of\n",
      "CPRValidation of CPR when tested prospectively in one setting;\n",
      "blinded assessment of outcomes.Needs validation in varied settings; may use CPR\n",
      "cautiously in patients similar to derivation sample.\n",
      "Level 3: Broad validation of\n",
      "CPRValidation of CPR in varied settings with wide spectrum of\n",
      "patients and clinicians.Needs impact analysis; may use CPR predictions\n",
      "with confidence in their accuracy.\n",
      "Level 4: Narrow impact analysis\n",
      "of CPR used for decision-\n",
      "makingProspective demonstration in one setting that use of CPR\n",
      "improves clinicians ’decisions (quality or cost-effectiveness of pa-\n",
      "tient care).May use cautiously to inform decisions in settings\n",
      "similar to that studied.\n",
      "Level 5: Broad impact analysis\n",
      "of CPR used for decision-\n",
      "makingProspective demonstration in varied settings that use of CPR\n",
      "improves clinicians ’decisions for wide spectrum of patients.May use in varied settings with confidence that\n",
      "its use will benefit patient care quality or\n",
      "effectiveness.\n",
      "Adapted from Reilly and Evans 2016 [ 32].CPR clinical prediction ruleCowley et al. Diagnostic and Prognostic Research            (2019) 3:16 Page 5 of 23\n",
      "\n",
      "Page 6:\n",
      "machine learning approaches are becoming increasingly\n",
      "more common [ 81,82].\n",
      "Missing data\n",
      "In clinical research, investigators almost always encounter\n",
      "missing observations involving predictor or outcome vari-\n",
      "ables, even in carefully designed studies and in spite of\n",
      "their best efforts to maximise data quality [ 83]. There are\n",
      "three types of missing data mechanisms: (1) missing com-\n",
      "pletely at random (MCAR), (2) missing at random (MAR)\n",
      "and (3) missing not at random (MNAR) [ 84]. When data\n",
      "are MCAR, this means that there are no systematic differ-\n",
      "ences between the missing and observed values; for ex-\n",
      "ample, laboratory tests may be missing because of a\n",
      "d r o p p e dt e s tt u b eo rb r o k e ne q u i p m e n t .W h e nd a t aa r e\n",
      "MAR, this means that the probability of a missing value\n",
      "depends on the observed values of other variables (but\n",
      "not the unobserved values); for example, missing blood\n",
      "pressure measurements may be lower than observed mea-\n",
      "surements because younger people may be more likely to\n",
      "have missing measurements; in this case, data can be said\n",
      "to be MAR given age [ 85]. When data are MNAR, this\n",
      "means that the probability of a missing value depends on\n",
      "the unobserved values or other unobserved predictors,\n",
      "conditional on the observed data; for example, people with\n",
      "high blood pressure may be more likely to miss a doctor ’s\n",
      "appointment due to headaches [ 85]. Missing values are\n",
      "rarely MCAR, that is, their ‘missingness ’is usually directly\n",
      "or indirectly related to other subject or disease character-\n",
      "istics, including the outcome [ 23,25]. Missing data is fre-\n",
      "quently addressed with case-wise deletion, which excludes\n",
      "all participants with missing values from the analysis [ 85].\n",
      "However, when data are plausibly MAR, this reduces sam-\n",
      "ple size and statistical power and biases the results [ 85],\n",
      "leading to inaccurate estimates of predictor-outcome rela-\n",
      "tionships and the predictive performance of the model,\n",
      "since the participants with complete data are not a ran-\n",
      "dom subsample of the original sample [ 84,86,87].\n",
      "Multiple imputation is a popular approach to the prob-\n",
      "lem of missing data [ 83,85,86,88–91], as it quantifies the\n",
      "uncertainty in the imputed valu es, by generating multiple\n",
      "different plausible imputed dat asets, and pooling the results\n",
      "o b t a i n e df r o me a c ho ft h e m[ 85,91]. Multiple imputation\n",
      "involves three stages [ 85,89,91–93]. First, as the name sug-\n",
      "gests, multiple imputed datasets are created, based on the\n",
      "distribution of the observed d ata. This first stage accounts\n",
      "for uncertainty in estimating the missing values by adding\n",
      "variability into the values across the imputed datasets. Inthe second stage, standard stati stical techniques are used to\n",
      "fit the models that are of interest in the substantive analysis\n",
      "to each of the imputed datasets. Estimated associations in\n",
      "each of the imputed datasets will be different, due to the\n",
      "variability introduced in stage one. In the third and final\n",
      "stage, the multiple results are averaged together, and stand-\n",
      "ard errors are calculated using Rubin ’s combination rules\n",
      "[91], which account for both within-and between-imput-\n",
      "ation variability and the number of imputed datasets, and\n",
      "therefore the uncertainty of t he imputed val ues. Multiple\n",
      "imputation typically assumes that data are MAR [ 93]. Im-\n",
      "portantly, the MAR assumption is just that; an assumption,\n",
      "rather than a property of the data [ 85]. The MCAR as-\n",
      "sumption can be tested, but it is not possible to differentiate\n",
      "between MAR and MNAR from the observed data [ 26,85].\n",
      "Most missing data are expected to be at least partly MNAR\n",
      "[85,94,95]. Sensitivity analyses can help to determine the\n",
      "effect of different assumptions about the missing data\n",
      "mechanism; work in this area is ongoing [ 96–100]. Other\n",
      "statistically principled approaches to dealing with missing\n",
      "data have been developed, based on random effects models\n",
      "[101,102], Bayesian methods or maximum likelihood esti-\n",
      "mation [ 103] or, where data are longitudinal, joint models\n",
      "[104,105]. Guidelines for reporting on the treatment of\n",
      "missing data in clinical and epidemiological research studies\n",
      "have been suggested by Sterne and colleagues [ 85]. Guid-\n",
      "ance also exists for handling missing data when deriving\n",
      "and validating CPRs [ 83,106,107]. It has been demon-\n",
      "strated that the outcome should be used for imputation of\n",
      "missing predictor values [ 87]. It is also becoming increas-\n",
      "ingly apparent that a real-time strategy to impute missing\n",
      "values is desirable when apply ing a CPR in clinical practice\n",
      "[108 –110]. This is because one or more predictor variables\n",
      "may be unobserved for a particular patient, and thus the\n",
      "CPRs risk prediction cannot be estimated at the time of\n",
      "decision-making [ 108]. Real-time multiple imputation is\n",
      "not typically straightforwar d, as it requires access to the\n",
      "derivation dataset via, for example, a website [ 108,110]. Of\n",
      "note, although multiple imp utation is a widely advocated\n",
      "approach for handling missing data in CPR studies, a recent\n",
      "study showed that impleme nting simpler imputation\n",
      "methods resulted in similar predictive utility of a CPR to\n",
      "predict undiagnosed diabetes, when compared to multiple\n",
      "imputation [ 111].\n",
      "Selection of candidate predictors for inclusion in a\n",
      "multivariable model\n",
      "Candidate predictors are variables that are preselected\n",
      "for consideration in a multivariable model, and differ\n",
      "from those that are subsequently selected for inclusion\n",
      "in the final model [ 23]. Candidate predictors should be\n",
      "selected without studying the predictor-outcome rela-\n",
      "tionship in the data; in other words, predictors should\n",
      "not be excluded as candidates solely because they areTable 3 Clinical prediction rule for postoperative nausea and\n",
      "vomiting (PONV) [ 77]\n",
      "Risk of PONV = 1/(1 + exp. −[2.28 + 1.27 × female sex + 0.65 × history of\n",
      "PONV or motion sickness + 0.72 × non-smoking + 0.78 × postoperative\n",
      "opioid use])Cowley et al. Diagnostic and Prognostic Research            (2019) 3:16 Page 6 of 23\n",
      "\n",
      "Page 7:\n",
      "not statistically significant in univariable analysis [ 25,26,\n",
      "29,112 –114]. Predictor variables do not have to be caus-\n",
      "ally related to the outcome of interest [ 21,115]. Effects\n",
      "modelled in studies examining causality are expressed\n",
      "with relative risk estimates such as odds ratios, while\n",
      "risk predictions are presented as probabilities on an ab-\n",
      "solute scale between 0 and 1. Relative risk estimates are\n",
      "used in prediction research to calculate an absolute\n",
      "probability of an outcome for a patient, as described\n",
      "above, and can also be reported alongside risk predic-\n",
      "tions. All variables thought to be related to the target\n",
      "outcome can be selected as candidate predictors for in-\n",
      "clusion in a multivariable model; however, when the\n",
      "number of outcome events in the dataset is small, there\n",
      "is a risk of overfitting the data when a large number of\n",
      "predictor variables are included. Thus the CPR will per-\n",
      "form well on the derivation data, but poorly on new data\n",
      "[29,69,113,116]. CPRs with a smaller number of pre-\n",
      "dictors are also easier to use in practice. To overcome\n",
      "this problem, only the most clinically relevant candidate\n",
      "predictors should be chosen from the larger pool of po-\n",
      "tential predictor variables, without looking into the data\n",
      "[5,117]. In addition, sample size recommendations for\n",
      "studies deriving CPRs are often based on the concept of\n",
      "events-per-variable (EVP), whereby the researcher con-\n",
      "trols the ratio of the number of outcome events to the\n",
      "number of coefficients estimated prior to any data-\n",
      "driven variable selection [ 31]. A rule-of-thumb of ten\n",
      "EPV has been suggested [ 29,31,114,118]. Simulation\n",
      "studies examining the effect of this rule-of-thumb have\n",
      "yielded conflicting results [ 119 –123]. One study found\n",
      "that when the EPV was less than ten, there were a range\n",
      "of circumstances in which coverage and bias were within\n",
      "acceptable levels [ 119]. Another found that 20 EPV or\n",
      "more are required when low-prevalence predictors are\n",
      "included in a model [ 123], while another suggested that\n",
      "problems may arise even when the EPV exceeds ten, as\n",
      "CPR performance may depend on many other factors\n",
      "[120]. Research in this area continues to evolve, as new\n",
      "guidance is clearly needed to support sample size con-\n",
      "siderations for the derivation of CPRs [ 121]. Recently,\n",
      "van Smeden and colleagues have suggested that sample\n",
      "size should be guided by three influential parameters:\n",
      "the number of predictors, total sample size and the\n",
      "events fraction [ 122].\n",
      "Relevant predictors may be chosen based on a com-\n",
      "bination of clinical experience, expert opinion surveys,\n",
      "qualitative studies and formal systematic reviews and\n",
      "meta-analyses of the literature [ 26,33,36,65,124].\n",
      "Strategie s for reducing the number of candidate predic-\n",
      "tors include removing those that are highly correlated\n",
      "with others, and combining similar predictors [ 29].\n",
      "Other considerations include selecting predictors that\n",
      "will be readily available for clinicians to observe ormeasure in the target setting, and selecting predictors\n",
      "that are relatively easy to measure and demonstrate high\n",
      "inter-rater reliability between clinicians [ 17,21]. In terms\n",
      "of handling continuous predictors, researchers strongly\n",
      "advise against converting continuous variables into cat-\n",
      "egorical variables, due to information loss and reduced\n",
      "predictive accuracy [ 125 –128]. Similarly, it should not\n",
      "be assumed that continuous variables have a linear rela-\n",
      "tionship [ 127]. Instead, methods that permit more flexi-\n",
      "bility in the functional form of the association between\n",
      "the predictors and outcome should be considered [ 127,\n",
      "129]; two common approaches are fractional polyno-\n",
      "mials and restricted cubic splines [ 130,131]. However, if\n",
      "sample size is limited, assuming a linear relationship be-\n",
      "tween continuous variables may make a model less sen-\n",
      "sitive to extreme observations.\n",
      "Penalised regression can be used to alleviate the prob-\n",
      "lem of overfitting [ 116]. This approach involves placing a\n",
      "constraint on the values of the estimated regression coeffi-\n",
      "cients in order to shrink them towards zero [ 116]. This\n",
      "has the effect of yielding less extreme risk predictions, and\n",
      "thus may improve the accuracy of predictions when the\n",
      "CPR is applied in new patients [ 113,132]. The two most\n",
      "popular penalised methods are ridge regression [ 133]a n d\n",
      "lasso regression [ 134]. Unlike ridge regression, lasso re-\n",
      "gression also selects predictors as a consequence of its\n",
      "penalisation [ 116]. Ridge regression is usually preferred\n",
      "when a set of pre-specified predictors is available, while\n",
      "lasso regression may be preferred if a simpler model with\n",
      "fewer predictors is required [ 116,132].\n",
      "Selection of predictors during multivariable modelling\n",
      "There is no consensus regarding how predictors should\n",
      "be selected while developing the final model [ 25]. Two\n",
      "common strategies include the ‘full model approach ’and\n",
      "the ‘predictor selection approach ’[23]. An alternative\n",
      "approach, known as ‘all possible subsets regression ’,i s\n",
      "less commonly used [ 28]. In the full model approach, all\n",
      "previously identified candidate predictors are included,\n",
      "and no further analysis is performed. Although this ap-\n",
      "proach precludes selection bias and overfitting, it re-\n",
      "quires in-depth knowledge about the most relevant\n",
      "candidate predictors [ 26,29]. In the predictor selection\n",
      "approach, predictors are chosen either by ‘backward\n",
      "elimination ’or ‘forward selection ’, based on pre-defined\n",
      "criteria. Backward elimination begins with all predictors\n",
      "in the model and removes predictors, while forward se-\n",
      "lection begins with an empty model, and predictors are\n",
      "added successively. All possible subsets regression can\n",
      "build models with combinations of predictors not gener-\n",
      "ated by the standard forward or backward procedures,\n",
      "because every conceivable combination of predictors is\n",
      "assessed to find the best fitting model [ 135]. With all\n",
      "methods, a series of statistical tests are performed toCowley et al. Diagnostic and Prognostic Research            (2019) 3:16 Page 7 of 23\n",
      "\n",
      "Page 8:\n",
      "assess the ‘goodness of fit ’between the different models.\n",
      "Models can be compared by setting a pre-defined signifi-\n",
      "cance level and using the log likelihood ratio test, or\n",
      "using other model selection criterion such as the Akaike\n",
      "information criterion, or the Bayesian information criter-\n",
      "ion [ 23,25]. Backward elimination is favoured, as it al-\n",
      "lows for the assessment of the effects of all predictors\n",
      "concurrently, and can take into account all correlations\n",
      "between predictors [ 136,137]. Multiple testing in all\n",
      "possible subsets regression can easily lead to overfitting.\n",
      "However, with all methods, the choice of significance\n",
      "level impacts upon the number of final predictors; the\n",
      "use of smaller significance levels (e.g. p< 0.05) produces\n",
      "models with fewer predictors at the risk of excluding po-\n",
      "tentially important predictors, while the use of larger\n",
      "significance levels (e.g. p< 0.25) may result in the inclu-\n",
      "sion of less important predictors [ 25].\n",
      "Predictor selection by so-called automated, data-\n",
      "dependent significance testing may generate overfitted,\n",
      "‘optimistic ’models, particularly when the derivation data-\n",
      "set is small [ 23,28,128,138,139]. Thus, the Akaike infor-\n",
      "mation criterion is preferred, as it discourages overfitting\n",
      "by comparing models based on their fit to the data and\n",
      "penalising for the complexity of the model [ 25]. In\n",
      "addition, it may be acceptable to retain a non-significant\n",
      "predictor in a model, if there is substantial evidence of its\n",
      "predictive ability in the literature [ 26].\n",
      "Definition and assessment of predictor and outcome\n",
      "variables\n",
      "To ensure that the CPR can be accurately applied in\n",
      "practice, predictor and outcome variables should be\n",
      "clearly defined, and outcome variables should be clinic-\n",
      "ally important [ 17]. Predictor variables must be reliable\n",
      "to enable their assessment in clinical practice; reliability\n",
      "refers to the reproducibility of the findings by the same\n",
      "clinician (intra-rater reliability) or between different cli-\n",
      "nicians (inter-rater reliability). Some researchers recom-\n",
      "mend that the reliability of predictor variables be\n",
      "explicitly evaluated, and that only those demonstrating\n",
      "good agreement beyond that expected by chance alone\n",
      "should be considered for inclusion [ 17]. A recent study\n",
      "found that measurement error of predictor variables is\n",
      "poorly reported, and that researchers seldom state expli-\n",
      "citly when the predictors should be measured, and the\n",
      "CPR applied [ 140]. Another study demonstrated that\n",
      "predictor measurement heterogeneity across settings can\n",
      "have a detrimental impact on the performance of a CPR\n",
      "at external validation [ 141]. Ideally, the outcome variable\n",
      "should be assessed independently of the predictor vari-\n",
      "ables to avoid circular reasoning or ‘incorporation bias ’,\n",
      "when the results of the CPR or its predictor variables\n",
      "are used in the determination of the outcome [ 142].\n",
      "However, it is acknowledged that this is not alwayspossible, particularly for conditions that require a con-\n",
      "sensus diagnosis based on all available patient informa-\n",
      "tion [ 143]. It is well known that misclassification in the\n",
      "outcome variable may cause serious problems with pre-\n",
      "diction accuracy [ 144,145].\n",
      "Internal validation\n",
      "Prediction models are known to perform better in the data-\n",
      "set from which they are derived, in comparison to applying\n",
      "them in new but plausibly related patients [ 146,147].\n",
      "‘Plausibly related patients ’m a yb ed e f i n e da st h o s ew h oa r e\n",
      "suspected of having the same condition or who are at risk\n",
      "of the same outcome examin ed in the derivation study\n",
      "[148]. This enhanced performance occurs simply because a\n",
      "model is designed to optimally fit the available data [ 23].\n",
      "The performance of a model is most likely to be overesti-\n",
      "mated when the derivation dataset is small, and uses a large\n",
      "number of candidate predictors .T h e r e f o r e ,r e g a r d l e s so f\n",
      "the approaches used in the derivation stage of development,\n",
      "internal validation is required to examine and correct the\n",
      "amount of overfitting or ‘optimism ’in the model, and thus\n",
      "the stability of the model [ 23].\n",
      "Internal validation does not validate a model itself, but\n",
      "the process used to fit the model [ 26,29]. Optimism is es-\n",
      "timated using the original derivation dataset only. A num-\n",
      "ber of methods are available for this purpose, including\n",
      "split-sampling, cross-validation and bootstrapping.\n",
      "Split-sampling is the simplest method, and is performed\n",
      "by dividing the derivation dataset into a ‘training ’sample\n",
      "and a ‘test ’sample prior to modelling. The CPR is then de-\n",
      "rived using the training sample, and its performance is\n",
      "assessed using the test sample [ 20]. However, the test sam-\n",
      "ple usually comprises one-third of the original derivation\n",
      "dataset and is likely to be relatively small, resulting in im-\n",
      "precise performance estimates [ 149,150]. This approach\n",
      "also squanders the test data that could have been used in\n",
      "the derivation of the CPR [ 23,150]. In cross-validation,\n",
      "the CPR is derived using the whole derivation dataset, and\n",
      "the whole dataset is then reused to assess performance\n",
      "[20]. It is randomly split into equal samples: five or ten\n",
      "samples are commonly used. In the case of five samples,\n",
      "the model is refitted using four of the five samples and its\n",
      "performance tested using the fifth; this process is repeated\n",
      "five times until each of the five samples has been used as\n",
      "the test data, and an average of the estimated performance\n",
      "is taken. To improve stability, the overall procedure can\n",
      "be replicated several times, using different random sub-\n",
      "samples [ 149]. The preferred internal validation method is\n",
      "bootstrapping, particularly when the derivation dataset is\n",
      "small or a large number of candidate predictors are\n",
      "assessed [ 23,29]. The idea is to mimic random sampling\n",
      "from the target population by repeatedly drawing samples\n",
      "of the same size with replacement from the derivation\n",
      "dataset [ 151]. Sampling with replacement rendersCowley et al. Diagnostic and Prognostic Research            (2019) 3:16 Page 8 of 23\n",
      "\n",
      "Page 9:\n",
      "bootstrap samples similar, but not identical, to the original\n",
      "derivation sample [ 23]. Each step of model development is\n",
      "repeated in each bootstrap sample (typically 500), most\n",
      "likely yielding different models with varying performance.\n",
      "Each bootstrap model is then applied to the original deriv-\n",
      "ation sample, yielding a difference in model performance.\n",
      "The average of these differences indicates the optimism in\n",
      "the performance metrics of the model that was initially\n",
      "derived in the derivation dataset [ 23,26,29,151], and en-\n",
      "abling adjustment of the overall performance to better ap-\n",
      "proximate the expected model performance in novel\n",
      "samples [ 23]. Bootstrapping also estimates a uniform\n",
      "shrinkage factor to enable adjustment of the estimated re-\n",
      "gression coefficients for over-fitting [ 26,29,151]. How-\n",
      "ever, no internal validation procedures can be a substitute\n",
      "for external validation; internal validation only addresses\n",
      "sampling variability, while external validation considers\n",
      "variation in the patient population [ 147].\n",
      "Clinical prediction rule performance measures\n",
      "CPR predictive performance can be assessed in terms of\n",
      "overall performance, calibration and discrimination [ 26].\n",
      "‘Overall performance ’can be quantified by calculating\n",
      "the distance between observed and predicted outcomes,\n",
      "using measures such as R2or the Brier score [ 152].‘Cali-\n",
      "bration ’reflects the agreement between the predicted\n",
      "probabilities produced by the model and the observed\n",
      "outcome frequencies [ 23]. For example, if a model pre-\n",
      "dicts a 20% probability of residual tumour for a testicu-\n",
      "lar cancer patient, residual tumour should be observed\n",
      "in about 20 out of 100 of these patients [ 46].‘Internal\n",
      "calibration ’refers to agreement between predicted prob-\n",
      "abilities and observed outcome frequencies in the deriv-\n",
      "ation dataset, where poor calibration may indicate lack\n",
      "of model fit or model misspecification [ 153].‘External\n",
      "calibration ’refers to agreement between predicted prob-\n",
      "abilities and observed outcome frequencies in novel\n",
      "datasets external to the one from which the model was\n",
      "derived, where poor calibration may indicate an over-\n",
      "fitted model [ 153]. Calibration can be visualised by cate-\n",
      "gorising individuals into quantiles based on their\n",
      "predicted probabilities, and plotting the observed out-\n",
      "come frequencies against the mean predicted probabil-\n",
      "ities [ 25]. Such a plot is the graphical equivalent of the\n",
      "Hosmer and Lemeshow goodness-of-fit test [ 154],\n",
      "which, although frequently used, may lack statistical\n",
      "power to identify overfitting [ 25,26]. Alternatively, bin-\n",
      "ary outcomes can be regressed on the predicted prob-\n",
      "abilities of the fitted model to estimate the observed\n",
      "outcome probabilities using smoothing techniques such\n",
      "as the loess algorithm [ 29,153]. A comprehensive over-\n",
      "view of calibration is given in Van Calster et al. [ 155].\n",
      "Discrimination reflects the ability of a CPR to discrim-\n",
      "inate between patients with, and without, the outcomeof interest. The predicted probabilities for patients with\n",
      "the outcome should be higher than the predicted prob-\n",
      "abilities for those who do not have the outcome [ 46].\n",
      "The easiest way to assess discrimination is by calculation\n",
      "of the discrimination slope, which is simply the absolute\n",
      "difference in the average predicted probabilities for pa-\n",
      "tients with and without the outcome [ 26]. Discrimin-\n",
      "ation can also be visualised with a simple box plot. The\n",
      "most widely used measure to assess discrimination is the\n",
      "concordance index (c-index) [ 156], or, for logistic\n",
      "models its equivalent, the area under the receiver oper-\n",
      "ating characteristic curve (AUROC) [ 157]. These mea-\n",
      "sures represent the chance that, given one patient with\n",
      "the outcome and one without, the CPR will assign a\n",
      "higher predictive probability to the patient with the out-\n",
      "come compared to the one without. A c-index or\n",
      "AUROC of 0.5 indicates predictions that are no better\n",
      "than random predictions, and a value of 1 represents\n",
      "perfect discrimination between patients with and with-\n",
      "out the outcome [ 29]. In theory, a CPR may demonstrate\n",
      "good discrimination (classifying patients into the correct\n",
      "risk categories), but poor calibration (inaccurately esti-\n",
      "mating the absolute probability of an outcome), and vice\n",
      "versa [ 158]. A model that cannot discriminate between\n",
      "patients with and without the outcome has little use as a\n",
      "CPR; however, poor calibration can be corrected without\n",
      "compromising discriminatory performance [ 19,11 4 ].\n",
      "Van Calster and Vickers [ 159] found that poorly cali-\n",
      "brated models diminish the clinical usefulness of a CPR,\n",
      "and can be harmful for clinical decision-making under\n",
      "certain circumstances, emphasising the importance of\n",
      "developing well-calibrated CPR ’s. On the other hand, a\n",
      "CPR with poor calibration but good discrimination at a\n",
      "particular risk threshold may be appropriate if the aim is\n",
      "to prioritise patients for assessment or treatment, by\n",
      "identifying those with a very low risk of the target out-\n",
      "come relative to the rest of the population [ 160].\n",
      "Performance measures such as sensitivity, specificity,\n",
      "positive and negative predictive values and positive and\n",
      "negative likelihood ratios ar e used to assess performance\n",
      "following the application of a risk threshold. Choosing a\n",
      "risk threshold can often be arbitrary, and it can therefore be\n",
      "useful to consider a range of thresholds when assessing per-\n",
      "formance [ 19]. Ideally, a CPR will have both a high sensitiv-\n",
      "ity and a high specificity, and therefore correctly identify\n",
      "the majority of patients who truly have the condition, as\n",
      "w e l la sc o r r e c t l ye x c l u d et h em a j o r i t yo fp a t i e n t sw h od o\n",
      "not actually have the condition. However, this scenario\n",
      "rarely occurs in clinical practice. More often than not, the\n",
      "definition of a threshold is based on clinical considerations\n",
      "about the relative consequences of false positive and false\n",
      "negative classifications. Sensi tivity and specificity are in-\n",
      "versely proportional, so that as sensitivity increases, specifi-\n",
      "city decreases and vice versa [ 161]. Defining a high cut-offCowley et al. Diagnostic and Prognostic Research            (2019) 3:16 Page 9 of 23\n",
      "\n",
      "Page 10:\n",
      "point will result in good specificity and few false positives,\n",
      "but poor sensitivity and many fa lse negatives. A test with a\n",
      "high specificity is useful for ruling in a disease if a person\n",
      "tests positive. This is because it rarely misdiagnoses those\n",
      "who do not have the condition of interest. Defining a low\n",
      "cut-off point will result in good sensitivity and few false\n",
      "negatives, but poor specificity and many false positives. A\n",
      "test with a high sensitivity is useful for ruling out disease if\n",
      "a person tests negative. This is because it rarely misdiag-\n",
      "noses those who have the condition of interest [ 161]. Re-\n",
      "ceiver operating characteris tic (ROC) curves display the\n",
      "sensitivity and specificity of a CPR across the full range of\n",
      "cut-off values, and can be used to choose an optimal cut-off\n",
      "threshold [ 162]. Other approaches to determining clinical\n",
      "cut-offs have also been proposed [ 163].\n",
      "In recent years, some novel model performance mea-\n",
      "sures have been proposed that quantify the clinical use-\n",
      "fulness of a CPR, by taking into account the costs and\n",
      "benefits of clinical decisions. These measures include\n",
      "relative utility curves and decision curves [ 164,165]. De-\n",
      "cision curves in particular are becoming a popular\n",
      "method of evaluating whether clinical decisions based\n",
      "on CPRs would do more good than harm [ 166]. Decision\n",
      "curve analysis assumes that a given probability threshold\n",
      "is directly related to the cost to benefit ratio, and uses\n",
      "this threshold to weight false positive and false negative\n",
      "predictions. The cost to benefit ratio thus defines the\n",
      "relative weight of false-positive decisions to true-positive\n",
      "decisions [ 164]. Model performance can subsequently be\n",
      "summarised as a net benefit, by subtracting the propor-\n",
      "tion of false-positive patients from the proportion of\n",
      "true-positive patients, weighting by the relative costs of\n",
      "a false-positive and a false-negative result. The net bene-\n",
      "fit of a CPR can be derived across and plotted against\n",
      "the whole range of threshold probabilities, yielding a de-\n",
      "cision curve, similar to ROC curves that plot the full\n",
      "range of cut-offs for a sensitivity/specificity pair [ 164].\n",
      "Presentation of a clinical prediction rule\n",
      "The final step in the derivation of a CPR is to consider\n",
      "the format in which it should be presented. It is impera-\n",
      "tive that the regression coefficients and intercept of a\n",
      "final model are presented, and confidence intervals\n",
      "around predicted probabilities can also be provided [ 23,\n",
      "26]. If the final regression formula (as in Table 3) is not\n",
      "provided, a CPR could not be applied by future users\n",
      "[36]. A model can be developed into a simple web-based\n",
      "calculator or application to enhance the usability of a\n",
      "CPR. This may be beneficial for complex CPRs, and\n",
      "would facilitate their integration into the electronic\n",
      "health record, allowing them to be used at the point of\n",
      "clinical care [ 167]. Nomograms, graphical decision trees\n",
      "and other novel visualisation techniques could also be\n",
      "used [ 26,168], which may aid in the interpretation andunderstanding of a CPR [ 168]; however, these must be\n",
      "presented alongside the full model formula. Scoring sys-\n",
      "tems are often used to simplify CPRs and facilitate use,\n",
      "where regression coefficients are converted to integer\n",
      "point values that can be easily totalled and related back\n",
      "to the predicted probabilities [ 169]. However, this trans-\n",
      "formation leads to a loss of information and therefore\n",
      "reduced predictive accuracy [ 170].\n",
      "Reporting the derivation of a clinical prediction rule\n",
      "Numerous systematic reviews have shown that reporting\n",
      "of the derivation of CPRs is deficient [ 6–8]. As a result,\n",
      "the TRIPOD guidelines were produced [ 36], and should\n",
      "be followed by all researchers working in this field.\n",
      "Stage 3: external validation and refinement of a clinical\n",
      "prediction rule\n",
      "As previously noted, CPRs perform better in the dataset\n",
      "from which they are derived compared to their application\n",
      "in plausibly related or ‘similar but different ’individuals,\n",
      "even after internal validation and adjustment [ 24]. Dimin-\n",
      "ished performance can be due to o verfitting, unsatisfactory\n",
      "model derivation, the absence of important predictors, dif-\n",
      "ferences in how the predictor v ariables are interpreted and\n",
      "measured, differences in the patient samples ( ‘case mix ’)\n",
      "a n dd i f f e r e n c e si nt h ep r e v a l e n c eo ft h ed i s e a s e[ 26,148].\n",
      "There is no guarantee that even well-developed CPRs will\n",
      "be generalisable to new individuals. In one external valid-\n",
      "ation study, a CPR to detect serious bacterial infections in\n",
      "children with fever of unknown source demonstrated con-\n",
      "siderably worse predictive performance, such that it was\n",
      "rendered useless for clinical care [ 146]. It is therefore essen-\n",
      "tial to assess the performance of a CPR in individuals out-\n",
      "side the derivation dataset; this process is known as\n",
      "external validation [ 28].\n",
      "External validation is not simply repeating the steps\n",
      "involved at the derivation stage in a new sample to\n",
      "examine whether the same predictors and regression co-\n",
      "efficients are obtained; neither is it refitting the model in\n",
      "a new sample and comparing the performance to that\n",
      "observed in the derivation sample [ 24,31]. External val-\n",
      "idation involves taking the original fully specified model,\n",
      "with its predictors and regression coefficients as esti-\n",
      "mated from the derivation study; measuring and docu-\n",
      "menting the predictor and outcome variables in a new\n",
      "patient sample; applying the original model to these data\n",
      "to predict the outcome of interest; and quantifying the\n",
      "predictive performance of the model by comparing the\n",
      "predictions with the observed outcomes [ 20]. Perform-\n",
      "ance should be assessed using calibration, discrimination\n",
      "and measures to quantify clinical usefulness such as de-\n",
      "cision curve analysis [ 164]. A CPR can also be refined if\n",
      "it demonstrates poor performance in an external valid-\n",
      "ation study. Regrettably, few CPRs are externally validatedCowley et al. Diagnostic and Prognostic Research            (2019) 3:16 Page 10 of 23\n",
      "\n",
      "Page 11:\n",
      "[27,171,172]. A systematic review of CPRs for children\n",
      "identified 101 CPRs addressing 36 conditions; of these,\n",
      "only 17% had narrow validation and only 8% had broad\n",
      "validation [ 171].\n",
      "Study design for the external validation of a clinical\n",
      "prediction rule\n",
      "Ideally, a validation study should be conducted prospect-\n",
      "ively, by enrolling new individuals in a specifically prede-\n",
      "signed study, and the CPR should be applied to all\n",
      "patients meeting the study inclusion criteria [ 17,23].\n",
      "However, validation studies can be conducted retro-\n",
      "spectively, using existing datasets. If adequate data on\n",
      "the predictor and outcome variables is available [ 23]. In-\n",
      "vestigators conducting a validation study should receive\n",
      "brief training on the accurate application of the CPR. If\n",
      "possible, all patients should be subjected to the reference\n",
      "standard, to establish their true outcome and enable\n",
      "comparison with the CPR prediction. However, in some\n",
      "cases, this may not be feasible or practical, and an ap-\n",
      "propriate and sensible proxy outcome may be used in-\n",
      "stead [ 173]. Stiell and Wells [ 17] recommend that the\n",
      "inter-rater reliability of the interpretation of the CPR re-\n",
      "sult is assessed, to determine if the CPR is being applied\n",
      "accurately and consistently. In terms of sample size, for\n",
      "a logistic regression model with six predictors, a mini-\n",
      "mum of 100 patients with the outcome of interest and\n",
      "100 patients without the outcome of interest has been\n",
      "suggested [ 174]. Other authors propose that external\n",
      "validation studies require a minimum of 100 events, but\n",
      "ideally 200 events [ 175]. A minimum of 200 events and\n",
      "200 non-events has been suggested in order to reliably\n",
      "assess moderate calibration and produce useful calibra-\n",
      "tion plots [ 155]. The characteristics of patients included\n",
      "in a validation study should be described in detail, and\n",
      "compared with those included in the derivation study.\n",
      "To enhance the interpretation of external validation\n",
      "studies, it is possible to quantify the degree of relatedness\n",
      "between derivation and validation datasets, to determine\n",
      "the extent to which the CPR can be generalised to differ-\n",
      "ent populations [ 34]. Authors have also proposed bench-\n",
      "mark values to distinguish between a case-mix effect and\n",
      "incorrect regression coefficients in external validation\n",
      "studies, and therefore assist in the interpretation of a\n",
      "CPR ’s performance in validation samples [ 176]. Similarly,\n",
      "a model-based concordance measure has recently been\n",
      "derived that enables quantification of the expected change\n",
      "in a CPR ’s discriminative ability owing to case-mix hetero-\n",
      "geneity [ 177].\n",
      "Types of external validation\n",
      "Many types of external validation are recognised in\n",
      "the literature, but all types consider patients that dif-\n",
      "fer in some respect from the patients included in thederivation study [ 26]. The greater the differences be-\n",
      "tween the patients in the derivation and validation\n",
      "samples, the stronger the test of generalisability of\n",
      "the CPR [ 24]. Three types of external validation have\n",
      "received the most attention, namely temporal valid-\n",
      "ation, geographical validation and domain validation\n",
      "[148].\n",
      "Intemporal validation studies, the CPR is tested on\n",
      "patients in the same centre(s) but over a different time\n",
      "period [ 147].Geographical validation studies examine\n",
      "the generalisability of the CPR to other centres, insti-\n",
      "tutes, hospitals or countries [ 147]. Patient characteristics\n",
      "are likely to vary between locations, and predictor and\n",
      "outcome variables are likely to be interpreted and mea-\n",
      "sured differently in different places, leading to greater\n",
      "differences between the derivation and validation popu-\n",
      "lations than in a temporal validation study [ 24,148]. In\n",
      "domain validation, the CPR is tested in very different pa-\n",
      "tients than those from whom it was derived, for example\n",
      "in patients from a different setting (e.g. primary or sec-\n",
      "ondary care), or in patients of different ages (e.g. adults\n",
      "vs. children). The case mix of patients included in a\n",
      "domain validation study will clearly differ from the der-\n",
      "ivation population [ 148]. Differences between the deriv-\n",
      "ation and validation populations are generally smallest in\n",
      "a temporal validation study, and greatest in a domain\n",
      "validation study; therefore, good performance of a CPR\n",
      "in a temporal validation study may only provide weak\n",
      "evidence that the CPR can be generalised to new pa-\n",
      "tients, while good performance in a domain validation\n",
      "study can be considered as the strongest evidence of\n",
      "generalisability [ 148]. Other types of external validation\n",
      "studies include methodologic validation which refers to\n",
      "testing using data collected via different methods,\n",
      "spectrum validation which refers to testing in patients\n",
      "with different disease severity or prevalence of the out-\n",
      "come of interest and fully independent validation which\n",
      "refers to testing by independent investigators at different\n",
      "sites [ 26,147]. A recent study of cardiovascular risk\n",
      "CPRs found that very few were externally validated by\n",
      "independent researchers; to increase the chance of fully\n",
      "independent validation, researchers should report all the\n",
      "information required for risk calculation, to ensure rep-\n",
      "licability [ 178]. Some authors have found that CPRs\n",
      "demonstrate worse performance in fully independent\n",
      "external validation studies compared to temporal or\n",
      "geographical external validation studies [ 26,28], while\n",
      "others have found no difference [ 179]. When multiple\n",
      "external validations of a CPR have been performed, it is\n",
      "useful to conduct a formal meta-analysis to summarise\n",
      "its overall performance across different settings and to\n",
      "assess the circumstances under which the CPR may need\n",
      "adjusting; a recently published framework provides guid-\n",
      "ance on how to do this [ 35].Cowley et al. Diagnostic and Prognostic Research            (2019) 3:16 Page 11 of 23\n",
      "\n",
      "Page 12:\n",
      "Refinement of a clinical prediction rule: model updating or\n",
      "adjustment\n",
      "When researchers encounter an inferior performance of\n",
      "a CPR in an external validation study compared with\n",
      "that found in the derivation study, there is a temptation\n",
      "to reject the CPR and derive an entirely new one in the\n",
      "often considerably smaller validation dataset [ 148,180].\n",
      "This approach leads to a loss of scientific information\n",
      "captured in the derivation study and an abundance of\n",
      "CPRs developed for the same clinical situation, leaving\n",
      "clinicians in a quandary over which one to use [ 24,148].\n",
      "However, a reduction in performance is to be expected\n",
      "in an external validation study [ 24,26,148]. The recom-\n",
      "mended alternative is to update, adjust or recalibrate the\n",
      "CPR using the validation data, thereby combining infor-\n",
      "mation captured in the original CPR with information\n",
      "from new patients and improving generalisability [ 22,\n",
      "181,182]. Several methods for updating CPRs are avail-\n",
      "able. When the outcome prevalence in the validation\n",
      "study is different to that in the derivation study, calibra-\n",
      "tion in the validation sample will be affected, but can be\n",
      "improved by adjusting the baseline risk (intercept) of the\n",
      "original model to the patients in the validation sample\n",
      "[180]. If the CPR is overfitted or underfitted, calibration\n",
      "can be improved by simultaneously adjusting all of the\n",
      "regression coefficients [ 24]. To improve discrimination,\n",
      "individual regression coefficients can be re-estimated, or\n",
      "additional predictors can be added [ 24,180]. Ideally, up-\n",
      "dated CPRs that are adjusted to validation samples\n",
      "should themselves be externally validated, just like newly\n",
      "derived CPRs [ 148].\n",
      "Comparing the performance of clinical prediction rules\n",
      "Once a CPR has been externally validated, it is useful to\n",
      "compare its performance with the performance of other\n",
      "existing CPRs for the same condition [ 61]. Improve-\n",
      "ments in discrimination can be assessed by quantifying\n",
      "the difference in the AUROC or equivalent c-index be-\n",
      "tween two CPRs [ 183]; however, this approach is in-\n",
      "appropriate in the case of nested models that are fitted\n",
      "in the same data set [ 184]. Novel metrics have been pro-\n",
      "posed that quantify the extent to which a new CPR im-\n",
      "proves the classification of individuals with and without\n",
      "the outcome of interest into predefined risk groups [ 46].\n",
      "These include the net reclassification improvement\n",
      "(NRI), and the integrated discrimination improvement\n",
      "(IDI) [ 185]. Various decision-analytic approaches to\n",
      "model comparison have also been proposed [ 186]. All of\n",
      "these measures can be used for comparing both nested\n",
      "and non-nested models. However, both the NRI and IDI\n",
      "statistics have come under intense scrutiny in the litera-\n",
      "ture and many researchers caution against their use, as\n",
      "positive values may arise simply due to poorly fitted\n",
      "models [ 30,187 –191]. Therefore, the NRI and IDIstatistics cannot be recommended [ 192]. Decision-analytic\n",
      "methods are increasingly recommended as they incorporate\n",
      "misclassification costs and therefore indicate the clinical\n",
      "usefulness of CPRs [ 186]. A systematic review of compari-\n",
      "sons of prediction models for cardiovascular disease found\n",
      "that formal and consistent statistical testing of the differ-\n",
      "ences between models was lacking and that appropriate risk\n",
      "reclassification measures were rarely reported [ 193]. A re-\n",
      "cent commentary provides a useful and comprehensive\n",
      "overview of the advantages and disadvantages of the various\n",
      "methods available for quantifying the added value of new\n",
      "biomarkers [ 194].\n",
      "Reporting the external validation of a clinical prediction\n",
      "rule\n",
      "External validation studies of CPRs are often poorly re-\n",
      "ported [ 9]; researchers should adhere to the TRIPOD\n",
      "checklist and accompanying guidelines [ 36].\n",
      "Stage 4: impact of a clinical prediction rule on clinical\n",
      "practice\n",
      "Since the ultimate aim of a CPR is to improve the qual-\n",
      "ity of patient care, the effect of a validated CPR on clin-\n",
      "ician behaviour and patient outcomes should be\n",
      "examined in what are known as impact analysis studies\n",
      "[22,24]. It is increasingly recognised that CPR ’s should\n",
      "be regarded as complex interventions, as the introduc-\n",
      "tion of a CPR into clinical practice with subsequent\n",
      "management decisions consists of multiple interacting\n",
      "components [ 108,195 –201]. The impact of a CPR on\n",
      "clinical practice will depend on several interacting fac-\n",
      "tors, including the accuracy and applicability of the CPR,\n",
      "clinicians ’interpretation of probabilities and clinicians ’\n",
      "adherence to and acceptance of the CPR [ 196]. Evaluat-\n",
      "ing the impact of a CPR has been described as ‘the next\n",
      "painful step ’in the development process [ 202]. Impact\n",
      "analysis studies clearly differ from validation studies as\n",
      "they must be comparative, typically requiring a control\n",
      "group of clinicians providing usual care [ 22,24,32]. It is\n",
      "possible to assess the impact of both assistive CPRs that\n",
      "simply provide predicted probabilities, and directive de-\n",
      "cision rules that suggest a specific course of action based\n",
      "on probability categories [ 32]. Assistive CPRs respect cli-\n",
      "nicians ’individual judgement and leave room for intu-\n",
      "ition, whereas directive rules may be more likely to\n",
      "influence clinician behaviour [ 32,203,204]. However, it\n",
      "is not guaranteed that clinicians will follow CPR, or the\n",
      "recommendations provided by directive rules [ 32].\n",
      "Therefore, an impact study must demonstrate that clin-\n",
      "ical behaviour can be altered and patient care improved\n",
      "by the CPR, prior to widespread dissemination and im-\n",
      "plementation [ 17].\n",
      "Unfortunately, even fewer CPRs undergo an impact as-\n",
      "sessment than undergo external validation. In theCowley et al. Diagnostic and Prognostic Research            (2019) 3:16 Page 12 of 23\n",
      "\n",
      "Page 13:\n",
      "systematic review of 101 CPRs for children, none had\n",
      "impact analysis performed [ 171]. An evaluation of 434\n",
      "primary care CPRs found that only 12 had undergone\n",
      "impact analysis [ 172]. A subsequent systematic review of\n",
      "the impact of primary care CPRs found 18 studies relat-\n",
      "ing to 14 CPRs, with 10/18 studies demonstrating an im-\n",
      "provement in primary outcome when the CPR was used\n",
      "compared to usual care [ 205]. This review cautioned that\n",
      "the small number of impact analysis studies found pre-\n",
      "cluded the possibility of drawing firm conclusions about\n",
      "the overall effectiveness of CPRs in primary care, with\n",
      "the authors pointing out that the methodological quality\n",
      "of the included studies was unclear due to incomplete\n",
      "reporting [ 205]. Another recent systematic review of the\n",
      "impact of CPRs found that the intermediate conse-\n",
      "quences of a CPR such as clinical management decisions\n",
      "were the primary outcome in the majority of studies,\n",
      "while few studies aimed to establish the effect of a CPR\n",
      "on patient outcomes [ 206]. In addition, in many of the\n",
      "included studies, the risk of bias was either high or un-\n",
      "clear [ 206]. Finally, a study describing the distribution of\n",
      "derivation, validation and impact studies in four reviews\n",
      "of leading medical journals since 1981 demonstrated\n",
      "that a minority of studies concerned CPR impact (10/\n",
      "201), with the pattern remaining stable over time [ 27].\n",
      "Study design for an impact analysis\n",
      "Before carrying out a formal impact study, researchers\n",
      "must consider whether the CPR is ready for implemen-\n",
      "tation [ 108,207]. If possible, the predictive performance\n",
      "of the CPR should be verified in the new setting, and the\n",
      "CPR tailored to the new setting to enhance performance\n",
      "[108]. The optimal study design for an impact analysis is\n",
      "a cluster randomised trial with centres as clusters [ 22].\n",
      "Randomising individual patients is not recommended as\n",
      "clinicians may learn the rule and apply it to patients ran-\n",
      "domised to the control group [ 22]. Randomising clini-\n",
      "cians is preferable but requires more patients, and may\n",
      "lead to contamination of experience between clinicians\n",
      "in the same centre [ 24,208]. An attractive variant of a\n",
      "cluster randomised trial is the stepped-wedge cluster\n",
      "randomised trial. In a stepped-wedge design, all centres\n",
      "apply care-as-usual, and then use the CPR at different,\n",
      "randomly allocated time periods [ 209]. This design allows\n",
      "for the comparison of outcomes both within and between\n",
      "hospitals, generates a wealth of data regarding potential\n",
      "barriers to implementation and is particularly beneficial if\n",
      "t h eC P Rt u r n so u tt oh a v eap r o m i s i n ge f f e c t[ 210]. When\n",
      "the outcome of interest in an impact study is clinician be-\n",
      "haviour or decision-making, a cross-sectional randomised\n",
      "study without patient follow-up is sufficient, with random-\n",
      "isation at either the patient or clinician level. However, to\n",
      "determine the impact of a CPR on patient outcomes or\n",
      "cost-effectiveness, follow-up of patients is essential [ 22].Given the significant practical, logistic and economic\n",
      "challenges associated with cluster randomised trials,\n",
      "non-randomised approaches are possible and are often\n",
      "used. Cluster randomised trials can be expensive and\n",
      "time-consuming and it may be difficult to recruit an ad-\n",
      "equate number of clusters [ 24,108]. A suggested\n",
      "rule-of-thumb is to regard four clusters per arm as the\n",
      "absolute minimum number required [ 211]; however,\n",
      "methods for determining sample size in cluster rando-\n",
      "mised trials have been proposed by a number of authors\n",
      "[212 –214]. A popular design is a before –after study, in\n",
      "which outcomes are assessed in a time period before a\n",
      "CPR is available and compared with outcomes measured\n",
      "in a time period after it is introduced; this design is sus-\n",
      "ceptible to temporal confounding [ 24]. Finally, a rela-\n",
      "tively low-cost and simple design is a before –after study\n",
      "within the same clinicians. In this design, clinicians are\n",
      "asked to indicate their treatment or management deci-\n",
      "sion or perceived risk of disease for the same patient\n",
      "both before, and after, receiving the CPR prediction [ 24].\n",
      "Single centre impact studies are recommended to inform\n",
      "the planning of multicentre randomised trials [ 32]. As\n",
      "with derivation and validation studies, a sample size cal-\n",
      "culation should be performed, with consideration of all\n",
      "relevant impact measures, and where possible assess-\n",
      "ment of outcome measures should be blinded to the\n",
      "CPR predictions and recommendations [ 32,33]. Clini-\n",
      "cians must undergo training in order to correctly inter-\n",
      "pret and use the CPR [ 17].\n",
      "The impact of CPRs can also be estimated indirectly\n",
      "using decision analytic modelling, which integrates infor-\n",
      "mation on CPR predictions and information about the\n",
      "effectiveness of treatments from therapeutic intervention\n",
      "studies [ 215,216]. Such studies cost less, and take less\n",
      "time, than RCTs; however, they are limited by the quality\n",
      "of available evidence, and only provide theoretical indi-\n",
      "cations of the impact CPRs may have on patient out-\n",
      "come s. Thus it has been suggested that they should not\n",
      "replace RCTs but rather be performed as an intermedi-\n",
      "ate step prior to an RCT [ 217].\n",
      "Measures of impact of a clinical prediction rule\n",
      "During an impact analysis study, the sensitivity and speci-\n",
      "ficity of the CPR should be recalculated to determine its\n",
      "accuracy in the new study population [ 17]. However, mea-\n",
      "sures of CPR accuracy are not synonymous with measures\n",
      "ofimpact , and only represent the potential impact of the\n",
      "CPR [ 32]. This is because clinicians are unlikely to follow\n",
      "the logic of the CPR or its recommendations in every case;\n",
      "they may not use the CPR at all, they may not use it cor-\n",
      "rectly, they may deliberately disregard its predictions or\n",
      "suggestions or they may be unable to use it for other rea-\n",
      "sons [ 32]. Measures that are assessed in traditional RCTs\n",
      "include safety, which refers to any adverse events resultingCowley et al. Diagnostic and Prognostic Research            (2019) 3:16 Page 13 of 23\n",
      "\n",
      "Page 14:\n",
      "from the implementation of an intervention, and efficacy,\n",
      "which relates to the extent that an intervention helps to\n",
      "improve patient outcomes, for example by reducing mor-\n",
      "tality rates [ 218]. In addition, Reilly and Evans [ 32]\n",
      "propose that the impact of a CPR is assessed in terms of\n",
      "its ‘safety ’and ‘efficiency ’, where safety is defined as the\n",
      "proportion of patients found to have the outcome of inter-\n",
      "est and who received the appropriate intervention, and ef-\n",
      "ficiency is defined as the proportion of patients without\n",
      "the outcome of interest and who did not receive the inter-\n",
      "vention. The sensitivity and specificity of a CPR will only\n",
      "be the same as its safety and efficiency if clinicians follow\n",
      "the logic and recommendations of the CPR exactly [ 32].\n",
      "Therefore, in an impact analysis study, a CPR may demon-\n",
      "strate more, or less, actual impact than its potential im-\n",
      "pact. The effect of clinicians ’incorrect use of the CPR, or\n",
      "their deviations from its logic or suggestions can provide\n",
      "important insights into its impact under specific circum-\n",
      "stances, and may reveal complex interactions between cli-\n",
      "nicians and the CPR [ 32]. For example, Reilly and\n",
      "colleagues [ 219] found that when clinicians did not con-\n",
      "sult a CPR for suspected acute cardiac ischemia at all, or\n",
      "overruled its recommendations, their decisions were less\n",
      "efficient than if they had followed the CPR in every case.\n",
      "Acceptability of a clinical prediction rule\n",
      "If the use of a CPR is warranted but it is not used, the\n",
      "considerable time, money and effort that goes into its\n",
      "development and evaluation is wasted. Assessing the ac-\n",
      "ceptability of a CPR is therefore crucial for successful\n",
      "implementation. Even valid and reliable CPRs may not\n",
      "be accepted or used by clinicians [ 17]. Impact studies\n",
      "allow researchers to evaluate the acceptability of a CPR\n",
      "to clinicians, patients or others who may use it, as well\n",
      "as its ease of use and barriers to its uptake [ 22]. If a CPR\n",
      "proves to be acceptable, its long-term and widespread\n",
      "dissemination and implementation would be justified; if\n",
      "not, the CPR could undergo modification and further\n",
      "evaluation [ 48]. Acceptability of a CPR and attitudes to-\n",
      "wards it can be determined via survey, qualitative, simu-\n",
      "lation or clinical vignette studies [ 33,48,220 –222]. The\n",
      "validated Ottawa Acceptability of Decision Rules survey\n",
      "instrument can be used both to measure the overall ac-\n",
      "ceptability of a CPR, and to assess specific barriers to its\n",
      "use, which can inform potential improvements to the\n",
      "CPR as well as the design of dedicated implementation\n",
      "strategies [ 48]. Qualitative studies can be invaluable for\n",
      "determining the acceptability of a CPR but are relatively\n",
      "rare [ 200,220,222 –225].\n",
      "Comparison of a clinical prediction rule with unstructured\n",
      "clinical judgement\n",
      "For a CPR to improve the diagnostic accuracy of clini-\n",
      "cians, its performance in distinguishing between patientswith and without the condition of interest should be su-\n",
      "perior to that of unstructured clinical judgement alone.\n",
      "Therefore, a vital metric is the comparison of the accuracy\n",
      "of the CPR-predicted probabilities of disease, or recom-\n",
      "mended decisions, with the accuracy of clinicians own es-\n",
      "timated disease probabilities or management decisions\n",
      "[18]. The sensitivity and specificity of clinicians ’predic-\n",
      "tions or decisions are generally measured under usual\n",
      "practice, and compared to the sensitivity and specificity of\n",
      "the CPR predictions or decisions when applied to the\n",
      "same patients [ 226,227]. Some studies have used clinical\n",
      "vignettes [ 228] while others have used multivariable logis-\n",
      "tic models to assess the added value of a CPR over and\n",
      "above clinical judgement alone [ 229]. If it can be demon-\n",
      "strated that the performance of a CPR is superior to un-\n",
      "aided clinician judgement, this may aid clinicians ’\n",
      "acceptance and use of the CPR [ 32]. Although comparison\n",
      "of a CPR to clinician suspicion regularly takes place at the\n",
      "impact analysis stage, some researchers have recom-\n",
      "mended that this is carried out during the derivation or\n",
      "validation stages, arguing that if the CPR does not add\n",
      "anything beyond clinical judgement, then the use of the\n",
      "CPR and an impact study would not be warranted [ 230].\n",
      "In addition, Finnerty and colleagues [ 231] recommend\n",
      "that comparison is undertaken in multiple settings, as the\n",
      "performance of a CPR may be superior to clinical judge-\n",
      "ment in certain settings, but inferior or no different in\n",
      "other settings. A recent systematic review comparing\n",
      "CPRs with clinical judgement concluded that the differ-\n",
      "ences between the two methods of judgement are likely\n",
      "due to different diagnostic thresholds, and that the pre-\n",
      "ferred judgement method in a given situation would\n",
      "therefore depend on the relative benefits and harms\n",
      "resulting from true positive and false positive diagnoses\n",
      "[232]. Brown and colleagues ’[200] found that the use and\n",
      "potential advantages of a CPR may be much more com-\n",
      "plex than originally thought, and that CPRs may be useful\n",
      "for purposes not previously reported, such as enhancing\n",
      "communication with colleagues and patients, and medico-\n",
      "legal purposes. Recent studies in the child protection field\n",
      "have demonstrated that CPRs may provide clinicians with\n",
      "additional confidence in their decision-making, even if\n",
      "they do not alter their management actions based on the\n",
      "CPRs risk prediction [ 220,233].\n",
      "The four phases of impact analysis for clinical prediction\n",
      "rules\n",
      "Despite the abundance of methodological guidelines for\n",
      "the derivation and validation of CPRs [ 26], there is a lack\n",
      "of clear guidance for the design, conduct and reporting\n",
      "of impact analysis studies of CPRs. To this end, Wallace\n",
      "and colleagues [ 33] formulated an iterative four-phased\n",
      "framework for the impact analysis of CPRs, specifying\n",
      "the importance of substantial preparatory and feasibilityCowley et al. Diagnostic and Prognostic Research            (2019) 3:16 Page 14 of 23\n",
      "\n",
      "Page 15:\n",
      "work prior to the conduct of a full-scale formal experi-\n",
      "mental study (Fig. 2). Phase 1 involves determining\n",
      "whether the CPR is ready for impact analysis, i.e.\n",
      "whether it has been rigorously derived and broadly vali-\n",
      "dated according to pre-defined methodological stan-\n",
      "dards. Phase 2 includes assessing the acceptability of the\n",
      "CPR and identifying potential barriers to its uptake and\n",
      "implementation, as well as assessing the feasibility of\n",
      "conducting an impact study. Evaluating the feasibility of\n",
      "carrying out an impact study involves consideration of\n",
      "multiple factors including the most appropriate study\n",
      "design for measuring relevant outcomes, and how the\n",
      "CPR will be delivered at the point of care or integrated\n",
      "into the clinical workflow. Phase 3 involves formally test-\n",
      "ing the impact of the CPR using a comparative study de-\n",
      "sign. Phase 4 involves long-term dissemination and\n",
      "implementation of the CPR, which corresponds to stage\n",
      "6 in the development of CPRs, discussed below.\n",
      "Reporting the impact analysis of a clinical prediction rule\n",
      "There are currently no published reporting guidelines\n",
      "for studies analysing the impact of CPRs. This is a gap\n",
      "in the literature, and a priority for future research. How-\n",
      "ever, researchers assessing the impact of CPRs in an\n",
      "RCT may refer to guidelines on the reporting of clinical\n",
      "trials, such as the Consolidated Standards of Reporting\n",
      "Trials (CONSORT) statement [ 218].Stage 5: cost-effectiveness of the clinical prediction rule\n",
      "If an impact analysis study shows that a CPR demon-\n",
      "strates safety and efficiency, alters clinician behaviour\n",
      "and improves clinical care, a formal economic evaluation\n",
      "can be carried out to determine the cost-effectiveness of\n",
      "the CPR. The aim is to establish the health care savings\n",
      "associated with routine use of the CPR in clinical prac-\n",
      "tice [ 17]. Economic evaluation is usually based on deci-\n",
      "sion analytic models [ 234]. Any economic evaluation\n",
      "must make reasonable assumptions about the accuracy\n",
      "and effectiveness of the CPR and the costs involved [ 17].\n",
      "Sensitivity analyses should be performed by re-running\n",
      "models with alternative assumptions, to examine the un-\n",
      "certainty of the model projections [ 234]. In reality, many\n",
      "economic evaluations are conducted prior to an impact\n",
      "analysis study or even an external validation study, per-\n",
      "haps because they are relatively quick and low cost to\n",
      "perform, and provide a significant part of the justifica-\n",
      "tion for the development and implementation of a CPR.\n",
      "Stage 6: long-term implementation and dissemination of\n",
      "the clinical prediction rule\n",
      "The gap between evidence and practice has been con-\n",
      "sistently demonstrated in health services research [ 235],\n",
      "and there is no guarantee that a CPR will be widely dis-\n",
      "seminated or used, even if it is shown to have a positive\n",
      "impact on clinical care and cost benefits. Therefore, in\n",
      "order to maximise the uptake of a CPR, an active\n",
      "Fig. 2 The four phases of impact analysis for a clinical prediction rule. Reproduced with permission from Wallace et al. 2011 [ 33]Cowley et al. Diagnostic and Prognostic Research            (2019) 3:16 Page 15 of 23\n",
      "\n",
      "Page 16:\n",
      "dissemination and implementation plan must be in\n",
      "place. Simple passive diffusion of study results via publi-\n",
      "cation in journals or presentations at conferences is un-\n",
      "likely to significantly change clinical practice [ 236].\n",
      "Examples of dissemination include actively targeting spe-\n",
      "cific audiences via direct mail or the press, while imple-\n",
      "mentation involves the use of local administrative,\n",
      "educational, organisational and behavioural strategies to\n",
      "put the CPR into effect in clinical practice [ 236]. Active\n",
      "broad dissemination of the widely accepted Ottawa ankle\n",
      "rule via an educational intervention found no impact of\n",
      "the rule on clinicians ’use of ankle radiography [ 237], lead-\n",
      "ing the authors to recommend implementation strategies\n",
      "at the local level instead. Some implementation strategies\n",
      "have been found to be more effective than others in chan-\n",
      "ging clinician behaviour. A systematic review found the\n",
      "most effective approaches to be reminders in the form of\n",
      "posters, pocket cards, sheets or computer-embedded\n",
      "prompts, face-to-face local clinician education and the use\n",
      "of multiple interventions simultaneously [ 238]. Incorpor-\n",
      "ation of CPRs into clinical guidelines may also be of bene-\n",
      "fit; a recent study found that clinical guidelines and local\n",
      "policies that mandated the use of CPRs were effective in\n",
      "increasing their adoption in clinical practice [ 200]. In\n",
      "addition, the integration of CPRs into the clinical work-\n",
      "flow via electronic health records may promote their use\n",
      "[239]. Since impact in a research study does not ensure\n",
      "impact in real-world clinical practice, follow-up of clini-\n",
      "cians can be conducted to assess the long-term use and ef-\n",
      "fect of the CPR [ 17,33].\n",
      "Barriers and facilitators to the use of clinical prediction\n",
      "rules\n",
      "Clearly, identifying the barriers and facilitators to the imple-\n",
      "mentation of CPRs is crucial for the development of tar-\n",
      "geted implementation strategies that may encourageTable 4 Barriers to the use of clinical prediction rules in practice\n",
      "identified in the literature\n",
      "Theme Subtheme Barrier\n",
      "Knowledge Awareness Unaware:\n",
      "That CPR exists\n",
      "Of clinical problem or burden of clinical\n",
      "problem to which CPR applies\n",
      "Unable to choose from multiple CPRs\n",
      "Familiarity Unfamiliar with CPR\n",
      "Understanding Lack of knowledge and understanding of the\n",
      "purpose, development and application of CPRs in\n",
      "general\n",
      "Forgetting Clinician forgets to use CPR despite best\n",
      "intentions\n",
      "Attitudes Negative beliefs\n",
      "about CPRsBelief that:\n",
      "CPRs threaten autonomy\n",
      "CPRs are too ‘cook-book ’, and oversimplify the\n",
      "clinical assessment process\n",
      "Clinical judgement is superior to CPRs\n",
      "Clinical judgement is not error prone\n",
      "Use of CPRs causes intellectual laziness\n",
      "The development of the CPR was biased\n",
      "Patients will deem clinicians less capable if\n",
      "using a CPR\n",
      "CPRs only apply to the less experienced\n",
      "Probabilities are not helpful for decision-making\n",
      "Dislike of the term ‘rule ’\n",
      "Clinician had a false negative result when using a\n",
      "CPR in the past\n",
      "Existing CPRs are not ready for clinical application\n",
      "Outcome\n",
      "expectancyBelief that:\n",
      "CPRs will not lead to improved patient or\n",
      "process outcomes\n",
      "The information provided by the CPR is not\n",
      "sufficient to alter clinical decisions\n",
      "Clinician:\n",
      "Fears unintended consequences of use\n",
      "Is uncertain about using the CPR in patients\n",
      "with an atypical presentation\n",
      "Worries that improving efficiency threatens\n",
      "patient safety\n",
      "Self-efficacy Belief that the CPR is too difficult to use\n",
      "Clinician uncertain how to interpret or use CPR\n",
      "output\n",
      "Motivation Clinician lacks motivation to use the CPR\n",
      "Behaviour Patient factors Patients expectations are not consistent with the\n",
      "CPR\n",
      "Features of the\n",
      "CPRClinician:\n",
      "Finds CPR too complicated\n",
      "Finds CPR ‘too much trouble ’to apply\n",
      "Perception that:\n",
      "The CPR is not an efficient use of time\n",
      "The CPR does not have face validity or that\n",
      "important predictors are missing\n",
      "The CPR does not fit in with usual work flow or\n",
      "approach to decision-makingTable 4 Barriers to the use of clinical prediction rules in practice\n",
      "identified in the literature (Continued)\n",
      "Theme Subtheme Barrier\n",
      "The CPR is not generalisable to the clinician ’s\n",
      "patient\n",
      "The CPR is static and does not consider the\n",
      "dynamic nature of clinical practice\n",
      "Overruling the CPR is often justified\n",
      "Data required for the CPR is difficult to obtain\n",
      "Environmental\n",
      "factorsLack of:\n",
      "Time\n",
      "Organisational support\n",
      "Peer support for use\n",
      "Perceived increased risk of litigation\n",
      "Insufficient incentives or reimbursement for use\n",
      "of the CPR\n",
      "Adapted from Sanders 2015 [ 253].CPR clinical prediction ruleCowley et al. Diagnostic and Prognostic Research            (2019) 3:16 Page 16 of 23\n",
      "\n",
      "Page 17:\n",
      "clinicians to use the CPR. The adoption of CPRs into clinical\n",
      "practice is influenced by various factors including clinician\n",
      "characteristics, patient factors, features of the CPR itself and\n",
      "environmental factors [ 32,66,221,224,225,240 –252].\n",
      "Table 4provides an overview of the barriers to the adop-\n",
      "tion of CPRs identified in the literature [ 253], grouped ac-\n",
      "cording to their effect on clinician knowledge, attitudes or\n",
      "behaviours [ 254]. Barriers relating to knowledge include\n",
      "lack of awareness of the CPR or the burden of the clinical\n",
      "problem it applies to, unfamiliarity with the CPR and a\n",
      "lack of understanding of the purpose of CPRs in general\n",
      "[225,240 –242]. Clinicians may also be unaware of a CPR\n",
      "due to the increasing volume of CPRs, particularly when\n",
      "they are developed for the same condition [ 61,243]. Com-\n",
      "mon barriers relating to clinician attitude include a con-\n",
      "viction that clinical judgement is superior to the CPR, and\n",
      "distrust of the accuracy of the CPR [ 32,224,240,241,244,\n",
      "245]. Barriers relating to behaviour include organisational\n",
      "factors [ 251], the complexity of the CPR and the time it\n",
      "takes to apply; survey studies suggest that clinicians much\n",
      "prefer a CPR that is simple to use, memorable and saves\n",
      "time [ 221,246,247]. Complex models such as those based\n",
      "on machine and artificial learning algorithms may intro-\n",
      "duce additional barriers relating to applicability and us-\n",
      "ability, due to their potential lack of reproducibility and\n",
      "transparency [ 60,82]. Other studies have demonstrated\n",
      "that clinicians will be unlikely to use a CPR if there are\n",
      "predictors missing which are deemed to be important, or\n",
      "if the predictor variables are not logically related to the\n",
      "outcome variable [ 32,225]. Reilly and Evans [ 32] offer a\n",
      "number of strategies for overcoming barriers to the use of\n",
      "CPRs. These include emphasising the discretionary use of\n",
      "the CPR, comparing clinical judgement with the CPR,\n",
      "checking whether any excluded factors affect the CPR pre-\n",
      "dictions, performing a simulated impact analysis and soli-\n",
      "citing clinicians input regarding the logic and format of\n",
      "the CPR, among others [ 32].\n",
      "Summary\n",
      "For CPRs to be useful in clinical practice, they must be\n",
      "properly planned [ 67], derived using appropriate statistical\n",
      "techniques [ 23] and externally validated in multiple set-\n",
      "tings and by independent investigators to determine their\n",
      "predictive accuracy [ 148]. In addition, CPRs must undergo\n",
      "impact analysis to determine their effect on clinician be-\n",
      "haviour and relevant patient outcomes [ 22]. There are nu-\n",
      "merous factors to consider when deriving, validating and\n",
      "assessing the impact of a CPR including the study design,\n",
      "preparatory work, statistical analysis, modelling strategy,\n",
      "performance/impact measures, the presentation of the\n",
      "CPR and the reporting of the study methodology. New\n",
      "CPRs should only be derived when there is a clear clinical\n",
      "need for them [ 17]. There is an urgent need to change the\n",
      "focus from the derivation of CPRs, to the validation andimpact analysis of existing ones [ 33]. The CPR must be\n",
      "presented in full, and the study methods reported ad-\n",
      "equately, to ensure its quality, risk of bias and clinical util-\n",
      "ity can be evaluated; the TRIPOD guidelines should be\n",
      "followed to ensure completeness of reporting require-\n",
      "ments [ 36]. Feasibility and preparatory work is essential to\n",
      "determine whether a formal impact study of the CPR is\n",
      "warranted [ 33,108], and survey and qualitative work\n",
      "should be undertaken to verify whether the CPR is accept-\n",
      "able and relevant to clinicians [ 48,65,220,222]. If a CPR\n",
      "is found to have a positive impact on patient outcomes, its\n",
      "cost-effectiveness should be evaluated, and a targeted im-\n",
      "plementation and dissemination strategy devised, with\n",
      "consideration of possible barriers to implementation, to\n",
      "maximise uptake [ 17].\n",
      "In summary, the development and evaluation of a ro-\n",
      "bust, clinically useful CPR with high predictive accuracy\n",
      "is challenging, and research in the field concerning der-\n",
      "ivation, validation and impact evaluation continues to\n",
      "evolve. However, adhering to the existing methodological\n",
      "standards and recommendations in the literature at\n",
      "every step will help to ensure a rigorous CPR that has\n",
      "the potential to contribute usefully to clinical practice\n",
      "and decision-making.\n",
      "Abbreviations\n",
      "AUROC: Area under the receiver operating characteristic curve; CPR: Clinical\n",
      "prediction rule; EPV: Events per variable; IDI: Integrated discrimination\n",
      "improvement; MAR: Missing at random; MCAR: Missing completely at\n",
      "random; MNAR: Missing not at random; NRI: Net reclassification\n",
      "improvement; RCT: Randomised controlled trial; ROC: Receiver operating\n",
      "characteristic curve; TRIPOD: Transparent Reporting of a multivariable\n",
      "prediction model for Individual Prognosis or Diagnosis\n",
      "Acknowledgements\n",
      "We would like to thank Health and Care Research Wales for funding this\n",
      "work.\n",
      "Funding\n",
      "This work was supported by Health and Care Research Wales (grant number\n",
      "HS-14-24). The funders had no involvement in the study design, the collec-\n",
      "tion, analysis or interpretation of the data, the writing of the manuscript or\n",
      "the decision to submit the manuscript for publication.\n",
      "Availability of data and materials\n",
      "Not applicable.\n",
      "Authors ’contributions\n",
      "LEC conducted the literature search, drafted the manuscript, produced the\n",
      "tables, boxes and figures and edited the manuscript. DMF, SM and AMK\n",
      "critically revised the manuscript for important intellectual content. All authors\n",
      "approved the final version submitted for publication.\n",
      "Ethics approval and consent to participate\n",
      "Not applicable.\n",
      "Consent for publication\n",
      "Not applicable.\n",
      "Competing interests\n",
      "The authors declare that they have no competing interests.Cowley et al. Diagnostic and Prognostic Research            (2019) 3:16 Page 17 of 23\n",
      "\n",
      "Page 18:\n",
      "Publisher ’sN o t e\n",
      "Springer Nature remains neutral with regard to jurisdictional claims in\n",
      "published maps and institutional affiliations.\n",
      "Received: 13 August 2018 Accepted: 12 May 2019\n",
      "References\n",
      "1. Adams ST, Leveson SH. Clinical prediction rules. BMJ. 2012;344:d8312.\n",
      "2. Beattie P, Nelson R. Clinical prediction rules: what are they and what do\n",
      "they tell us? Aust J Physiother. 2006;52(3):157 –63.\n",
      "3. Laupacis A, Sekar N, Stiell IG. Clinical prediction rules. A review and suggested\n",
      "modifications of methodological standards. JAMA. 1997;277(6):488 –94.\n",
      "4. McGinn TG, Guyatt GH, Wyer PC, Naylor CD, Stiell IG, Richardson WS. Users'\n",
      "guides to the medical literature: XXII: how to use articles about clinical decision\n",
      "rules. Evidence-based medicine working group. JAMA. 2000;284(1):79 –84.\n",
      "5. Hendriksen JM, Geersing GJ, Moons KG, de Groot JA. Diagnostic and\n",
      "prognostic prediction models. J Thromb Haemost. 2013;11(Suppl 1):129 –41.\n",
      "6. Bouwmeester W, Zuithoff NP, Mallett S, Geerlings MI, Vergouwe Y,\n",
      "Steyerberg EW, et al. Reporting and methods in clinical prediction research:\n",
      "a systematic review. PLoS Med. 2012;9(5):1 –12.\n",
      "7. Mallett S, Royston P, Dutton S, Waters R, Altman DG. Reporting methods in\n",
      "studies developing prognostic models i n cancer: a review. BMC Med. 2010;8:20.\n",
      "8. Collins GS, Mallett S, Omar O, Yu L-M. Developing risk prediction\n",
      "models for type 2 diabetes: a systematic review of methodology and\n",
      "reporting. BMC Med. 2011;9:103.\n",
      "9. Collins GS, de Groot JA, Dutton S, Omar O, Shanyinde M, Tajar A, et al. External\n",
      "validation of multivariable prediction models: a systematic review of\n",
      "methodological conduct and reporting. BMC Med Res Methodol. 2014;14:40.\n",
      "10. Kleinrouweler CE, Cheong-See FM, Collins GS, Kwee A, Thangaratinam S,\n",
      "Khan KS, et al. Prognostic models in obstetrics: available, but far from\n",
      "applicable. Am J Obstet Gynecol. 2016;214(1):79 –90 e36.\n",
      "11. Ettema RG, Peelen LM, Schuurmans MJ, Nierich AP, Kalkman CJ, Moons KG.\n",
      "Prediction models for prolonged intensive care unit stay after cardiac surgery:\n",
      "systematic review and validation study. Circulation. 2010;122(7):682 –9.\n",
      "12. Collins GS, Omar O, Shanyinde M, Yu LM. A systematic review finds prediction\n",
      "models for chronic kidney disease were poorly reported and often developed\n",
      "using inappropriate methods. J Clin Epidemiol. 2013;66(3):268 –77.\n",
      "13. Nayak S, Edwards DL, Saleh AA, Greenspan SL. Performance of risk\n",
      "assessment instruments for predicting osteoporotic fracture risk: a\n",
      "systematic review. Osteoporos Int. 2014;25(1):23 –49.\n",
      "14. Altman DG. Prognostic models: a methodological framework and review of\n",
      "models for breast cancer. Cancer Investig. 2009;27(3):235 –43.\n",
      "15. Collins GS, Michaelsson K. Fracture risk assessment: state of the art,\n",
      "methodologically unsound, or poorly reported? Curr Osteoporos Rep.\n",
      "2012;10(3):199 –207.\n",
      "16. Wasson JH, Sox HC, Neff RK, Goldman L. Clinical prediction rules. Applications\n",
      "and methodological standards. N Engl J Med. 1985;313(13):793 –8.\n",
      "17. Stiell I, Wells G. Methodologic standards for the development of clinical\n",
      "decision rules in emergency medicine. Ann Emerg Med. 1999;33(4):437 –47.\n",
      "18. Green SM, Schriger DL, Yealy DM. Methodologic standards for interpreting\n",
      "clinical decision rules in emergency medicine: 2014 update. Ann Emerg\n",
      "Med. 2014;64(3):286 –91.\n",
      "19. Steyerberg EW, Vergouwe Y. Towards better clinical prediction models:\n",
      "seven steps for development and an ABCD for validation. Eur Heart J.\n",
      "2014;35(29):1925 –31.\n",
      "20. Altman DG, Vergouwe Y, Royston P, Moons KG. Prognosis and prognostic\n",
      "research: validating a prognostic model. BMJ. 2009;338:b605.\n",
      "21. Moons KG, Royston P, Vergouwe Y, Grobbee DE, Altman DG. Prognosis and\n",
      "prognostic research: what, why, and how? BMJ. 2009;338:b375.\n",
      "22. Moons KG, Altman DG, Vergouwe Y, Royston P. Prognosis and prognostic\n",
      "research: application and impact of prognostic models in clinical practice.\n",
      "BMJ. 2009;338:b606.\n",
      "23. Moons KG, Kengne AP, Woodward M, Royston P, Vergouwe Y, Altman DG,\n",
      "Grobbee DE. Risk prediction models: I. development, internal validation, and\n",
      "assessing the incremental value of a new (bio)marker. Heart. 2012;98(9):683 –90.\n",
      "24. Moons KG, Kengne AP, Grobbee DE, Royston P, Vergouwe Y, Altman DG,\n",
      "Woodward M. Risk prediction models: II. External validation, model\n",
      "updating, and impact assessment. Heart. 2012;98(9):691 –8.\n",
      "25. Royston P, Moons KGM, Altman DG, Vergouwe Y. Prognosis and prognostic\n",
      "research: developing a prognostic model. BMJ. 2009;338:b604.26. Steyerberg E. Clinical prediction models: a practical approach to\n",
      "development, validation and updating. New York: Springer-Verlag; 2009.\n",
      "27. Steyerberg EW, Moons KG, van der Windt DA, Hayden JA, Perel P, Schroter\n",
      "S, et al. Prognosis research strategy (PROGRESS) 3: prognostic model\n",
      "research. PLoS Med. 2013;10(2):e1001381.\n",
      "28. Altman DG, Royston P. What do we mean by validating a prognostic\n",
      "model? Stat Med. 2000;19(4):453 –73.\n",
      "29. Harrell F. Regression modeling strategies: with applications to linear models,\n",
      "logistic regression, and survival analysis. New York: Springer; 2001.\n",
      "30. Wynants L, Collins GS, Van Calster B. Key steps and common pitfalls in\n",
      "developing and validating risk models. BJOG. 2017;124(3):423 –32.\n",
      "31. Collins GS, Ma J, Gerry S, Ohuma E, Odondi LO, Trivella M, et al. Risk\n",
      "prediction models in perioperative medicine: methodological\n",
      "considerations. Curr Anesthesiol Rep. 2016;6(3):267 –75.\n",
      "32. Reilly BM, Evans AT. Translating clinical research into clinical practice: impact of\n",
      "using prediction rules to make decisions. Ann Intern Med. 2006;144(3):201 –9.\n",
      "33. Wallace E, Smith SM, Perera-Salazar R, Vaucher P, McCowan C, Collins G, et\n",
      "al. Framework for the impact analysis and implementation of clinical\n",
      "prediction rules (CPRs). BMC Med Inform Decis Mak. 2011;11:62.\n",
      "34. Debray TP, Vergouwe Y, Koffijberg H, Nieboer D, Steyerberg EW, Moons KG.\n",
      "A new framework to enhance the interpretation of external validation\n",
      "studies of clinical prediction models. J Clin Epidemiol. 2015;68(3):279 –89.\n",
      "35. Debray TP, Damen JA, Riley RD, Snell K, Reitsma JB, Hooft L, et al. A\n",
      "framework for meta-analysis of prediction model studies with binary and\n",
      "time-to-event outcomes. Stat Methods Med Res. 2018. https://doi.org/10.\n",
      "1177/0962280218785504 .\n",
      "36. Moons KG, Altman DG, Reitsma JB, Ioannidis JP, Macaskill P, Steyerberg EW,\n",
      "et al. Transparent reporting of a multivariable prediction model for\n",
      "individual prognosis or diagnosis (TRIPOD): explanation and elaboration.\n",
      "Ann Intern Med. 2015;162(1):W1 –W73.\n",
      "37. Lo BWY, Fukuda H, Nishimura Y, Farrokhyar F, Thabane L, Levine MAH.\n",
      "Systematic review of clinical prediction tools and prognostic factors in\n",
      "aneurysmal subarachnoid hemorrhage. Surg Neurol Int. 2015;6:135.\n",
      "38. Hopper AD, Cross SS, Hurlstone DP, McAlindon ME, Lobo AJ, Hadjivassiliou\n",
      "M, et al. Pre-endoscopy serological testing for coeliac disease: evaluation of\n",
      "a clinical decision tool. BMJ. 2007;334:729.\n",
      "39. LaValley MP, Lo GH, Price LL, Driban JB, Eaton CB, McAlindon TE.\n",
      "Development of a clinical prediction algorithm for knee osteoarthritis\n",
      "structural progression in a cohort study: value of adding measurement of\n",
      "subchondral bone density. Arthritis Res Ther. 2017;19:95.\n",
      "40. Steyerberg EW, Mushkudiani N, Perel P, Butcher I, Lu J, McHugh GS, et al.\n",
      "Predicting outcome after traumatic brain injury: development and\n",
      "international validation of prognostic scores based on admission\n",
      "characteristics. PLoS Med. 2008;5(8):e165.\n",
      "41. Ferro JM, Bacelar-Nicolau H, Rodrigues T, Bacelar-Nicolau L, Canhão P,\n",
      "Crassard I, et al. Risk score to predict the outcome of patients with cerebral\n",
      "vein and dural sinus thrombosis. Cerebrovasc Dis. 2009;28(1):39 –44.\n",
      "42. Woo J, Leung J, Wong S, Kwok T, Lee J, Lynn H. Development of a simple\n",
      "scoring tool in the primary care setting for prediction of recurrent falls in\n",
      "men and women aged 65 years and over living in the community. J Clin\n",
      "Nurs. 2009;18(7):1038 –48.\n",
      "43. Scholz NN, Bäsler KK, Saur PP, Burchardi HH, Felder SS. Outcome prediction\n",
      "in critical care: physicians' prognoses vs. scoring systems. Eur J Anaesthesiol.\n",
      "2004;21(8):606 –11.\n",
      "44. Kheterpal S, Tremper KK, Heung M, Rosenberg AL, Englesbe M, Shanks AM,\n",
      "Campbell DA. Development and validation of an acute kidney injury risk\n",
      "index for patients undergoing general surgery results from a national data\n",
      "set. Anesthesiology. 2009;110(3):505 –15.\n",
      "45. Pace N, Eberhart L, Kranke P. Quantifying prognosis with risk predictions. Eur\n",
      "J Anaesthesiol. 2012;29(1):7 –16.\n",
      "46. Steyerberg EW, Vickers AJ, Cook NR, Gerds T, Gonen M, Obuchowski N, et al.\n",
      "Assessing the performance of prediction models: a framework for some\n",
      "traditional and novel measures. Epidemiology. 2010;21(1):128 –38.\n",
      "47. McGinn T. Putting meaning into meaningful use: a roadmap to successful\n",
      "integration of evidence at the point of care. JMIR Med Inform. 2016;4(2):e16.\n",
      "48. Brehaut JC, Graham ID, Wood TJ, Taljaard M, Eagles D, Lott A, et al.\n",
      "Measuring acceptability of clinical decision rules: validation of the Ottawa\n",
      "acceptability of decision rules instrument (OADRI) in four countries. Med\n",
      "Decis Mak. 2010;30(3):398 –408.\n",
      "49. Sarasin FP, Reymond JM, Griffith JL, Beshansky JR, Schifferli JA, Unger PF, et\n",
      "al. Impact of the acute cardiac ischemia time-insensitive predictiveCowley et al. Diagnostic and Prognostic Research            (2019) 3:16 Page 18 of 23\n",
      "\n",
      "Page 19:\n",
      "instrument (ACI-TIPI) on the speed of triage decision making for emergency\n",
      "department patients presenting with chest pain: a controlled clinical trial. J\n",
      "Gen Intern Med. 1994;9(4):187 –94.\n",
      "50. Stiell IG, McDowell I, Nair RC, Aeta H, Greenberg G, McKnight RD, Ahuja J.\n",
      "Use of radiography in acute ankle injuries: physicians' attitudes and practice.\n",
      "CMAJ. 1992;147(11):1671 –8.\n",
      "51. Stiell IG, McKnight R, Greenberg GH, McDowell I, Nair RC, Wells GA, et al.\n",
      "Implementation of the Ottawa ankle rules. JAMA. 1994;271(11):827 –32.\n",
      "52. Anis AH, Stiell IG, Stewart DG, Laupacis A. Cost-effectiveness analysis of the\n",
      "Ottawa ankle rules. Ann Emerg Med. 1995;26(4):422 –8.\n",
      "53. Graham ID, Stiell IG, Laupacis A, McAuley L, Howell M, Clancy M, et al.\n",
      "Awareness and use of the Ottawa ankle and knee rules in 5 countries:\n",
      "can publication alone be enough to change practice? Ann Emerg Med.\n",
      "2001;37(3):259 –66.\n",
      "54. Damen JA, Hooft L, Schuit E, Debray TP, Collins GS, Tzoulaki I, et al.\n",
      "Prediction models for cardiovascular disease risk in the general population:\n",
      "systematic review. BMJ. 2016;353:i2416.\n",
      "55. Shariat SF, Karakiewicz PI, Margulis V, Kattan MW. Inventory of prostate\n",
      "cancer predictive tools. Curr Opin Urol. 2008;18(3):279 –96.\n",
      "56. Perel P, Edwards P, Wentz R, Roberts I. Systematic review of prognostic\n",
      "models in traumatic brain injury. BMC Med Inform Decis Mak. 2006;6:38.\n",
      "57. Wessler BS, Lai Yh L, Kramer W, Cangelosi M, Raman G, Lutz JS, Kent DM.\n",
      "Clinical prediction models for cardiovascular disease: tufts predictive\n",
      "analytics and comparative effectiveness clinical prediction model database.\n",
      "Circ Cardiovasc Qual Outcomes. 2015;8(4):368 –75.\n",
      "58. Geersing GJ, Bouwmeester W, Zuithoff P, Spijker R, Leeflang M, Moons KG.\n",
      "Search filters for finding prognostic and diagnostic prediction studies in\n",
      "Medline to enhance systematic reviews. PLoS One. 2012;7(2):e32844.\n",
      "59. Moons KG, de Groot JA, Bouwmeester W, Vergouwe Y, Mallett S,\n",
      "Altman DG, et al. Critical appraisal and data extraction for systematic\n",
      "reviews of prediction modelling studies: the CHARMS checklist. PLoS\n",
      "Med. 2014;11(10):e1001744.\n",
      "60. Moons KM, Wolff RF, Riley RD, Whiting PF, Westwood M, Collins GS, et al.\n",
      "PROBAST: a tool to assess risk of bias and applicability of prediction model\n",
      "studies: explanation and elaboration. Ann Intern Med. 2019;170(1):W1 –W33.\n",
      "61. Collins GS, Moons KG. Comparing risk prediction models. BMJ. 2012;344:e3186.\n",
      "62. Dekker FW, Ramspek CL, van Diepen M. Con: most clinical risk scores are\n",
      "useless. Nephrol Dial Transplant. 2017;32(5):752 –5.\n",
      "63. Masconi K, Matsha T, Erasmus R, Kengne A. Recalibration in validation\n",
      "studies of diabetes risk prediction models: a systematic review. Int J Stat\n",
      "Med Res. 2015;4(4):347 –69.\n",
      "64. Ban JW, Wallace E, Stevens R, Perera R. Why do authors derive new\n",
      "cardiovascular clinical prediction rules in the presence of existing rules? A\n",
      "mixed methods study. PLoS One. 2017;12(6):e0179102.\n",
      "65. de Salis I, Whiting P, Sterne JA, Hay AD. Using qualitative research to\n",
      "inform development of a diagnostic algorithm for UTI in children. Fam\n",
      "Pract. 2013;30(3):325 –31.\n",
      "66. Haskins R, Osmotherly PG, Southgate E, Rivett DA. Australian\n",
      "physiotherapists' priorities for the development of clinical prediction rules\n",
      "for low back pain: a qualitative study. Physiotherapy. 2015;101(1):44 –9.\n",
      "67. Peat G, Riley RD, Croft P, Morley KI, Kyzas PA, Moons KG, et al. Improving\n",
      "the transparency of prognosis research: the role of reporting, data sharing,\n",
      "registration, and protocols. PLoS Med. 2014;11(7):e1001671.\n",
      "68. Altman DG. The time has come to register diagnostic and prognostic\n",
      "research. Clin Chem. 2014;60(4):580 –2.\n",
      "69. Han K, Song K, Choi BW. How to develop, validate, and compare clinical\n",
      "prediction models involving radiological parameters: study design and\n",
      "statistical methods. Korean J Radiol. 2016;17(3):339 –50.\n",
      "70. Lee Y-h, Bang H, Kim DJ. How to establish clinical prediction models.\n",
      "Endocrinol Metab (Seoul). 2016;31(1):38 –44.\n",
      "71. Biesheuvel CJ, Vergouwe Y, Oudega R, Hoes AW, Grobbee DE, Moons KG.\n",
      "Advantages of the nested case-control design in diagnostic research. BMC\n",
      "Med Res Methodol. 2008;8:48.\n",
      "72. Sanderson J, Thompson SG, White IR, Aspelund T, Pennells L. Derivation and\n",
      "assessment of risk prediction models using case-cohort data. BMC Med Res\n",
      "Methodol. 2013;13:113.\n",
      "73. Nee RJ, Coppieters MW. Interpreting research on clinical prediction rules for\n",
      "physiotherapy treatments. Man Ther. 2011;16(2):105 –8.\n",
      "74. Hancock M, Herbert RD, Maher CG. A guide to interpretation of studies\n",
      "investigating subgroups of responders to physical therapy interventions.\n",
      "Phys Ther. 2009;89(7):698 –704.75. Labarère J, Renaud B, Fine MJ. How to derive and validate clinical prediction\n",
      "models for use in intensive care medicine. Intensive Care Med. 2014;40(4):513 –27.\n",
      "76. Grobman WA, Stamilio DM. Methods of clinical prediction. Am J Obstet\n",
      "Gynecol. 2006;194(3):888 –94.\n",
      "77. van den Bosch JE, Kalkman CJ, Vergouwe Y, Van Klei WA, Bonsel GJ, Grobbee\n",
      "DE, Moons KG. Assessing the applicability of scoring systems for predicting\n",
      "postoperative nausea and vomiting. Anaesthesia. 2005;60(4):323 –31.\n",
      "78. Hilbe J. Logistic regression models. Boca Raton: Chapman & Hall/CRC; 2009.\n",
      "79. Marshall RJ. The use of classification and regression trees in clinical\n",
      "epidemiology. J Clin Epidemiol. 2001;54(6):603 –9.\n",
      "80. Stiell IG, Greenberg GH, McKnight RD, Nair RC, McDowell I, Worthington JR.\n",
      "A study to develop clinical decision rules for the use of radiography in\n",
      "acute ankle injuries. Ann Emerg Med. 1992;21(4):384 –90.\n",
      "81. Topol EJ. High-performance medicine: the convergence of human and\n",
      "artificial intelligence. Nat Med. 2019;25(1):44 –56.\n",
      "82. Vollmer S, Mateen BA, Bohner G, Király FJ, Ghani R, Jonsson P, et al. Machine\n",
      "learning and AI research for patient benefit: 20 critical questions on\n",
      "transparency, replicability, ethics and effectiveness. CoRR. 2018; abs/1812.10404.\n",
      "83. Vergouwe Y, Royston P, Moons KG, Altman DG. Development and\n",
      "validation of a prediction model with missing predictor data: a practical\n",
      "approach. J Clin Epidemiol. 2010;63(2):205 –14.\n",
      "84. Little RJA, Rubin DB. Statistical analysis with missing data. New York: Wiley; 2002.\n",
      "85. Sterne JAC, White IR, Carlin JB, Spratt M, Royston P, Kenward MG, et al.\n",
      "Multiple imputation for missing data in epidemiological and clinical\n",
      "research: potential and pitfalls. BMJ. 2009;338:b2393.\n",
      "86. Donders ART, van der Heijden GJMG, Stijnen T, Moons KGM. Review: a\n",
      "gentle introduction to imputation of missing values. J Clin Epidemiol.\n",
      "2006;59(10):1087 –91.\n",
      "87. Moons KGM, Donders RART, Stijnen T, Harrell FE. Using the outcome for\n",
      "imputation of missing predictor values was preferred. J Clin Epidemiol.\n",
      "2006;59(10):1092 –101.\n",
      "88. Janssen KJM, Donders ART, Harrell FE, Vergouwe Y, Chen Q, Grobbee DE,\n",
      "Moons KGM. Missing covariate data in medical research: to impute is better\n",
      "than to ignore. J Clin Epidemiol. 2010;63(7):721 –7.\n",
      "89. Pedersen AB, Mikkelsen EM, Cronin-Fenton D, Kristensen NR, Pham TM,\n",
      "Pedersen L, Petersen I. Missing data and multiple imputation in clinical\n",
      "epidemiological research. Clin Epidemiol. 2017;9:157 –66.\n",
      "90. van der Heijden GJMG, Donders AR, Stijnen T, Moons KGM. Imputation of\n",
      "missing values is superior to complete case analysis and the missing-\n",
      "indicator method in multivariable diagnostic research: a clinical example. J\n",
      "Clin Epidemiol. 2006;59(10):1102 –9.\n",
      "91. Rubin DB. Multiple imputation for nonresponse in surveys. New York: Wiley; 1987.\n",
      "92. van Buuren S, Groothuis-Oudshoorn K. Mice: multivariate imputation by\n",
      "chained equations in R. J Stat Softw. 2011;45(3):1 –67.\n",
      "93. White IR, Royston P, Wood AM. Multiple imputation using chained\n",
      "equations: issues and guidance for practice. Stat Med. 2011;30(4):377 –99.\n",
      "94. Collins LM, Schafer JL, Kam CM . A comparison of inclusive and restrictive strategies\n",
      "in modern missing data procedure s. Psychol Metho ds. 2001;6(4):330 –51.\n",
      "95. Graham JW. Missing data analysis: making it work in the real world. Annu\n",
      "Rev Psychol. 2009;60:549 –76.\n",
      "96. Carpenter JR, Kenward MG, White IR. Sensitivity analysis after multiple\n",
      "imputation under missing at random: a weighting approach. Stat Methods\n",
      "Med Res. 2007;16(3):259 –75.\n",
      "97. Demirtas H, Schafer JL. On the performance of random-coefficient pattern-\n",
      "mixture models for non-ignorable drop-out. Stat Med. 2003;22(16):2553 –75.\n",
      "98. Leurent B, Gomes M, Faria R, Morris S, Grieve R, Carpenter JR. Sensitivity\n",
      "analysis for not-at-random missing data in trial-based cost-effectiveness\n",
      "analysis: a tutorial. Pharmacoeconomics. 2018;36(8):889 –901.\n",
      "99. Leacy FP, Floyd S, Yates TA, White IR. Analyses of sensitivity to the missing-\n",
      "at-random assumption using multiple imputation with delta adjustment:\n",
      "application to a tuberculosis/HIV prevalence survey with incomplete HIV-\n",
      "status data. Am J Epidemiol. 2017;185(4):304 –15.\n",
      "100. Héraud-Bousquet V, Larsen C, Carpenter J, Desenclos J-C, Le Strat Y.\n",
      "Practical considerations for sensitivity analysis after multiple imputation\n",
      "applied to epidemiological studies with incomplete data. BMC Med Res\n",
      "Methodol. 2012;12:73.\n",
      "101. Carpenter JR, Kenward MG. MAR methods for quantitative data. In: missing\n",
      "data in randomised controlled trials —a practical guide. Birmingham:\n",
      "National Institute for Health Research; 2008.\n",
      "102. Goldstein H, Carpenter J, Kenward MG, Levin KA. Multilevel models with\n",
      "multivariate mixed response types. Stat Model. 2009;9(3):173 –97.Cowley et al. Diagnostic and Prognostic Research            (2019) 3:16 Page 19 of 23\n",
      "\n",
      "Page 20:\n",
      "103. Schafer JL. Analysis of incomplete multivariate data. London: Chapman\n",
      "& Hall; 1997.\n",
      "104. Dobson A, Diggle P, Henderson R. Joint modelling of longitudinal\n",
      "measurements and event time data. Biostatistics. 2000;1(4):465 –80.\n",
      "105. Rizopoulos D. Joint models for longitudinal and time-to-event data with\n",
      "applications in R. New York: Chapman and Hall/CRC; 2012.\n",
      "106. Marshall A, Altman DG, Holder RL, Royston P. Combining estimates of\n",
      "interest in prognostic modelling studies after multiple imputation: current\n",
      "practice and guidelines. BMC Med Res Methodol. 2009;9:57.\n",
      "107. Marshall A, Altman DG, Holder RL. Comparison of imputation methods for\n",
      "handling missing covariate data when fitting a Cox proportional hazards\n",
      "model: a resampling study. BMC Med Res Methodol. 2010;10:112.\n",
      "108. Kappen TH, van Klei WA, van Wolfswinkel L, Kalkman CJ, Vergouwe Y,\n",
      "Moons KGM. Evaluating the impact of prediction models: lessons learned,\n",
      "challenges, and recommendations. BMC Diagn Progn Res. 2018;2:11.\n",
      "109. Kappen TH, Vergouwe Y, van Klei WA, van Wolfswinkel L, Kalkman CJ,\n",
      "Moons KGM. Adaptation of clinical prediction models for application in\n",
      "local settings. Med Decis Mak. 2012;32(3):E1 –E10.\n",
      "110. Janssen KJM, Vergouwe Y, Donders ART, Harrell FE, Chen Q, Grobbee DE,\n",
      "Moons KGM. Dealing with missing predictor values when applying clinical\n",
      "prediction models. Clin Chem. 2009;55(5):994 –1001.\n",
      "111. Masconi KL, Matsha TE, Erasmus RT, Kengne AP. Effects of different missing\n",
      "data imputation techniques on the performance of undiagnosed diabetes\n",
      "risk prediction models in a mixed-ancestry population of South Africa. PLoS\n",
      "One. 2015;10(9):e0139210.\n",
      "112. Sun GW, Shook TL, Kay GL. Inappropriate use of bivariable analysis to screen\n",
      "risk factors for use in multivariable analysis. J Clin Epidemiol. 1996;49(8):907 –16.\n",
      "113. Steyerberg EW, Eijkemans MJC, Harrell FE, Habbema JDF. Prognostic\n",
      "modeling with logistic regression analysis: in search of a sensible strategy in\n",
      "small data sets. Med Decis Mak. 2001;21(1):45 –56.\n",
      "114. Harrell FEJ, Lee KL, Mark DB. Multivariable prognostic models: issues in\n",
      "developing models, evaluating assumptions and adequacy, and measuring\n",
      "and reducing errors. Stat Med. 1996;15(4):361 –87.\n",
      "115. Shmueli G. To explain or to predict? Stat Sci. 2010;25(3):289 –310.\n",
      "116. Pavlou M, Ambler G, Seaman SR, Guttmann O, Elliott P, King M, Omar RZ.\n",
      "How to develop a more accurate risk prediction model when there are few\n",
      "events. BMJ. 2015;351:h3868.\n",
      "117. Heinze G, Dunkler D. Five myths about variable selection. Transpl Int.\n",
      "2017;30(1):6 –10.\n",
      "118. Peduzzi P, Concato J, Kemper E, Holford TR, Feinstein AR. A simulation study\n",
      "of the number of events per variable in logistic regression analysis. J Clin\n",
      "Epidemiol. 1996;49(12):1373 –9.\n",
      "119. Vittinghoff E, McCulloch CE. Relaxing the rule of ten events per variable in\n",
      "logistic and cox regression. Am J Epidemiol. 2007;165(6):710 –8.\n",
      "120. Courvoisier DS, Combescure C, Agoritsas T, Gayet-Ageron A, Perneger\n",
      "TV. Performance of logistic regression modeling: beyond the number\n",
      "of events per variable, the role of data structure. J Clin Epidemiol.\n",
      "2011;64(9):993 –1000.\n",
      "121. van Smeden M, de Groot JAH, Moons KGM, Collins GS, Altman DG,\n",
      "Eijkemans MJC, Reitsma JB. No rationale for 1 variable per 10 events\n",
      "criterion for binary logistic regression analysis. BMC Med Res\n",
      "Methodol. 2016;16:163.\n",
      "122. van Smeden M, Moons KGM, de Groot JAH, Collins GS, Altman DG,\n",
      "Eijkemans MJC, Reitsma JB. Sample size for binary logistic prediction\n",
      "models: beyond events per variable criteria. Stat Methods Med Res. 2018.\n",
      "https://doi.org/10.1177/0962280218784726 .\n",
      "123. Ogundimu EO, Altman DG, Collins GS. Adequate sample size for developing\n",
      "prediction models is not simply related to events per variable. J Clin\n",
      "Epidemiol. 2016;76:175 –82.\n",
      "124. Battle CE, Hutchings H, Evans PA. Expert opinion of the risk factors for\n",
      "morbidity and mortality in blunt chest wall trauma: results of a national\n",
      "postal questionnaire survey of emergency departments in the United\n",
      "Kingdom. Injury. 2013;44(1):56 –9.\n",
      "125. Sauerbrei W, Royston P, Binder H. Selection of important variables and\n",
      "determination of functional form for continuous predictors in multivariable\n",
      "model building. Stat Med. 2007;26(30):5512 –28.\n",
      "126. Royston P, Altman DG, Sauerbrei W. Dichotomizing continuous predictors in\n",
      "multiple regression: a bad idea. Stat Med. 2006;25(1):127 –41.\n",
      "127. Collins GS, Ogundimu EO, Cook JA, Manach YL, Altman DG. Quantifying the\n",
      "impact of different approaches for handling continuous predictors on the\n",
      "performance of a prognostic model. Stat Med. 2016;35(23):4124 –35.128. Steyerberg EW, Uno H, Ioannidis JPA, van Calster B, Ukaegbu C, Dhingra T,\n",
      "et al. Poor performance of clinical prediction models: the harm of\n",
      "commonly applied methods. J Clin Epidemiol. 2018;98:133 –43.\n",
      "129. Royston P, Sauerbrei W. Multivariable model-building: a pragmatic approach\n",
      "to regression analysis based on fractional polynomials for modelling\n",
      "continuous variables. Chichester: Wiley; 2009.\n",
      "130. Harrell FEJ, Lee KL, Pollock BG. Regression models in clinical studies:\n",
      "determining relationships between predictors and response. J Natl Cancer\n",
      "Inst. 1988;80(15):1198 –202.\n",
      "131. Royston P, Altman DG. Regression using fractional polynomials of\n",
      "continuous covariates: parsimonious parametric modelling. J R Stat Soc Ser\n",
      "C Appl Stat. 1994;43(3):429 –67.\n",
      "132. Ambler G, Seaman S, Omar RZ. An evaluation of penalised survival\n",
      "methods for developing prognostic models with rare events. Stat Med.\n",
      "2012;31(11 –12):1150 –61.\n",
      "133. Le Cessie S, Van Houwelingen JC. Ridge estimators in logistic regression. J R\n",
      "Stat Soc Ser C Appl Stat. 1992;41(1):191 –201.\n",
      "134. Tibshirani R. Regression shrinkage and selection via the lasso. J R Stat Soc\n",
      "Series B Stat Methodol. 1996;58(1):267 –88.\n",
      "135. Hosmer DW, Jovanovic B, Lemeshow S. Best subsets logistic regression.\n",
      "Biometrics. 1989;45(4):1265 –70.\n",
      "136. Mantel N. Why stepdown procedures in variable selection.\n",
      "Technometrics. 1970;12(3):621 –5.\n",
      "137. Moons KG, Biesheuvel CJ, Grobbee DE. Test research versus diagnostic\n",
      "research. Clin Chem. 2004;50(3):473 –6.\n",
      "138. Steyerberg EW, Eijkemans MJC, Habbema JDF. Stepwise selection in small\n",
      "data sets: a simulation study of bias in logistic regression analysis. J Clin\n",
      "Epidemiol. 1999;52(10):935 –42.\n",
      "139. Steyerberg EW, Schemper M, Harrell FE. Logistic regression modeling and\n",
      "the number of events per variable: selection bias dominates. J Clin\n",
      "Epidemiol. 2011;64(12):1464 –5.\n",
      "140. Whittle R, Peat G, Belcher J, Collins GS, Riley RD. Measurement error and timing\n",
      "of predictor values for multivariable risk prediction models are poorly reported.\n",
      "J Clin Epidemiol. 2018. https://doi.org/10.1016/j.jclinepi.2018.05.008 .\n",
      "141. Luijken K, Groenwold RHH, van Calster B, Steyerberg EW, van Smeden M.\n",
      "Impact of predictor measurement heterogeneity across settings on\n",
      "performance of prediction models: a measurement error perspective. arXiv:\n",
      "180610495 [statME]. 2018:arXiv:1806.10495.\n",
      "142. Worster A, Carpenter C. Incorporation bias in studies of diagnostic tests:\n",
      "how to avoid being biased about bias. CJEM. 2008;10(2):174 –5.\n",
      "143. Moons KG, Grobbee DE. When should we remain blind and when\n",
      "should our eyes remain open in diagnostic studies? J Clin Epidemiol.\n",
      "2002;55(7):633 –6.\n",
      "144. Wang LE, Shaw PA, Mathelier HM, Kimmel SE, French B. Evaluating risk-\n",
      "prediction models using data from electronic health records. Ann Appl Stat.\n",
      "2016;10(1):286 –304.\n",
      "145. van Doorn S, Brakenhoff TB, Moons KGM, Rutten FH, Hoes AW,\n",
      "Groenwold RHH, Geersing GJ. The effects of misclassification in routine\n",
      "healthcare databases on the accuracy of prognostic prediction models:\n",
      "a case study of the CHA2DS2-VASc score in atrial fibrillation. BMC\n",
      "Diagn Progn Res. 2017;1:18.\n",
      "146. Bleeker SE, Moll HA, Steyerberg EW, Donders AR, Derksen-Lubsen G,\n",
      "Grobbee DE, Moons KG. External validation is necessary in prediction\n",
      "research: a clinical example. J Clin Epidemiol. 2003;56(9):826 –32.\n",
      "147. Justice AC, Covinsky KE, Berlin JA. Assessing the generalizability of\n",
      "prognostic information. Ann Intern Med. 1999;130(6):515 –24.\n",
      "148. Toll DB, Janssen KJ, Vergouwe Y, Moons KG. Validation, updating and impact\n",
      "of clinical prediction rules: a review. J Clin Epidemiol. 2008;61(11):1085 –94.\n",
      "149. Steyerberg EW, Harrell FE Jr, Borsboom GJ, Eijkemans MJ, Vergouwe Y,\n",
      "Habbema JD. Internal validation of predictive models: efficiency of some\n",
      "procedures for logistic regression analysis. J Clin Epidemiol. 2001;54(8):774 –81.\n",
      "150. Steyerberg EW. Validation in prediction research: the waste by data-splitting.\n",
      "J Clin Epidemiol. 2018. https://doi.org/10.1016/j.jclinepi.2018.07.010 .\n",
      "151. Efron B, Tibshirani R. An introduction to the bootstrap. Boca Raton:\n",
      "Chapman & Hall/CRC; 1993.\n",
      "152. Gerds TA, Cai T, Schumacher M. The performance of risk prediction models.\n",
      "Biom J. 2008;50(4):457 –79.\n",
      "153. Austin PC, Steyerberg EW. Graphical assessment of internal and external\n",
      "calibration of logistic regression models by using loess smoothers. Stat Med.\n",
      "2014;33(3):517 –35.\n",
      "154. Hosmer DW, Lemeshow S. Applied logistic regression. New York: Wiley; 2000.Cowley et al. Diagnostic and Prognostic Research            (2019) 3:16 Page 20 of 23\n",
      "\n",
      "Page 21:\n",
      "155. Van Calster B, Nieboer D, Vergouwe Y, De Cock B, Pencina MJ, Steyerberg\n",
      "EW. A calibration hierarchy for risk models was defined: from utopia to\n",
      "empirical data. J Clin Epidemiol. 2016;74:167 –76.\n",
      "156. Pencina MJ, D'Agostino RBS. Evaluating discrimination of risk prediction\n",
      "models: the C statistic. JAMA. 2015;314(10):1063 –4.\n",
      "157. Hanley JA, McNeil BJ. The meaning and use of the area under a receiver\n",
      "operating characteristic (ROC) curve. Radiology. 1982;143(1):29 –36.\n",
      "158. Baron JA, Sorensen HT. Clinical epidemiology. In: Olsen J, Saracci R,\n",
      "Trichopoulos D, editors. Teaching epidemiology: a guide for teachers in\n",
      "epidemiology, public health and clinical medicine. New York: Oxford\n",
      "University Press; 2010. p. 411 –28.\n",
      "159. Van Calster B, Vickers AJ. Calibration of risk prediction models: impact on\n",
      "decision-analytic performance. Med Decis Mak. 2014;35(2):162 –9.\n",
      "160. Meurer WJ, Tolles J. Logistic regression diagnostics: understanding how well\n",
      "a model predicts outcomes. JAMA. 2017;317(10):1068 –9.\n",
      "161. Parikh R, Mathai A, Parikh S, Chandra Sekhar G, Thomas R.\n",
      "Understanding and using sensitivity , specificity and predictive values.\n",
      "Indian J Ophthalmol. 2008;56(1):45 –50.\n",
      "162. Søreide K. Receiver-operating characteristic curve analysis in diagnostic,\n",
      "prognostic and predictive biomarker research. J Clin Pathol. 2009;62(1):1 –5.\n",
      "163. Ebell MH, Locatelli I, Senn N. A novel approach to the determination of\n",
      "clinical decision thresholds. BMJ Evid Based Med. 2015;20(2):41 –7.\n",
      "164. Vickers AJ, Elkin EB. Decision curve analysis: a novel method for evaluating\n",
      "prediction models. Med Decis Mak. 2006;26(6):565 –74.\n",
      "165. Baker SG, Cook NR, Vickers A, Kramer BS. Using relative utility curves to\n",
      "evaluate risk prediction. J R Stat Soc Ser A Stat Soc. 2009;172(4):729 –48.\n",
      "166. Vickers AJ, Van Calster B, Steyerberg EW. Net benefit approaches to the\n",
      "evaluation of prediction models, molecular markers, and diagnostic\n",
      "tests. BMJ. 2016;352:i6.\n",
      "167. Feldstein DA, Hess R, McGinn T, Mishuris RG, McCullagh L, Smith PD, et al.\n",
      "Design and implementation of electronic health record integrated clinical\n",
      "prediction rules (iCPR): a randomized trial in diverse primary care settings.\n",
      "Implement Sci. 2017;12(1):37.\n",
      "168. Van Belle V, Van Calster B. Visualizing risk prediction models. PLoS One.\n",
      "2015;10(7):e0132614.\n",
      "169. Sullivan LM, Massaro JM, D'Agostino RB. Presentation of multivariate\n",
      "data for clinical use: the Framingham study risk score functions. Stat\n",
      "Med. 2004;23(10):1631 –60.\n",
      "170. Cole TJ. Algorithm AS 281: scaling and rounding regression coefficients to\n",
      "integers. J R Stat Soc Ser C Appl Stat. 1993;42(1):261 –8.\n",
      "171. Maguire JL, Kulik DM, Laupacis A, Kuppermann N, Uleryk EM, Parkin PC.\n",
      "Clinical prediction rules for children: a systematic review. Pediatrics.\n",
      "2011;128(3):e666 –e77.\n",
      "172. Keogh C, Wallace E, O'Brien KK, Galvin R, Smith SM, Lewis C, et al.\n",
      "Developing an international register of clinical prediction rules for use in\n",
      "primary care: a descriptive analysis. Ann Fam Med. 2014;12(4):359 –66.\n",
      "173. Stiell IG, Greenberg GH, Wells GA, McDowell I, Cwinn AA, Smith NA, et al.\n",
      "Prospective validation of a decision rule for the use of radiography in acute\n",
      "knee injuries. JAMA. 1996;275(8):611 –5.\n",
      "174. Vergouwe Y, Steyerberg EW, Eijkemans MJC, Habbema JDF.\n",
      "Substantial effective sample sizes were required for external validation\n",
      "studies of predictive logistic regression models. J Clin Epidemiol.\n",
      "2005;58(5):475 –83.\n",
      "175. Collins GS, Ogundimu EO, Altman DG. Sample size considerations for the\n",
      "external validation of a multivariable prognostic model: a resampling study.\n",
      "Stat Med. 2016;35(2):214 –26.\n",
      "176. Vergouwe Y, Moons KGM, Steyerberg EW. External validity of risk models:\n",
      "use of benchmark values to disentangle a case-mix effect from incorrect\n",
      "coefficients. Am J Epidemiol. 2010;172(8):971 –80.\n",
      "177. van Klaveren D, Gönen M, Steyerberg EW, Vergouwe Y. A new concordance\n",
      "measure for risk prediction models in external validation settings. Stat Med.\n",
      "2016;35(23):4136 –52.\n",
      "178. Ban J-W, Stevens R, Perera R. Predictors for independent external validation\n",
      "of cardiovascular risk clinical prediction rules: cox proportional hazards\n",
      "regression analyses. BMC Diagn Progn Res. 2018;2:3.\n",
      "179. Siontis GCM, Tzoulaki I, Castaldi PJ, Ioannidis JPA. External validation of new\n",
      "risk prediction models is infrequent and reveals worse prognostic\n",
      "discrimination. J Clin Epidemiol. 2015;68(1):25 –34.\n",
      "180. Janssen KJM, Moons KGM, Kalkman CJ, Grobbee DE, Vergouwe Y. Updating\n",
      "methods improved the performance of a clinical prediction model in new\n",
      "patients. J Clin Epidemiol. 2008;61(1):76 –86.181. Ivanov J, Tu JV, Naylor CD. Ready-made, recalibrated, or remodeled? Issues\n",
      "in the use of risk indexes for assessing mortality after coronary artery bypass\n",
      "graft surgery. Circulation. 1999;99(16):2098 –104.\n",
      "182. Steyerberg EW, Borsboom GJ, van Houwelingen HC, Eijkemans MJ,\n",
      "Habbema JD. Validation and updating of predictive logistic regression\n",
      "models: a study on sample size and shrinkage. Stat Med. 2004;23(16):\n",
      "2567 –86.\n",
      "183. DeLong ER, DeLong DM, Clarke-Pearson DL. Comparing the areas under\n",
      "two or more correlated receiver operating characteristic curves: a\n",
      "nonparametric approach. Biometrics. 1988;44(3):837 –45.\n",
      "184. Demler OV, Pencina MJ, D ’Agostino RBS. Misuse of DeLong test to compare\n",
      "AUCs for nested models. Stat Med. 2012;31(23):2577 –87.\n",
      "185. Pencina MJ, D'Agostino RB Sr, D'Agostino RB Jr, Vasan RS. Evaluating the\n",
      "added predictive ability of a new marker: from area under the ROC curve to\n",
      "reclassification and beyond. Stat Med. 2008;27(2):157 –72.\n",
      "186. Van Calster B, Vickers AJ, Pencina MJ, Baker SG, Timmerman D,\n",
      "Steyerberg EW. Evaluation of markers and risk prediction models:\n",
      "overview of relationships between NRI and decision-analytic measures.\n",
      "Med Decis Mak. 2013;33(4):490 –501.\n",
      "187. Leening MJ, Steyerberg EW, Van Calster B, D ’Agostino RB Sr, Pencina MJ.\n",
      "Net reclassification improvement and integrated discrimination\n",
      "improvement require calibrated models: relevance from a marker and\n",
      "model perspective. Stat Med. 2014;33(19):3415 –8.\n",
      "188. Leening MJ, Vedder MM, Witteman JC, Pencina MJ, Steyerberg EW. Net\n",
      "reclassification improvement: computation, interpretation, and\n",
      "controversies: a literature review a nd clinician's guide. Ann Intern Med.\n",
      "2014;160(2):122 –31.\n",
      "189. Pepe MS, Fan J, Feng Z, Gerds T, Hilden J. The net reclassification index\n",
      "(NRI): a misleading measure of prediction improvement even with\n",
      "independent test data sets. Stat Biosci. 2015;7(2):282 –95.\n",
      "190. Burch PM, Glaab WE, Holder DJ, Phillips JA, Sauer JM, Walker EG. Net\n",
      "reclassification index and integrated discrimination index are not\n",
      "appropriate for testing whether a biomarker improves predictive\n",
      "performance. Toxicol Sci. 2017;156(1):11 –3.\n",
      "191. Hilden J, Gerds TA. A note on the evaluation of novel biomarkers: do not\n",
      "rely on integrated discrimination improvement and net reclassification\n",
      "index. Stat Med. 2014;33(19):3405 –14.\n",
      "192. Antolini L, Tassistro E, Valsecchi MG, Bernasconi DP. Graphical\n",
      "representations and summary indicators to assess the performance of risk\n",
      "predictors. Biom J. 2018. https://doi.org/10.1002/bimj.201700186 .\n",
      "193. Siontis GC, Tzoulaki I, Siontis KC, Ioannidis JP. Comparisons of\n",
      "established risk prediction models for cardiovascular disease: systematic\n",
      "review. BMJ. 2012;344:e3318.\n",
      "194. Cook NR. Quantifying the added value of new biomarkers: how and how\n",
      "not. BMC Diagn Progn Res. 2018;2:14.\n",
      "195. Ferrante di Ruffano L, Hyde CJ, McCaffery KJ, Bossuyt PMM, Deeks JJ.\n",
      "Assessing the value of diagnostic tests: a framework for designing and\n",
      "evaluating trials. BMJ. 2012;344:e686.\n",
      "196. White H. Theory-based impact evaluation: principles and practice. J Dev\n",
      "Effect. 2009;1(3):271 –84.\n",
      "197. Moore GF, Audrey S, Barker M, Bond L, Bonell C, Hardeman W, et al. Process\n",
      "evaluation of complex interventions: Medical Research Council guidance.\n",
      "BMJ. 2015;350:h1258.\n",
      "198. Dowding D, Lichtner V, Closs SJ. Using the MRC framework for complex\n",
      "interventions to develop clinical decision support: a case study. Stud Health\n",
      "Technol Inform. 2017;235:544-8.\n",
      "199. Noble D, Mathur R, Dent T, Meads C, Greenhalgh T. Risk models and scores\n",
      "for type 2 diabetes: systematic review. BMJ. 2011;343:d7163.\n",
      "200. Brown B, Cheraghi-Sohi S, Jaki T, Su T-L, Buchan I, Sperrin M. Understanding\n",
      "clinical prediction models as ‘innovations ’: a mixed methods study in UK\n",
      "family practice. BMC Med Inform Decis Mak. 2016;16:106.\n",
      "201. Craig P, Dieppe P, Macintyre S, Michie S, Nazareth I, Petticrew M.\n",
      "Developing and evaluating complex interventions: the new Medical\n",
      "Research Council guidance. BMJ. 2008;337:a1655.\n",
      "202. Lee TH. Evaluating decision aids. J Gen Intern Med. 1990;5(6):528 –9.\n",
      "203. Kappen TH, Vergouwe Y, van Wolfswinkel L, Kalkman CJ, Moons KG, van Klei\n",
      "WA. Impact of adding therapeutic recommendations to risk assessments\n",
      "from a prediction model for postoperative nausea and vomiting. Br J\n",
      "Anaesth. 2015;114(2):252 –60.\n",
      "204. Michie S, Johnston M. Changing clinical behaviour by making guidelines\n",
      "specific. BMJ. 2004;328(7435):343 –5.Cowley et al. Diagnostic and Prognostic Research            (2019) 3:16 Page 21 of 23\n",
      "\n",
      "Page 22:\n",
      "205. Wallace E, Uijen MJM, Clyne B, Zarabzadeh A, Keogh C, Galvin R, et al.\n",
      "Impact analysis studies of clinical prediction rules relevant to primary care: a\n",
      "systematic review. BMJ Open. 2016;6(3):e009957.\n",
      "206. Sanders SL, Rathbone J, Bell KJL, Glasziou PP, Doust JA. Systematic review of\n",
      "the effects of care provided with and without diagnostic clinical prediction\n",
      "rules. BMC Diagn Progn Res. 2017;1:13.\n",
      "207. Kappen T, Peelen LM. Prediction models: the right tool for the right\n",
      "problem. Curr Opin Anesthesiol. 2016;29(6):717 –26.\n",
      "208. Campbell MK, Elbourne DR, Altman DG. CONSORT statement: extension to\n",
      "cluster randomised trials. BMJ. 2004;328(7441):702 –8.\n",
      "209. Hemming K, Haines TP, Chilton PJ, Girling AJ, Lilford RJ. The stepped\n",
      "wedge cluster randomised trial: rationale, design, analysis, and\n",
      "reporting. BMJ. 2015;350:h391.\n",
      "210. Poldervaart JM, Reitsma JB, Koffijberg H, Backus BE, Six AJ, Doevendans PA,\n",
      "Hoes AW. The impact of the HEART risk score in the early assessment of\n",
      "patients with acute chest pain: design of a stepped wedge, cluster\n",
      "randomised trial. BMC Cardiovasc Disord. 2013;13:77.\n",
      "211. Hayes RJ, Moulton LH. Cluster randomised trials. Boca Raton: CRC Press; 2017.\n",
      "212. Campbell MK, Elbourne DR, Altman DG. CONSORT group. CONSORT\n",
      "statement: extension to cluster randomised trials. BMJ. 2004;328(7441):\n",
      "702 –8.\n",
      "213. Rutterford C, Copas A, Eldridge S. Methods for sample size determination in\n",
      "cluster randomized trials. Int J Epidemiol. 2015;44(3):1051 –67.\n",
      "214. Hemming K, Eldridge S, Forbes G, Weijer C, Taljaard M. How to design\n",
      "efficient cluster randomised trials. BMJ. 2017;358:j3064.\n",
      "215. Schaafsma JD, van der Graaf Y, Rinkel GJ, Buskens E. Decision analysis to\n",
      "complete diagnostic research by closing the gap between test\n",
      "characteristics and cost-effectiveness. J Clin Epidemiol. 2009;62(12):1248 –52.\n",
      "216. Koffijberg H, van Zaane B, Moons KG. From accuracy to patient outcome\n",
      "and cost-effectiveness evaluations of diagnostic tests and biomarkers: an\n",
      "exemplary modelling study. BMC Med Res Methodol. 2013;13:12.\n",
      "217. Siontis KC, Siontis GC, Contopoulos-Ioannidis DG, Ioannidis JP. Reply to\n",
      "letter by Ferrante di Ruffano et al.: patient outcomes in randomized\n",
      "comparisons of diagnostic tests are still the ultimate judge. J Clin Epidemiol.\n",
      "2016;69:267 –8.\n",
      "218. Moher D, Hopewell S, Schulz KF, Montori V, Gøtzsche PC, Devereaux PJ, et\n",
      "al. CONSORT 2010 explanation and elaboration: updated guidelines for\n",
      "reporting parallel group randomised trials. BMJ. 2010;340:c869.\n",
      "219. Reilly BM, Evans AT, Schaider JJ, Das K, Calvin JE, Moran LA, et al.\n",
      "Impact of a clinical decision rule on hospital triage of patients with\n",
      "suspected acute cardiac ischemia in the emergency department. JAMA.\n",
      "2002;288(3):342 –50.\n",
      "220. Cowley LE, Maguire S, Farewell DM, Quinn-Scoggins HD, Flynn MO, Kemp\n",
      "AM. Acceptability of the predicting abusive head trauma (PredAHT) clinical\n",
      "prediction tool: a qualitative study with child protection professionals. Child\n",
      "Abuse Negl. 2018;81:192 –205.\n",
      "221. Ballard DW, Rauchwerger AS, Reed ME, Vinson DR, Mark DG, Offerman SR, et\n",
      "al. Emergency physicians' knowledge and attitudes of clinical decision\n",
      "support in the electronic health record: a survey-based study. Acad Emerg\n",
      "Med. 2013;20(4):352 –60.\n",
      "222. Johnson EL, Hollen LI, Kemp AM, Maguire S. Exploring the acceptability of a\n",
      "clinical decision rule to identify paediatric burns due to child abuse or\n",
      "neglect. Emerg Med J. 2016;33(7):465 –70.\n",
      "223. Mullen S, Quinn-Scoggins HD, Nuttall D, Kemp AM. Qualitative analysis of\n",
      "clinician experience in utilising the BuRN tool (burns risk assessment for\n",
      "neglect or abuse tool) in clinical practice. Burns. 2018;44(7):1759 –66.\n",
      "224. Haskins R, Osmotherly PG, Southgate E, Rivett DA. Physiotherapists'\n",
      "knowledge, attitudes and practices regarding clinical prediction rules for\n",
      "low back pain. Man Ther. 2014;19(2):142 –51.\n",
      "225. Kelly J, Sterling M, Rebbeck T, Bandong AN, Leaver A, Mackey M, Ritchie C.\n",
      "Health practitioners' perceptions of adopting clinical prediction rules in the\n",
      "management of musculoskeletal pain: a qualitative study in Australia. BMJ\n",
      "Open. 2017;7(8):e015916.\n",
      "226. Atabaki SM, Hoyle JDJ, Schunk JE, Monroe DJ, Alpern ER, Quayle KS, et al.\n",
      "Comparison of prediction rules and clinician suspicion for identifying\n",
      "children with clinically important brain injuries after blunt head trauma.\n",
      "Acad Emerg Med. 2016;23(5):566 –75.\n",
      "227. Mahajan P, Kuppermann N, Tunik M, Yen K, Atabaki SM, Lee LK, et al.\n",
      "Comparison of clinician suspicion versus a clinical prediction rule in\n",
      "identifying children at risk for intra-abdominal injuries after blunt torso\n",
      "trauma. Acad Emerg Med. 2015;22(9):1034 –41.228. Reilly BM, Evans AT, Schaider JJ, Wang Y. Triage of patients with chest pain\n",
      "in the emergency department: a comparative study of physicians' decisions.\n",
      "Am J Med. 2002;112(2):95 –103.\n",
      "229. Broekhuizen BD, Sachs A, Janssen K, Geersing GJ, Moons K, Hoes A, Verheij\n",
      "T. Does a decision aid help physicians to detect chronic obstructive\n",
      "pulmonary disease? Br J Gen Pract. 2011;61(591):e674 –e79.\n",
      "230. Schriger DL, Newman DH. Medical decisionmaking: let's not forget the\n",
      "physician. Ann Emerg Med. 2012;59(3):219 –20.\n",
      "231. Finnerty N, Rodriguez R, Carpenter C, Sun B, Theyyunni N, Ohle R, et al.\n",
      "Clinical decision rules for diagnostic imaging in the emergency department:\n",
      "a research agenda. Acad Emerg Med. 2015;22(12):1406 –16.\n",
      "232. Sanders S, Doust J, Glasziou P. A systematic review of studies\n",
      "comparing diagnostic clinical prediction rules with clinical judgment.\n",
      "PLoS One. 2015;10(6):e0128233.\n",
      "233. Cowley LE, Farewell DM, Kemp AM. Potential impact of the validated\n",
      "predicting abusive head trauma (PredAHT) clinical prediction tool: a clinical\n",
      "vignette study. Child Abuse Negl. 2018;86:184 –96.\n",
      "234. Petrou S, Gray A. Economic evaluation using decision analytical modelling:\n",
      "design, conduct, analysis, and reporting. BMJ. 2011;342:d1766.\n",
      "235. Grimshaw J, Shirran L, Thomas R, Mowatt G, Fraser C, Bero L, et al. Changing\n",
      "provider behavior: an overview of systematic reviews of interventions. Med\n",
      "Care. 2001;39(8 Suppl 2):II2 –II45.\n",
      "236. Stiell IG, Bennett C. Implementation of clinical decision rules in the\n",
      "emergency department. Acad Emerg Med. 2007;14(11):955 –9.\n",
      "237. Cameron C, Naylor CD. No impact from active dissemination of the Ottawa\n",
      "ankle rules: further evidence of the need for local implementation of\n",
      "practice guidelines. CMAJ. 1999;160(8):1165 –8.\n",
      "238. Davis DA, Taylor-Vaisey A. Translating guidelines into practice. A\n",
      "systematic review of theoretic concepts, practical experience and\n",
      "research evidence in the adoption of c linical practice guidelines. CMAJ.\n",
      "1997;157(4):408 –16.\n",
      "239. Katz MH. Integrating prediction rules into clinical work flow. JAMA Intern\n",
      "Med 2013;173(17):1591 –91.\n",
      "240. Boutis K, Constantine E, Schuh S, Pecaric M, Stephens D, Narayanan UG.\n",
      "Pediatric emergency physician opinions on ankle radiograph clinical\n",
      "decision rules. Acad Emerg Med. 2010;17(7):709 –17.\n",
      "241. Pluddemann A, Wallace E, Bankhead C, Keogh C, Van der Windt D,\n",
      "Lasserson D, et al. Clinical prediction rules in practice: review of clinical\n",
      "guidelines and survey of GPs. Br J Gen Pract. 2014;64(621):e233 –e42.\n",
      "242. Kappen TH, van Loon K, Kappen MA, van Wolfswinkel L, Vergouwe Y, van\n",
      "Klei WA, et al. Barriers and facilitators perceived by physicians when using\n",
      "prediction models in practice. J Clin Epidemiol. 2016;70:136 –45.\n",
      "243. Keogh C, Fahey T. Clinical prediction rules in primary care: what can be\n",
      "done to maximise their implementation? Clin Evid. 2010. https://core.ac.uk/\n",
      "download/pdf/60774649.pdf . Accessed 12 June 2018.\n",
      "244. Runyon MS, Richman PB, Kline JA. Emergency medicine practitioner\n",
      "knowledge and use of decision rules for the evaluation of patients with\n",
      "suspected pulmonary embolism: variations by practice setting and training\n",
      "level. Acad Emerg Med. 2007;14(1):53 –7.\n",
      "245. Pearson SD, Goldman L, Garcia TB, Cook EF, Lee TH. Physician response to a\n",
      "prediction rule for the triage of emergency department patients with chest\n",
      "pain. J Gen Intern Med. 1994;9(5):241 –7.\n",
      "246. Brehaut JC, Stiell IG, Visentin L, Graham ID. Clinical decision rules \"in the real\n",
      "world\": how a widely disseminated rule is used in everyday practice. Acad\n",
      "Emerg Med. 2005;12(10):948 –56.\n",
      "247. Brehaut JC, Stiell IG, Graham ID. Will a new clinical decision rule be widely\n",
      "used? The case of the Canadian C-spine rule. Acad Emerg Med. 2006;13(4):\n",
      "413 –20.\n",
      "248. Graham ID, Stiell IG, Laupacis A, O'Connor AM, Wells GA. Emergency\n",
      "physicians' attitudes toward and use of clinical decision rules for\n",
      "radiography. Acad Emerg Med. 1998;5(2):134 –40.\n",
      "249. Eichler K, Zoller M, Tschudi P, Steurer J. Barriers to apply cardiovascular\n",
      "prediction rules in primary care: a postal survey. BMC Fam Pract. 2007;8:1.\n",
      "250. Beutel BG, Trehan SK, Shalvoy RM, Mello MJ. The Ottawa knee rule:\n",
      "examining use in an academic emergency department. West J Emerg Med.\n",
      "2012;13(4):366 –72.\n",
      "251. Sheehan B, Nigrovic LE, Dayan PS, Kuppermann N, Ballard DW,\n",
      "Alessandrini E, et al. Informing the design of clinical decision support\n",
      "services for evaluation of children with minor blunt head trauma in the\n",
      "emergency department: a sociotechnical analysis. J Biomed Inform.\n",
      "2013;46(5):905 –13.Cowley et al. Diagnostic and Prognostic Research            (2019) 3:16 Page 22 of 23\n",
      "\n",
      "Page 23:\n",
      "252. van der Steen JT, Albers G, Licht-Strunk E, Muller MT, Ribbe MW. A validated\n",
      "risk score to estimate mortality risk in patients with dementia and\n",
      "pneumonia: barriers to clinical impact. Int Psychogeriatr. 2011;23(1):31 –43.\n",
      "253. Sanders S. Clinical prediction rules for assisting diagnosis (doctoral thesis).\n",
      "Australia: Faculty of Heath Sciences & Medicine, Bond University; 2015.\n",
      "254. Cabana MD, Rand CS, Powe NR, Wu AW, Wilson MH, Abboud PA, Rubin HR.\n",
      "Why don't physicians follow clinical practice guidelines? A framework for\n",
      "improvement. JAMA. 1999;282(15):1458 –65.Cowley et al. Diagnostic and Prognostic Research            (2019) 3:16 Page 23 of 23\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing extract (PdfReader)\n",
    "src_dir = \"D:\\SingHealth\\Week 4\"\n",
    "extractor_type = \"PdfReader\"\n",
    "pdf_path = \"41512_2019_Article_60.pdf\"\n",
    "\n",
    "# Create an instance of the PDFExtractor class\n",
    "extractor = PDFExtractor(src_dir)\n",
    "\n",
    "# Test the extract method\n",
    "result = extractor.extract(extractor_type, pdf_path)\n",
    "\n",
    "# Print or inspect the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the temporary directory '.\\tmpyezx2vqx':\n",
      "File: 41512_2019_Article_60.json\n",
      "File: ast_sci_data_tables_sample.json\n",
      "File: Binuya et al. - 2022 - Methodological guidance for the evaluation and upd.pdf _ HSRC_Interns _ Zotero.json\n",
      "File: Cowley et al. - 2019 - Methodological standards for the development and e.pdf _ HSRC_Interns _ Zotero.json\n",
      "File: Hierarchical control of multi-agent reinforcement learning team i.json\n"
     ]
    }
   ],
   "source": [
    "# Testing mass_extract\n",
    "pdf_extractor = PDFExtractor(src_dir='D:\\SingHealth\\Week 4')\n",
    "\n",
    "# Call the mass_extract method to extract text from PDFs and get the temporary directory path\n",
    "temp_dir_path = pdf_extractor.mass_extract(extractor='pdfplumber', include_meta=False)\n",
    "\n",
    "# Check if the temporary directory exists and list its contents\n",
    "if os.path.exists(temp_dir_path):\n",
    "    print(f\"Contents of the temporary directory '{temp_dir_path}':\")\n",
    "    for item in os.listdir(temp_dir_path):\n",
    "        item_path = os.path.join(temp_dir_path, item)\n",
    "        if os.path.isfile(item_path):\n",
    "            print(f\"File: {item}\")\n",
    "        elif os.path.isdir(item_path):\n",
    "            print(f\"Directory: {item}\")\n",
    "else:\n",
    "    print(\"Temporary directory does not exist or has been cleaned up.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
