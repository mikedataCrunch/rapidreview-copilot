{
    "extracted_text": [
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Diagnostic and\nhttps://doi.org/10.1186/s41512-019-0060-y\nPrognostic Research\nREVIEW Open Access\nMethodological standards for the\ndevelopment and evaluation of clinical\nprediction rules: a review of the literature\nLaura E. Cowley* , Daniel M. Farewell, Sabine Maguire and Alison M. Kemp\nAbstract\nClinicalpredictionrules(CPRs)thatpredicttheabsoluteriskofaclinicalconditionorfutureoutcomeforindividualpatients\nare abundant in the medical literature; however, systematic reviews have demonstrated shortcomings in the\nmethodologicalqualityandreportingofpredictionstudies.TomaximisethepotentialandclinicalusefulnessofCPRs,they\nmust be rigorously developed and validated, and their impact on clinical practice and patient outcomes must be\nevaluated. This review aims to present a comprehensive overview of the stages involved in the development, validation\nand evaluation of CPRs, and to describe in detail the methodological standards required at each stage, illustrated with\nexampleswhereappropriate.Importantfeaturesofthestudydesign,statisticalanalysis,modellingstrategy,datacollection,\nperformanceassessment,CPRpresentationandreportingarediscussed,inadditiontoother,oftenoverlookedaspectssuch\nas the acceptability, cost-effectiveness and longer-term implementation of CPRs, and their comparison with clinical\njudgement. Although the development and evaluation of a robust, clinically useful CPR is anything but straightforward,\nadherencetotheplethoraofmethodologicalstandards,recommendationsandframeworksateachstagewillassistinthe\ndevelopment of a rigorous CPR that has the potential to contribute usefully to clinical practice and decision-making and\nhaveapositiveimpactonpatientcare.\nKeywords:Clinicalpredictionrule,Predictionmodel,Riskmodel,Modeldevelopment,Modelvalidation,Impactstudies,\nModelreporting,Implementation,Diagnosis,Prognosis,Studydesign\nBackground whilstothersaimto\u2018ruleout\u2019aconditionbyidentifyingpa-\nThe aim of a clinical prediction rule (CPR) is to estimate tientswhoareveryunlikelytohaveacondition,thusredu-\nthe probability of a clinical condition or a future outcome cing unnecessary testing without compromising patient\nbyconsideringasmallnumberofhighlyvalidindicators[1, care [2, 4]. CPRs that aim to predict the probability of a\n2]. CPRs include three or more predictors, from patients\u2019 condition being present are termed diagnostic or screening\nclinical findings, history or investigation results [3]. Their rules; those that aim to predict the probability of a future\npurpose is to assist clinicians in making decisions under outcomearetermedprognosticrules;andthosethataimto\nconditionsofuncertaintyandenhancediagnostic,prognos- predicttheprobabilitythataspecifictreatmentorinterven-\ntic or therapeutic accuracy and decision-making, with the tionwillbeeffectivearetermedprescriptiverules[2].\nultimate aim of improving the quality of patient care [1, 2, To maximise the predictive accuracy and clinical util-\n4]. The predicted probabilities from a CPR allow clinicians ity of CPRs, it is vital that they are rigorously developed,\ntostratifypatientsintoriskgroupsandhelpthemtodecide validated and evaluated. However, numerous systematic\nwhether further assessment or treatment is necessary [5]. reviews have demonstrated shortcomings in the meth-\nSome CPRs can help to \u2018rule in\u2019a condition by identifying odological quality and reporting of prediction studies,\npatients who are very likely to have a condition and who which restricts the CPR\u2019s usefulness in practice [6\u201315].\nthus require additional diagnostic testing or treatment, Methodological standards for the development of CPRs\nwere originally outlined by Wasson and colleagues [16].\n*Correspondence:CowleyLE@cardiff.ac.uk With the increase in popularity of CPRs inspired by the\nDivisionofPopulationMedicine,SchoolofMedicine,NeuaddMeirionnydd, evidence-based medicine movement, these standards\nHeathPark,CardiffUniversity,WalesCF144YS,UK\n\u00a9TheAuthor(s).2019OpenAccessThisarticleisdistributedunderthetermsoftheCreativeCommonsAttribution4.0\nInternationalLicense(http://creativecommons.org/licenses/by/4.0/),whichpermitsunrestricteduse,distribution,and\nreproductioninanymedium,providedyougiveappropriatecredittotheoriginalauthor(s)andthesource,providealinkto\ntheCreativeCommonslicense,andindicateifchangesweremade.TheCreativeCommonsPublicDomainDedicationwaiver\n(http://creativecommons.org/publicdomain/zero/1.0/)appliestothedatamadeavailableinthisarticle,unlessotherwisestated.",
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page2of23\nhave since been modified and updated by a number of Stages in the development of clinical prediction\nauthors over the years [3, 4, 17\u201319]. Experts have pro- rules\nvided thorough and accessible overviews of the princi- It is widely acknowledged in the literature that there are\nples and methods involved in conducting diagnostic and three main stages in the development of CPRs (Fig. 1);\nprognostic research [20\u201332] and devised frameworks to derivation;externalvalidation;andimpactanalysistode-\nenhance the conduct and interpretation of prediction termine their impact on patient care [4, 20, 22\u201325, 32,\nstudies [33\u201335]. They have also provided guidance and 33]. Stiell and Wells [17] identified a further three im-\nrecommendations for researchers to consider when de- portant stages, namely identifying the need for a CPR,\nveloping and evaluating CPRs, without aiming to dictate determining the cost-effectiveness of a CPR and\nhow analyses should be conducted. These recognise that long-term dissemination and implementation of a CPR.\nthere is no clear consensus on many aspects of model Therefore all six stages are summarised in Table 1 and\ndevelopment, that the field is continually evolving and discussedindetail below.\nthat methodological standards will therefore require up- Detailedmethodologicalandpracticalrecommendations\ndating accordingly [36]. Guidelines for the reporting of pertaining to the three main stages of development have\nclinical prediction research have also been developed, been published, as each requires a different methodo-\nnamely the Transparent Reporting of a multivariable logicalapproach[3,4,16\u201336].Thesethreestagesalsocor-\nprediction model for Individual Prognosis or Diagnosis respond to increasing hierarchies of evidence, as outlined\n(TRIPOD) guidelines[36]. in Table 2 [4, 32, 33]. A CPR that has been derived, but\nThis review aims to outline the stages and methodo- notexternallyvalidated,correspondstothelowestlevelof\nlogical standards involved in the development and evalu- evidenceandisnotrecommendedforuseinclinicalprac-\nationofCPRs,illustratedwithexampleswhereappropriate. tice, except arguably in rare instances when a CPR is de-\nveloped for use in only one setting. It has been suggested\nTerminologyusedinthisreview thata CPR thathasbeensuccessfullyexternally validated\nIn the literature, the term \u2018clinical prediction rule\u2019 is used in a setting, or population, similar to the one from which\ninterchangeably with the terms clinical prediction tool itwasderived(\u2018narrow\u2019validation),canbeusedcautiously\n[37], clinical decision rule [17], clinical decision tool [38], insimilarfuturepatients[32].Similarly,itisproposedthat\nclinical prediction algorithm [39], prognostic score [40], a CPR should be consistently successfully externally vali-\nprognostic model [21], risk prediction model [23], risk dated in multiple settings or populations (\u2018broad\u2019 valid-\nmodel [30], risk score [41], scoring tool [42], scoring sys- ation),beforeclinicianscanuseitspredictionsconfidently\ntem [43] or risk index [44]. Reilly and Evans [32] distin- in future patients [32]. Finally, it is recommended that an\nguish between assistive prediction rules that simply impact analysis is conducted and that the CPR demon-\nprovide clinicians with diagnostic or prognostic predicted stratesimprovementstopatientcare,beforeitcanbeused\nprobabilities without recommending a specific clinical as a decision rule for the management and treatment of\ncourseofaction,anddirectivedecisionrulesthatexplicitly patients [32]. Ideally, the impact of a CPR should also be\nsuggest additional diagnostic tests or treatment in line tested in multiple settings. Impact analysis studies corres-\nwith the obtained score. Decision rules intend to directly pondtothehighestlevelofevidence[32].\ninfluenceclinicianbehaviour,whilepredictionrulesintend\nto help clinicians predict risk without providing recom- Stage1:identifyingtheneedforaclinicalpredictionrule\nmendations, with the assumption that accurate predic- Before developing a CPR, researchers need to ensure\ntions will lead to better decisions [32]. Some researchers that there is a clinical need for the rule. CPRs are most\nalso distinguish between prediction models that provide valuable when decision-making is challenging, when\npredicted probabilities along the continuum between cer- there is evidence that clinicians are failing to accurately\ntified impossibility (Pi=0) and absolute certainty (Pi=1) diagnose a condition, and when there are serious conse-\n[45], and prediction rules that classify patients into risk quences associated with an incorrect diagnosis [2, 4].\ngroups, by applying a clinically relevant cut-off that bal- CPRs are also valuable when there is a need to simplify\nancesthelikelihoodof benefitwiththelikelihoodofharm or speed up the diagnostic or triage process, for example\n[19, 46]. Such cut-offs are known as \u2018decision thresholds\u2019; inpatientspresentingtotheemergency departmentwith\na threshold mustbe appliedifa prediction model aimsto chest pain and suspected acute cardiac ischaemia [49].\ninfluence decision-making [19]. In this review, the term CPRs are most likely to be adopted into clinical practice,\n\u2018clinical prediction rule\u2019 is used to refer to diagnostic, and to demonstrate improvements in patient care and\nprognosticorprescriptiverules/modelsderivedfrommul- reductions in health care costs, when they improve the\ntivariablestatisticalanalyses, whichpredicttheprobability overall efficiency of clinical practice [17]. For example,\nof a condition or outcome, with or without the use of a ankle injuries are frequently seen in the emergency de-\nclinicalcut-offorrecommendationforfurtheraction. partment. Prior to the implementation of the Ottawa",
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page3of23\nValidation\nEvidence of reproducible\naccuracy\nNarrow Validation Impact Analysis\nDerivation\nApplication of rule in a similar Evidence that rule\nIdentification of clinical setting and population as changes physician\nfactors with in the derivation stage behaviour and improves\npredictive power patient outcomes and/or\nBroad Validation\nreduces costs\nApplication of rule in multiple\nclinical settings with varying\nprevalence and outcomes of\ndisease\nFig.1Thethreemainstagesinthedevelopmentandevaluationofclinicalpredictionrules.AdaptedfromMcGinn,2016[47]\nAnkleRule,clinicians ordered ahighproportion of radio- protocol and registering the study prior to the derivation\ngraphs that were negative for fracture, when the majority ofanewCPR,intheinterestsoftransparency[67,68].\nof them believed that a fracture was highly unlikely [50].\nTherulewasfound tolead toareductioninbothradiog- Studydesignforthederivationofaclinicalpredictionrule\nraphy [51] and health care costs [52], and in one survey The first stage in the development of a CPR is the deriv-\n70% of Canadian and UK emergency department clini- ation of the rule. This involves an examination of the\nciansreportedfrequentuseoftherule[53]. ability of multiple potential variables from the clinical\nBefore developing a CPR, researchers should consider findings, history or investigation results to predict the\nwhether a new CPR is needed, as many are developed for target outcome of interest. Predicted probabilities are\nthe same target population or to predict the same out- derived from the statistical analysis of patients with\ncome [8, 10, 11, 54\u201357]. The characteristics, performance known outcomes, and the outcome of interest serves as\nandlevelofevidenceofexistingCPRsshouldbesystemat- the reference standard by which the performance of the\nically reviewed using validated search filters for locating CPRisassessed.TheperformanceofaCPRisdependent\npredictionstudies,andtheCriticalAppraisalandDataEx- upon the quality of the underlying data, and the dataset\ntraction for Systematic Reviews of prediction modelling used to derive the CPR should be representative of the\nstudies (CHARMS) checklist [58, 59]. The recently pub- target populationitisintended for[17,30,69,70].\nlished Prediction model Risk Of Bias ASsessment Tool Theoptimalstudydesignforthederivationofadiagnos-\n(PROBAST)canbeusedtoassesstheriskof biasandap- ticCPRisacross-sectionalcohortstudy,whileforprognos-\nplicability of CPRs [60]. Researchers can also assess the ticCPRs,thepreferreddesignisalongitudinalcohortstudy\nperformanceofexistingCPRs ontheirowncollecteddata [30]. In general, case-control studies are inappropriate, as\n[61].ExistingCPRswithpotentialshouldbeupdated,vali- they do not allow for the estimation of absolute outcome\ndatedortestedinanimpactstudybeforeanewCPRisde- risk [21, 23, 71]; however, nested case-control or\nveloped [54, 62, 63]. If a new CPR is derived, researchers case-cohortstudiescanbeused[71,72].Prospectivecohort\nshould clearly justify why it is required, with reference to studiesarepreferredtoretrospectivecohort studies,toop-\nexisting CPRs, to avoid research waste and duplication of timise measurement and documentation of predictive and\nefforts [64]. Qualitative research with clinicians can be outcomevariables[21,23].ForprescriptiveCPRs,studyde-\nusefulindeterminingwhetheraproposedCPRisclinically signsthatincludeacontrolgroup,suchasrandomisedcon-\nrelevant,andtoassessthe credibilityoftheproposedpre- trolled trials (RCTs), are essential to ensure that treatment\ndictorvariables[65,66]. effect modifiers and non-specific prognostic predictors are\ndistinguishablefromoneanother[73,74].Thestudydesign\nStage2:derivationofaclinicalpredictionruleaccording shouldbeadequatelydetailedandincludethestudysetting,\ntomethodologicalstandards inclusion and exclusion criteria and patient demographics\nOnce a need for a new CPR is established, and a re- and characteristics [17].To enhance generalisability,multi-\nsearcherhasanappropriate clinical question,a CPRmust centrestudiesarerecommended[30].\nbe derived according to strict methodological standards\n[23].Therearevariouselementstoconsider,pertainingto Statisticalanalysis\nthe study design, statistical techniques employed and the Commonly used statistical methods for the derivation of\nassessment, presentation and reporting of the CPR. Re- CPRs include multivariable regression techniques, and\nsearchers should consider writing and publishing a study recursive partitioning techniques, such as classification",
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page4of23\nTable1Stagesinthedevelopmentandevaluationofclinical Table1Stagesinthedevelopmentandevaluationofclinical\npredictionrules predictionrules(Continued)\nStageofdevelopment Methodologicalstandards Stageofdevelopment Methodologicalstandards\nStage1.Identifyingtheneedfora (cid:129)Considerconductingqualitativeresearch (cid:129)Considerdecisioncurveanalysisto\nCPR withclinicianstodetermineclinical estimatetheclinicalutilityoftheCPR\nrelevanceandcredibilityofCPR\nPresentationofaCPR\n(cid:129)Conductasystematicreviewofthe\n(cid:129)Reporttheregressioncoefficientsofthe\nliteraturetoidentifyandevaluateexisting\nfinalmodel,includingtheinterceptor\nCPRsdevelopedforthesamepurpose\nbaselinehazard\n(cid:129)Considerupdating,validatingortesting\n(cid:129)ConsideraclinicalcalculatoriftheCPRis\ntheimpactofexistingCPRs\ncomplex\nStage2.DerivationofaCPR StudydesignforthederivationofaCPR\nReportingthederivationofaCPR\naccordingtomethodological\n(cid:129)Considerregisteringthestudyand\nstandards (cid:129)AdheretotheTRIPODguidelines[36]\npublishingaprotocol\n(cid:129)Ensurethedatasetisrepresentativeofthe Stage3.Externalvalidationand Studydesignfortheexternalvalidationofa\nrefinementofaCPR CPR\npopulationforwhomtheCPRisintended\n(cid:129)Conductaprospectivemulticentrecohort\n(cid:129)Conductaprospectivemulticentrecohort\nstudy\nstudy\n(cid:129)Aimforasamplesizewithaminimumof\nStatisticalanalysis\n100outcomeevents,preferably200\n(cid:129)Conductmultivariableregressionanalysis\n(cid:129)Considerusingaframeworkof\n(logisticforbinaryoutcomes,Coxfor\ngeneralisabilitytoenhancethe\nlong-termprognosticoutcomes)\n(cid:129)Identifythemodeltobeused,plus interpretationofthefindings[34]\nrationaleifothermethodsused Typesofexternalvalidation\nMissingdata (cid:129)Conducttemporal,geographicaland\n(cid:129)Usemultipleimputation domainvalidationstudiestoensure\nmaximumgeneralisability\nSelectionofcandidatepredictorsfor\n(cid:129)Ifmultiplevalidationshavebeen\ninclusioninamultivariablemodel\nperformed,conductameta-analysisto\n(cid:129)Onlyincluderelevantpredictorsbasedon summarisetheoverallperformanceofthe\nevidenceintheliterature/clinical CPR,usingapublishedframework[35]\nexperience\nRefinementofaCPR:modelupdatingor\n(cid:129)Aimforasamplesizewithaminimumof adjustment\nteneventsperpredictor,preferablymore\n(cid:129)Considerupdating,adjustingor\n(cid:129)Avoidselectionbasedonunivariable recalibratingtheCPRifpoorperformance\nsignificancetesting isfoundinanexternalvalidationstudy\n(cid:129)Avoidcategorisingcontinuouspredictors (cid:129)Considerfurtherexternalvalidationof\nupdatedCPRs\nSelectionofpredictorsduringmultivariable\nmodelling ComparingtheperformanceofCPRs\n(cid:129)Backwardeliminationofpredictorsis (cid:129)ComparetheCPRwithotherexistingCPRs\npreferred forthesamecondition\n(cid:129)Avoiddata-drivenselectionandincorpor- (cid:129)Ensurethestatisticalproceduresusedfor\natesubject-matterknowledgeintothese- comparisonareappropriate;considera\nlectionprocess decision-analyticapproach\nDefinitionandassessmentofpredictorand ReportingtheexternalvalidationofaCPR\noutcomevariables\n(cid:129)AdheretotheTRIPODguidelines[36]\n(cid:129)Definepredictorandoutcomevariables\nclearly Stage4.ImpactofaCPRonclinical Studydesignforanimpactanalysis\npractice\n(cid:129)ConsiderwhethertheCPRisreadyfor\n(cid:129)Considerinter-raterreliabilityofpredictor\nimplementation\nmeasurementandpotentialmeasurement\nerror (cid:129)Conductaclusterrandomisedtrialwith\ncentresasclusters,orabefore\u2013afterstudy\n(cid:129)Aimforblindassessmentofpredictorand\noutcomevariables (cid:129)Performappropriatesamplesize\ncalculations\nInternalvalidation\n(cid:129)Considerdecision-analyticmodellingasan\n(cid:129)Usecross-validationorbootstrappingand\nintermediatesteppriortoaformalimpact\nadjustforoptimism\nstudy\n(cid:129)Ensuretorepeateachstepofmodel\nMeasuresofimpactofaCPR\ndevelopmentifusingbootstrapping\n(cid:129)ReportthesafetyandefficacyoftheCPR\nCPRperformancemeasures\n(cid:129)ReporttheimpactoftheCPRonclinician\n(cid:129)Assessandreportbothcalibrationand\nbehaviourifassessed\ndiscrimination",
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page5of23\nTable1Stagesinthedevelopmentandevaluationofclinical enabling improved assessment of the association of the\npredictionrules(Continued) predictorswiththetargetoutcome[76].\nStageofdevelopment Methodologicalstandards In the case of multivariable regression, logistic regres-\nAcceptabilityofaCPR sion models are required to predict binary events such as\n(cid:129)EvaluatetheacceptabilityoftheCPRusing the presence or absence of a condition, while Cox regres-\nthevalidatedOADRI[48],orusing sionmodelsaresuitablefortime-to-eventoutcomes.Such\nqualitativeorvignettemethods\nmodels estimate regression coefficients (e.g. log odds or\nComparisonofaCPRwithunstructured\nclinicaljudgement hazard ratios) of each predictor. Regression coefficients\n(cid:129)Comparethesensitivityandspecificityof are mutually adjusted for the other predictors, and thus\ntheCPRwithcliniciansownpredictions/ represent the contribution of each predictor to the prob-\ndecisions\nabilityoftheoutcome[23].Theprobabilityofanoutcome\nThefourphasesofimpactanalysisforCPRs\ncanbecomputedforapatientbycombiningtheobserved\n(cid:129)Followtheframeworkfortheimpact\nvalues of the predictors and their corresponding regres-\nanalysisofCPRs[33]\nsion coefficients with the model intercept, or estimated\n(cid:129)Ensureextensivepreparatoryand\nfeasibilityworkisconductedpriortoa baselinehazard [23].For logisticmodels, the modelinter-\nformalimpactstudy cept and the weighted values applicable to each patient\nReportingtheimpactanalysisofaCPR aresummed[16].Specificvaluesareassignedtoeachpre-\n(cid:129)Therearecurrentlynopublishedreporting dictor, which are multiplied by the corresponding coeffi-\nguidelinesforimpactstudiesofCPRs;this\ncients.Inthe caseofa model withonly binary categorical\nisanareaforfutureresearch\npredictors, the predictors are multiplied by 0 or 1, de-\nStage5.Cost-effectiveness (cid:129)Conductaformaleconomicevaluation,\nwithsensitivityanalysestoexaminethe pending on whether they are absent (0) or present (1), as\nuncertaintyofthemodelprojections perthemodelinTable3[77].Exponentiatingthefinalrisk\nStage6.Long-termimplementation (cid:129)Deviseandevaluatetargeted score gives the odds, and the probability (absolute risk) is\nanddissemination implementationstrategiestoensure\nmaximumuptake calculatedbyuse ofthe inverselogistic link function[78].\nIn this way, the probability of an outcome can be esti-\nBarriersandfacilitatorstotheuseofCPRs\nmated from any combination of the predictor values [36].\n(cid:129)AssessbarrierstotheuseoftheCPRand\ndevisestrategiestoovercomethese Theestimatedprobabilityforanindividualwithoutanyof\nCPRclinicalpredictionrule,TRIPODTransparentReportingofamultivariable the predictors depends only on the intercept [23]. In this\npredictionmodelforIndividualPrognosisorDiagnosis,OADRIOttawa case, the value for each of the predictors will be 0; when\nAcceptabilityofDecisionRulesInstrument\neach of these is multiplied by its relevant coefficient the\nand regression tree analysis [75]. Methods based on uni- valueof0isretained[78].ForCoxregressionmodels,the\nvariable analysis, where individual risk factors are simply baselinehazardisestimatedseparately[26,29].\ntotalled and assigned arbitrary weightings, should be Recursive partitioning involves repeatedly splitting\navoided, as they are much less accurate than methods patients into subpopulations including only individ-\nbased on multivariable analysis [76]. This is because the uals with a specific outcome [79], and was the\nfinal model may include predictors that are potentially method used to derive the Ottawa Ankle Rule [80].\nrelated to each other and not independently associated CPRs can also be derived using discriminant function\nwith the outcome ofinterest [76]. Multivariablemethods analysis [3], and machine learning algorithms based\novercome the limitations of univariable analysis by onartificialneuralnetworks[1].Artificialintelligenceand\nTable2Hierarchiesofevidenceinthedevelopmentandevaluationofclinicalpredictionrules\nLevelofevidence Definitionsandstandardsofevaluation Implicationsforclinicians\nLevel1:DerivationofCPR Identificationofpredictorsusingmultivariablemodel;blinded Needsvalidationandfurtherevaluationbeforeit\nassessmentofoutcomes. isusedclinicallyinactualpatientcare.\nLevel2:Narrowvalidationof ValidationofCPRwhentestedprospectivelyinonesetting; Needsvalidationinvariedsettings;mayuseCPR\nCPR blindedassessmentofoutcomes. cautiouslyinpatientssimilartoderivationsample.\nLevel3:Broadvalidationof ValidationofCPRinvariedsettingswithwidespectrumof Needsimpactanalysis;mayuseCPRpredictions\nCPR patientsandclinicians. withconfidenceintheiraccuracy.\nLevel4:Narrowimpactanalysis ProspectivedemonstrationinonesettingthatuseofCPR Mayusecautiouslytoinformdecisionsinsettings\nofCPRusedfordecision- improvesclinicians\u2019decisions(qualityorcost-effectivenessofpa- similartothatstudied.\nmaking tientcare).\nLevel5:Broadimpactanalysis ProspectivedemonstrationinvariedsettingsthatuseofCPR Mayuseinvariedsettingswithconfidencethat\nofCPRusedfordecision- improvesclinicians\u2019decisionsforwidespectrumofpatients. itsusewillbenefitpatientcarequalityor\nmaking effectiveness.\nAdaptedfromReillyandEvans2016[32].CPRclinicalpredictionrule",
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page6of23\nTable3Clinicalpredictionruleforpostoperativenauseaand thesecondstage,standardstatisticaltechniquesareusedto\nvomiting(PONV)[77] fitthemodelsthatareofinterestinthesubstantiveanalysis\nRiskofPONV=1/(1+exp.\u2212[2.28+1.27\u00d7femalesex+0.65\u00d7historyof to each of the imputed datasets. Estimated associations in\nPONVormotionsickness+0.72\u00d7non-smoking+0.78\u00d7postoperative each of the imputed datasets will be different, due to the\nopioiduse])\nvariability introduced in stage one. In the third and final\nstage,themultipleresultsareaveragedtogether,andstand-\nmachine learning approaches are becoming increasingly ard errors are calculated using Rubin\u2019s combination rules\nmorecommon[81,82]. [91], which account for both within-and between-imput-\nation variability and the number of imputed datasets, and\nMissingdata therefore the uncertainty of the imputed values. Multiple\nInclinical research, investigatorsalmost alwaysencounter imputation typically assumes that data are MAR [93]. Im-\nmissingobservationsinvolvingpredictororoutcome vari- portantly,theMARassumptionisjustthat;anassumption,\nables, even in carefully designed studies and in spite of rather than a property of the data [85]. The MCAR as-\ntheir best efforts to maximise data quality [83]. There are sumptioncanbetested,butitisnotpossibletodifferentiate\nthreetypesofmissingdatamechanisms:(1)missingcom- betweenMARandMNARfromtheobserveddata[26,85].\npletelyatrandom(MCAR),(2)missingatrandom(MAR) MostmissingdataareexpectedtobeatleastpartlyMNAR\nand (3) missing not at random (MNAR) [84]. When data [85, 94, 95]. Sensitivity analyses can help to determine the\nareMCAR,thismeansthattherearenosystematicdiffer- effect of different assumptions about the missing data\nences between the missing and observed values; for ex- mechanism; work in this area is ongoing [96\u2013100]. Other\nample, laboratory tests may be missing because of a statistically principled approaches to dealing with missing\ndropped test tube or broken equipment. When data are datahavebeendeveloped,basedonrandomeffectsmodels\nMAR, this means that the probability of a missing value [101, 102], Bayesian methods or maximum likelihood esti-\ndepends on the observed values of other variables (but mation [103] or, where data are longitudinal, joint models\nnot the unobserved values); for example, missing blood [104, 105]. Guidelines for reporting on the treatment of\npressuremeasurementsmaybelowerthanobservedmea- missingdatainclinicalandepidemiologicalresearchstudies\nsurements because younger people may be more likely to have been suggested by Sterne and colleagues [85]. Guid-\nhavemissing measurements; inthis case, data can besaid ance also exists for handling missing data when deriving\nto be MAR given age [85]. When data are MNAR, this and validating CPRs [83, 106, 107]. It has been demon-\nmeans that the probability of a missing value depends on strated that the outcome should be used for imputation of\nthe unobserved values or other unobserved predictors, missing predictor values [87]. It is also becoming increas-\nconditionalontheobserveddata;forexample,peoplewith ingly apparent that a real-time strategy to impute missing\nhighblood pressuremaybemorelikelytomissadoctor\u2019s valuesisdesirablewhenapplyingaCPRinclinicalpractice\nappointment due to headaches [85]. Missing values are [108\u2013110].Thisisbecauseoneormorepredictor variables\nrarelyMCAR,thatis,their\u2018missingness\u2019isusuallydirectly may be unobserved for a particular patient, and thus the\nor indirectly related to other subject or disease character- CPRs risk prediction cannot be estimated at the time of\nistics, including the outcome [23, 25]. Missing data is fre- decision-making [108]. Real-time multiple imputation is\nquentlyaddressedwithcase-wisedeletion,whichexcludes not typically straightforward, as it requires access to the\nall participantswithmissing valuesfrom theanalysis[85]. derivationdatasetvia,forexample,awebsite[108,110].Of\nHowever,whendataareplausiblyMAR,thisreducessam- note, although multiple imputation is a widely advocated\nple size and statistical power and biases the results [85], approachforhandlingmissingdatainCPRstudies,arecent\nleadingtoinaccurateestimatesofpredictor-outcomerela- study showed that implementing simpler imputation\ntionships and the predictive performance of the model, methods resulted in similar predictive utility of a CPR to\nsince the participants with complete data are not a ran- predict undiagnosed diabetes, when compared to multiple\ndomsubsampleoftheoriginalsample[84,86,87]. imputation[111].\nMultiple imputation is a popular approach to the prob-\nlem of missing data[83, 85, 86, 88\u201391], asit quantifies the Selectionofcandidatepredictorsforinclusionina\nuncertainty in the imputed values, by generating multiple multivariablemodel\ndifferentplausibleimputeddatasets,andpoolingtheresults Candidate predictors are variables that are preselected\nobtained from each of them [85, 91]. Multiple imputation for consideration in a multivariable model, and differ\ninvolvesthreestages[85,89,91\u201393].First,asthenamesug- from those that are subsequently selected for inclusion\ngests, multiple imputed datasets are created, based on the in the final model [23]. Candidate predictors should be\ndistribution of the observed data. This first stage accounts selected without studying the predictor-outcome rela-\nfor uncertainty in estimating the missing values by adding tionship in the data; in other words, predictors should\nvariability into the values across the imputed datasets. In not be excluded as candidates solely because they are",
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page7of23\nnot statistically significant in univariable analysis [25, 26, measure in the target setting, and selecting predictors\n29,112\u2013114].Predictor variablesdonothavetobecaus- that are relatively easy to measure and demonstrate high\nally related to the outcome of interest [21, 115]. Effects inter-raterreliabilitybetweenclinicians[17,21].Interms\nmodelled in studies examining causality are expressed of handling continuous predictors, researchers strongly\nwith relative risk estimates such as odds ratios, while advise against converting continuous variables into cat-\nrisk predictions are presented as probabilities on an ab- egorical variables, due to information loss and reduced\nsolute scale between 0 and 1. Relative risk estimates are predictive accuracy [125\u2013128]. Similarly, it should not\nused in prediction research to calculate an absolute be assumed that continuous variables have a linear rela-\nprobability of an outcome for a patient, as described tionship [127]. Instead, methods that permit more flexi-\nabove, and can also be reported alongside risk predic- bility in the functional form of the association between\ntions. All variables thought to be related to the target the predictors and outcome should be considered [127,\noutcome can be selected as candidate predictors for in- 129]; two common approaches are fractional polyno-\nclusion in a multivariable model; however, when the mials and restricted cubic splines [130, 131]. However, if\nnumber of outcome events in the dataset is small, there sample size is limited, assuming a linear relationship be-\nis a risk of overfitting the data when a large number of tween continuous variables may make a model less sen-\npredictor variables are included. Thus the CPR will per- sitive toextreme observations.\nform well onthe derivation data,butpoorlyonnewdata Penalised regression can be used to alleviate the prob-\n[29, 69, 113, 116]. CPRs with a smaller number of pre- lem of overfitting [116]. This approach involves placing a\ndictors are also easier to use in practice. To overcome constraintonthevaluesoftheestimatedregressioncoeffi-\nthis problem, only the most clinically relevant candidate cients in order to shrink them towards zero [116]. This\npredictors should be chosen from the larger pool of po- hastheeffectofyieldinglessextremeriskpredictions,and\ntential predictor variables, without looking into the data thus may improve the accuracy of predictions when the\n[5, 117]. In addition, sample size recommendations for CPR is applied in new patients [113, 132]. The two most\nstudies deriving CPRs are often based on the concept of popular penalised methods are ridge regression [133] and\nevents-per-variable (EVP), whereby the researcher con- lasso regression [134]. Unlike ridge regression, lasso re-\ntrols the ratio of the number of outcome events to the gression also selects predictors as a consequence of its\nnumber of coefficients estimated prior to any data- penalisation [116]. Ridge regression is usually preferred\ndriven variable selection [31]. A rule-of-thumb of ten when a set of pre-specified predictors is available, while\nEPV has been suggested [29, 31, 114, 118]. Simulation lasso regression may be preferred if a simpler model with\nstudies examining the effect of this rule-of-thumb have fewerpredictorsisrequired[116,132].\nyielded conflicting results [119\u2013123]. One study found\nthat when the EPV was less than ten, there were a range Selectionofpredictorsduringmultivariablemodelling\nofcircumstances inwhich coverage andbiaswere within There is no consensus regarding how predictors should\nacceptable levels [119]. Another found that 20 EPV or be selected while developing the final model [25]. Two\nmore are required when low-prevalence predictors are common strategies include the \u2018full model approach\u2019and\nincluded in a model [123], while another suggested that the \u2018predictor selection approach\u2019 [23]. An alternative\nproblems may arise even when the EPV exceeds ten, as approach, known as \u2018all possible subsets regression\u2019, is\nCPR performance may depend on many other factors less commonly used [28]. In the full model approach, all\n[120]. Research in this area continues to evolve, as new previously identified candidate predictors are included,\nguidance is clearly needed to support sample size con- and no further analysis is performed. Although this ap-\nsiderations for the derivation of CPRs [121]. Recently, proach precludes selection bias and overfitting, it re-\nvan Smeden and colleagues have suggested that sample quires in-depth knowledge about the most relevant\nsize should be guided by three influential parameters: candidate predictors [26, 29]. In the predictor selection\nthe number of predictors, total sample size and the approach, predictors are chosen either by \u2018backward\neventsfraction[122]. elimination\u2019 or \u2018forward selection\u2019, based on pre-defined\nRelevant predictors may be chosen based on a com- criteria. Backward elimination begins with all predictors\nbination of clinical experience, expert opinion surveys, in the model and removes predictors, while forward se-\nqualitative studies and formal systematic reviews and lection begins with an empty model, and predictors are\nmeta-analyses of the literature [26, 33, 36, 65, 124]. added successively. All possible subsets regression can\nStrategies for reducing the number of candidate predic- build models with combinations of predictors not gener-\ntors include removing those that are highly correlated ated by the standard forward or backward procedures,\nwith others, and combining similar predictors [29]. because every conceivable combination of predictors is\nOther considerations include selecting predictors that assessed to find the best fitting model [135]. With all\nwill be readily available for clinicians to observe or methods, a series of statistical tests are performed to",
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page8of23\nassess the \u2018goodness of fit\u2019 between the different models. possible, particularly for conditions that require a con-\nModelscanbe comparedbysettingapre-definedsignifi- sensus diagnosis based on all available patient informa-\ncance level and using the log likelihood ratio test, or tion [143]. It is well known that misclassification in the\nusing other model selection criterion such as the Akaike outcome variable may cause serious problems with pre-\ninformationcriterion,ortheBayesian informationcriter- diction accuracy[144,145].\nion [23, 25]. Backward elimination is favoured, as it al-\nlows for the assessment of the effects of all predictors Internalvalidation\nconcurrently, and can take into account all correlations Predictionmodelsareknowntoperformbetterinthedata-\nbetween predictors [136, 137]. Multiple testing in all setfromwhichtheyarederived,incomparisontoapplying\npossible subsets regression can easily lead to overfitting. them in new but plausibly related patients [146, 147].\nHowever, with all methods, the choice of significance \u2018Plausiblyrelatedpatients\u2019maybedefinedasthosewhoare\nlevel impacts upon the number of final predictors; the suspected of having the same condition or who are at risk\nuse of smaller significance levels (e.g. p<0.05) produces of the same outcome examined in the derivation study\nmodels with fewerpredictors at therisk ofexcluding po- [148].Thisenhancedperformanceoccurssimplybecausea\ntentially important predictors, while the use of larger model is designed to optimally fit the available data [23].\nsignificance levels (e.g. p<0.25) may result in the inclu- The performance of a model is most likely to be overesti-\nsionoflessimportantpredictors[25]. matedwhenthederivationdatasetissmall,andusesalarge\nPredictor selection by so-called automated, data- number of candidate predictors. Therefore, regardless of\ndependent significance testing may generate overfitted, theapproachesusedinthederivationstageofdevelopment,\n\u2018optimistic\u2019 models, particularly when the derivation data- internal validation is required to examine and correct the\nsetissmall[23,28,128,138,139].Thus,theAkaikeinfor- amountofoverfittingor \u2018optimism\u2019inthemodel, and thus\nmation criterion is preferred, as it discourages overfitting thestabilityofthemodel[23].\nby comparing models based on their fit to the data and Internal validation does not validate a model itself, but\npenalising for the complexity of the model [25]. In theprocessusedtofitthemodel[26,29].Optimismises-\naddition, it may be acceptable to retain a non-significant timatedusingtheoriginalderivationdatasetonly.Anum-\npredictor in a model, if there is substantialevidence of its ber of methods are available for this purpose, including\npredictiveabilityintheliterature[26]. split-sampling, cross-validation and bootstrapping.\nSplit-sampling is the simplest method, and is performed\nDefinitionandassessmentofpredictorandoutcome by dividing the derivation dataset into a \u2018training\u2019sample\nvariables anda\u2018test\u2019samplepriortomodelling.TheCPRisthende-\nTo ensure that the CPR can be accurately applied in rived using the training sample, and its performance is\npractice, predictor and outcome variables should be assessedusingthetestsample[20].However,thetestsam-\nclearly defined, and outcome variables should be clinic- ple usually comprises one-third of the original derivation\nally important [17]. Predictor variables must be reliable dataset and islikely toberelativelysmall, resulting in im-\nto enable their assessment in clinical practice; reliability precise performance estimates [149, 150]. This approach\nrefers to the reproducibility of the findings by the same also squanders the test data that could have been used in\nclinician (intra-rater reliability) or between different cli- the derivation of the CPR [23, 150]. In cross-validation,\nnicians (inter-rater reliability). Some researchers recom- theCPRisderivedusingthewholederivationdataset,and\nmend that the reliability of predictor variables be the whole dataset is then reused to assess performance\nexplicitly evaluated, and that only those demonstrating [20]. It is randomly split into equal samples: five or ten\ngood agreement beyond that expected by chance alone samples are commonly used. In the case of five samples,\nshould be considered for inclusion [17]. A recent study themodelisrefittedusing fourofthefivesamplesandits\nfound that measurement error of predictor variables is performancetestedusingthefifth;thisprocessisrepeated\npoorly reported, and that researchers seldom state expli- five times until each of the five samples has been used as\ncitly when the predictors should be measured, and the thetestdata,andanaverageoftheestimatedperformance\nCPR applied [140]. Another study demonstrated that is taken. To improve stability, the overall procedure can\npredictor measurement heterogeneity across settings can be replicated several times, using different random sub-\nhave a detrimental impact on the performance of a CPR samples[149].Thepreferredinternalvalidationmethodis\nat external validation [141]. Ideally, the outcome variable bootstrapping, particularly when the derivation dataset is\nshould be assessed independently of the predictor vari- small or a large number of candidate predictors are\nables to avoid circular reasoning or \u2018incorporation bias\u2019, assessed [23, 29]. The idea is to mimic random sampling\nwhen the results of the CPR or its predictor variables fromthetargetpopulationbyrepeatedlydrawingsamples\nare used in the determination of the outcome [142]. of the same size with replacement from the derivation\nHowever, it is acknowledged that this is not always dataset [151]. Sampling with replacement renders",
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page9of23\nbootstrapsamplessimilar,butnotidentical,totheoriginal of interest. The predicted probabilities for patients with\nderivationsample[23].Eachstepofmodeldevelopmentis the outcome should be higher than the predicted prob-\nrepeated in each bootstrap sample (typically 500), most abilities for those who do not have the outcome [46].\nlikely yielding different models with varying performance. Theeasiest way to assess discrimination is by calculation\nEachbootstrapmodelisthenappliedtotheoriginalderiv- of the discrimination slope, which is simply the absolute\nation sample, yielding a difference in model performance. difference in the average predicted probabilities for pa-\nTheaverageofthesedifferencesindicatestheoptimismin tients with and without the outcome [26]. Discrimin-\nthe performance metrics of the model that was initially ation can also be visualised with a simple box plot. The\nderivedinthederivationdataset[23,26,29,151],anden- most widely used measure to assess discrimination is the\nablingadjustmentoftheoverallperformancetobetterap- concordance index (c-index) [156], or, for logistic\nproximate the expected model performance in novel models its equivalent, the area under the receiver oper-\nsamples [23]. Bootstrapping also estimates a uniform ating characteristic curve (AUROC) [157]. These mea-\nshrinkagefactortoenableadjustmentoftheestimatedre- sures represent the chance that, given one patient with\ngression coefficients for over-fitting [26, 29, 151]. How- the outcome and one without, the CPR will assign a\never, nointernal validation procedurescan bea substitute higher predictive probability to the patient with the out-\nfor external validation; internal validation only addresses come compared to the one without. A c-index or\nsampling variability, while external validation considers AUROC of 0.5 indicates predictions that are no better\nvariationinthepatientpopulation[147]. than random predictions, and a value of 1 represents\nperfect discrimination between patients with and with-\nClinicalpredictionruleperformancemeasures outtheoutcome[29].Intheory,aCPRmaydemonstrate\nCPR predictive performance can be assessed in terms of good discrimination (classifying patients into the correct\noverall performance, calibration and discrimination [26]. risk categories), but poor calibration (inaccurately esti-\n\u2018Overall performance\u2019 can be quantified by calculating mating the absolute probability of an outcome), and vice\nthe distance between observed and predicted outcomes, versa [158]. A model that cannot discriminate between\nusingmeasures such asR2ortheBrierscore [152].\u2018Cali- patients with and without the outcome has little use as a\nbration\u2019 reflects the agreement between the predicted CPR; however, poor calibration can be corrected without\nprobabilities produced by the model and the observed compromising discriminatory performance [19, 114].\noutcome frequencies [23]. For example, if a model pre- Van Calster and Vickers [159] found that poorly cali-\ndicts a 20% probability of residual tumour for a testicu- brated models diminish the clinical usefulness of a CPR,\nlar cancer patient, residual tumour should be observed and can be harmful for clinical decision-making under\nin about 20 out of 100 of these patients [46]. \u2018Internal certain circumstances, emphasising the importance of\ncalibration\u2019 refers to agreement between predicted prob- developing well-calibrated CPR\u2019s. On the other hand, a\nabilities and observed outcome frequencies in the deriv- CPR with poor calibration but good discrimination at a\nation dataset, where poor calibration may indicate lack particular risk threshold may be appropriate if the aim is\nof model fit or model misspecification [153]. \u2018External to prioritise patients for assessment or treatment, by\ncalibration\u2019 refers to agreement between predicted prob- identifying those with a very low risk of the target out-\nabilities and observed outcome frequencies in novel comerelativetotherestofthepopulation[160].\ndatasets external to the one from which the model was Performance measures such as sensitivity, specificity,\nderived, where poor calibration may indicate an over- positive and negative predictive values and positive and\nfitted model [153]. Calibration can be visualised by cate- negative likelihood ratios are used to assess performance\ngorising individuals into quantiles based on their following the application of a risk threshold. Choosing a\npredicted probabilities, and plotting the observed out- riskthresholdcanoftenbearbitrary,anditcanthereforebe\ncome frequencies against the mean predicted probabil- usefultoconsiderarangeofthresholdswhenassessingper-\nities [25]. Such a plot is the graphical equivalent of the formance[19].Ideally,aCPRwillhavebothahighsensitiv-\nHosmer and Lemeshow goodness-of-fit test [154], ity and a high specificity, and therefore correctly identify\nwhich, although frequently used, may lack statistical the majority of patients who truly have the condition, as\npower to identify overfitting [25, 26]. Alternatively, bin- well as correctly exclude the majority of patients who do\nary outcomes can be regressed on the predicted prob- not actually have the condition. However, this scenario\nabilities of the fitted model to estimate the observed rarely occurs in clinical practice. More often than not, the\noutcome probabilities using smoothing techniques such definition of a threshold is based on clinical considerations\nas the loess algorithm [29, 153]. A comprehensive over- about the relative consequences of false positive and false\nview ofcalibration isgiveninVanCalster etal.[155]. negative classifications. Sensitivity and specificity are in-\nDiscrimination reflects the ability of a CPR to discrim- verselyproportional,sothatassensitivityincreases,specifi-\ninate between patients with, and without, the outcome city decreases and vice versa [161]. Defining a high cut-off",
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page10of23\npoint will result in good specificity and few false positives, understanding of a CPR [168]; however, these must be\nbutpoorsensitivityandmanyfalsenegatives.Atestwitha presented alongside the full model formula. Scoring sys-\nhigh specificity is useful for ruling in a disease if a person tems are often used to simplify CPRs and facilitate use,\ntests positive. This is because it rarely misdiagnoses those where regression coefficients are converted to integer\nwho do not have the condition of interest. Defining a low point values that can be easily totalled and related back\ncut-off point will result in good sensitivity and few false to the predicted probabilities [169]. However, this trans-\nnegatives, but poor specificity and many false positives. A formation leads to a loss of information and therefore\ntestwithahighsensitivityisusefulforrulingout diseaseif reduced predictiveaccuracy[170].\na person tests negative. This is because it rarely misdiag-\nnoses those who have the condition of interest [161]. Re- Reportingthederivationofaclinicalpredictionrule\nceiver operating characteristic (ROC) curves display the Numerous systematic reviews have shown that reporting\nsensitivity and specificity of a CPR across the full range of of the derivation of CPRs is deficient [6\u20138]. As a result,\ncut-offvalues,andcanbeusedtochooseanoptimalcut-off the TRIPOD guidelines were produced [36], and should\nthreshold [162]. Other approaches to determining clinical befollowed byallresearchersworkinginthisfield.\ncut-offshavealsobeenproposed[163].\nIn recent years, some novel model performance mea- Stage3:externalvalidationandrefinementofaclinical\nsures have been proposed that quantify the clinical use- predictionrule\nfulness of a CPR, by taking into account the costs and As previously noted, CPRs perform better in the dataset\nbenefits of clinical decisions. These measures include from which they are derived compared to their application\nrelativeutility curves and decision curves [164, 165]. De- in plausibly related or \u2018similar but different\u2019 individuals,\ncision curves in particular are becoming a popular even after internal validation and adjustment [24]. Dimin-\nmethod of evaluating whether clinical decisions based ished performance can be due to overfitting, unsatisfactory\nonCPRswoulddomoregoodthanharm[166].Decision model derivation, the absence of important predictors, dif-\ncurve analysis assumes that a given probability threshold ferences in how the predictor variables are interpreted and\nis directly related to the cost to benefit ratio, and uses measured, differences in the patient samples (\u2018case mix\u2019)\nthis threshold to weight false positive and false negative and differences in the prevalence of the disease [26, 148].\npredictions. The cost to benefit ratio thus defines the There is no guarantee that even well-developed CPRs will\nrelative weight of false-positive decisions to true-positive be generalisable to new individuals. In one external valid-\ndecisions [164]. Model performance can subsequently be ation study, a CPR to detect serious bacterial infections in\nsummarised as a net benefit, by subtracting the propor- children with fever of unknown source demonstrated con-\ntion of false-positive patients from the proportion of siderably worse predictive performance, such that it was\ntrue-positive patients, weighting by the relative costs of rendereduselessforclinicalcare[146].Itisthereforeessen-\na false-positive and a false-negative result. The net bene- tial to assess the performance of a CPR in individuals out-\nfit of a CPR can be derived across and plotted against side the derivation dataset; this process is known as\nthe whole range of threshold probabilities, yielding a de- externalvalidation[28].\ncision curve, similar to ROC curves that plot the full External validation is not simply repeating the steps\nrangeofcut-offs fora sensitivity/specificity pair [164]. involved at the derivation stage in a new sample to\nexamine whether the same predictors and regression co-\nPresentationofaclinicalpredictionrule efficients are obtained; neither is it refitting the model in\nThe final step in the derivation of a CPR is to consider a new sample and comparing the performance to that\nthe format in which it should be presented. It is impera- observed in the derivation sample [24, 31]. External val-\ntive that the regression coefficients and intercept of a idation involves taking the original fully specified model,\nfinal model are presented, and confidence intervals with its predictors and regression coefficients as esti-\naround predicted probabilities can also be provided [23, mated from the derivation study; measuring and docu-\n26]. If the final regression formula (as in Table 3) is not menting the predictor and outcome variables in a new\nprovided, a CPR could not be applied by future users patient sample; applying the original model to these data\n[36]. A model can be developed into a simple web-based to predict the outcome of interest; and quantifying the\ncalculator or application to enhance the usability of a predictive performance of the model by comparing the\nCPR. This may be beneficial for complex CPRs, and predictions with the observed outcomes [20]. Perform-\nwould facilitate their integration into the electronic ance should be assessed using calibration, discrimination\nhealth record, allowing them to be used at the point of and measures to quantify clinical usefulness such as de-\nclinical care [167]. Nomograms, graphical decision trees cision curve analysis [164]. A CPR can also be refined if\nand other novel visualisation techniques could also be it demonstrates poor performance in an external valid-\nused [26, 168], which may aid in the interpretation and ationstudy.Regrettably,fewCPRsareexternallyvalidated",
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page11of23\n[27, 171, 172]. A systematic review of CPRs for children derivation study [26]. The greater the differences be-\nidentified 101 CPRs addressing 36 conditions; of these, tween the patients in the derivation and validation\nonly 17% had narrow validation and only 8% had broad samples, the stronger the test of generalisability of\nvalidation[171]. the CPR [24]. Three types of external validation have\nreceived the most attention, namely temporal valid-\nStudydesignfortheexternalvalidationofaclinical ation, geographical validation and domain validation\npredictionrule [148].\nIdeally,avalidation studyshould be conducted prospect- In temporal validation studies, the CPR is tested on\nively,byenrollingnewindividualsina specificallyprede- patients in the same centre(s) but over a different time\nsigned study, and the CPR should be applied to all period [147]. Geographical validation studies examine\npatients meeting the study inclusion criteria [17, 23]. the generalisability of the CPR to other centres, insti-\nHowever, validation studies can be conducted retro- tutes, hospitals or countries [147]. Patient characteristics\nspectively, using existing datasets. If adequate data on are likely to vary between locations, and predictor and\nthe predictor and outcome variables is available [23]. In- outcome variables are likely to be interpreted and mea-\nvestigators conducting a validation study should receive sured differently in different places, leading to greater\nbrief training on the accurate application of the CPR. If differences between the derivation and validation popu-\npossible,allpatientsshouldbesubjected tothereference lations than in a temporal validation study [24, 148]. In\nstandard, to establish their true outcome and enable domainvalidation,theCPRistested inverydifferentpa-\ncomparison with the CPR prediction. However, in some tients than those from whom it was derived, for example\ncases, this may not be feasible or practical, and an ap- in patients from a different setting (e.g. primary or sec-\npropriate and sensible proxy outcome may be used in- ondary care), or in patients of different ages (e.g. adults\nstead [173]. Stiell and Wells [17] recommend that the vs. children). The case mix of patients included in a\ninter-rater reliability of the interpretation of the CPR re- domain validation study will clearly differ from the der-\nsult is assessed, to determine if the CPR is being applied ivation population [148]. Differences between the deriv-\naccurately and consistently. In terms of sample size, for ationandvalidation populationsaregenerallysmallestin\na logistic regression model with six predictors, a mini- a temporal validation study, and greatest in a domain\nmum of 100 patients with the outcome of interest and validation study; therefore, good performance of a CPR\n100 patients without the outcome of interest has been in a temporal validation study may only provide weak\nsuggested [174]. Other authors propose that external evidence that the CPR can be generalised to new pa-\nvalidation studies require a minimum of 100 events, but tients, while good performance in a domain validation\nideally 200 events [175]. A minimum of 200 events and study can be considered as the strongest evidence of\n200 non-events has been suggested in order to reliably generalisability [148]. Other types of external validation\nassess moderate calibration and produce useful calibra- studies include methodologic validation which refers to\ntion plots [155]. The characteristics of patients included testing using data collected via different methods,\nin a validation study should be described in detail, and spectrum validation which refers to testing in patients\ncompared with those included in the derivation study. with different disease severity or prevalence of the out-\nTo enhance the interpretation of external validation come of interest and fully independent validation which\nstudies, it is possible to quantify the degree of relatedness refers to testing by independent investigators at different\nbetween derivation and validation datasets, to determine sites [26, 147]. A recent study of cardiovascular risk\nthe extent to which the CPR can be generalised to differ- CPRs found that very few were externally validated by\nent populations [34]. Authors have also proposed bench- independent researchers; to increase the chance of fully\nmark values to distinguish between a case-mix effect and independent validation, researchers should report all the\nincorrect regression coefficients in external validation information required for risk calculation, to ensure rep-\nstudies, and therefore assist in the interpretation of a licability [178]. Some authors have found that CPRs\nCPR\u2019s performance in validation samples [176]. Similarly, demonstrate worse performance in fully independent\na model-based concordance measure has recently been external validation studies compared to temporal or\nderivedthatenablesquantificationoftheexpectedchange geographical external validation studies [26, 28], while\ninaCPR\u2019sdiscriminativeabilityowingtocase-mixhetero- others have found no difference [179]. When multiple\ngeneity[177]. external validations of a CPR have been performed, it is\nuseful to conduct a formal meta-analysis to summarise\nTypesofexternalvalidation its overall performance across different settings and to\nMany types of external validation are recognised in assessthecircumstancesunderwhichtheCPRmayneed\nthe literature, but all types consider patients that dif- adjusting; a recently published framework provides guid-\nfer in some respect from the patients included in the anceonhowtodothis [35].",
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page12of23\nRefinementofaclinicalpredictionrule:modelupdatingor statistics cannot be recommended [192]. Decision-analytic\nadjustment methodsareincreasinglyrecommendedastheyincorporate\nWhen researchers encounter an inferior performance of misclassification costs and therefore indicate the clinical\na CPR in an external validation study compared with usefulness of CPRs [186]. A systematic review of compari-\nthat found in the derivation study, there is a temptation sons of prediction models for cardiovascular disease found\nto reject the CPR and derive an entirely new one in the that formal and consistent statistical testing of the differ-\noften considerably smaller validation dataset [148, 180]. encesbetweenmodelswaslackingandthatappropriaterisk\nThis approach leads to a loss of scientific information reclassification measures were rarely reported [193]. A re-\ncaptured in the derivation study and an abundance of cent commentary provides a useful and comprehensive\nCPRs developed for the same clinical situation, leaving overviewoftheadvantagesanddisadvantagesofthevarious\nclinicians in a quandary over which one to use [24, 148]. methods available for quantifying the added value of new\nHowever, a reduction in performance is to be expected biomarkers[194].\nin an external validation study [24, 26, 148]. The recom-\nmended alternative is to update, adjust or recalibrate the Reportingtheexternalvalidationofaclinicalprediction\nCPR using the validation data, thereby combining infor- rule\nmation captured in the original CPR with information External validation studies of CPRs are often poorly re-\nfrom new patients and improving generalisability [22, ported [9]; researchers should adhere to the TRIPOD\n181, 182]. Several methods for updating CPRs are avail- checklist andaccompanyingguidelines[36].\nable. When the outcome prevalence in the validation\nstudy is different to that in the derivation study, calibra- Stage4:impactofaclinicalpredictionruleonclinical\ntion in the validation sample will be affected, but can be practice\nimproved by adjusting the baseline risk (intercept) of the Since the ultimate aim of a CPR is to improve the qual-\noriginal model to the patients in the validation sample ity of patient care, the effect of a validated CPR on clin-\n[180]. If the CPR is overfitted or underfitted, calibration ician behaviour and patient outcomes should be\ncan be improved by simultaneously adjusting all of the examined in what are known as impact analysis studies\nregression coefficients [24]. To improve discrimination, [22, 24]. It is increasingly recognised that CPR\u2019s should\nindividual regression coefficients can be re-estimated, or be regarded as complex interventions, as the introduc-\nadditional predictors can be added [24, 180]. Ideally, up- tion of a CPR into clinical practice with subsequent\ndated CPRs that are adjusted to validation samples management decisions consists of multiple interacting\nshould themselves be externally validated, just like newly components [108, 195\u2013201]. The impact of a CPR on\nderivedCPRs[148]. clinical practice will depend on several interacting fac-\ntors, including theaccuracy andapplicability ofthe CPR,\nComparingtheperformanceofclinicalpredictionrules clinicians\u2019 interpretation of probabilities and clinicians\u2019\nOnce a CPR has been externally validated, it is useful to adherence to and acceptance of the CPR [196]. Evaluat-\ncompare its performance with the performance of other ing the impact of a CPR has been described as \u2018the next\nexisting CPRs for the same condition [61]. Improve- painful step\u2019 in the development process [202]. Impact\nments in discrimination can be assessed by quantifying analysis studies clearly differ from validation studies as\nthe difference in the AUROC or equivalent c-index be- they must be comparative, typically requiring a control\ntween two CPRs [183]; however, this approach is in- group of clinicians providing usual care [22, 24, 32]. It is\nappropriate in the case of nested models that are fitted possible to assess the impact of both assistive CPRs that\nin the same data set [184]. Novel metrics have been pro- simply provide predicted probabilities, and directive de-\nposed that quantify the extent to which a new CPR im- cision rules that suggest a specific course of action based\nproves the classification of individuals with and without onprobability categories [32].AssistiveCPRsrespectcli-\nthe outcome of interest into predefined risk groups [46]. nicians\u2019 individual judgement and leave room for intu-\nThese include the net reclassification improvement ition, whereas directive rules may be more likely to\n(NRI), and the integrated discrimination improvement influence clinician behaviour [32, 203, 204]. However, it\n(IDI) [185]. Various decision-analytic approaches to is not guaranteed that clinicians will follow CPR, or the\nmodel comparison have also been proposed [186]. All of recommendations provided by directive rules [32].\nthese measures can be used for comparing both nested Therefore, an impact study must demonstrate that clin-\nand non-nested models. However, both the NRI and IDI ical behaviour can be altered and patient care improved\nstatistics have come under intense scrutiny in the litera- by the CPR, prior to widespread dissemination and im-\nture and many researchers caution against their use, as plementation[17].\npositive values may arise simply due to poorly fitted Unfortunately,evenfewerCPRsundergoanimpactas-\nmodels [30, 187\u2013191]. Therefore, the NRI and IDI sessment than undergo external validation. In the",
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page13of23\nsystematic review of 101 CPRs for children, none had Given the significant practical, logistic and economic\nimpact analysis performed [171]. An evaluation of 434 challenges associated with cluster randomised trials,\nprimary care CPRs found that only 12 had undergone non-randomised approaches are possible and are often\nimpact analysis [172]. A subsequent systematic review of used. Cluster randomised trials can be expensive and\nthe impact of primary care CPRs found 18 studies relat- time-consuming and it may be difficult to recruit an ad-\ningto14CPRs,with10/18studiesdemonstratinganim- equate number of clusters [24, 108]. A suggested\nprovement in primary outcome when the CPR was used rule-of-thumb is to regard four clusters per arm as the\ncomparedtousualcare[205].Thisreviewcautionedthat absolute minimum number required [211]; however,\nthe small number of impact analysis studies found pre- methods for determining sample size in cluster rando-\ncluded the possibility of drawing firm conclusions about mised trials have been proposed by a number of authors\nthe overall effectiveness of CPRs in primary care, with [212\u2013214]. A popular design is a before\u2013after study, in\nthe authors pointing out that the methodological quality which outcomes are assessed in a time period before a\nof the included studies was unclear due to incomplete CPR is available and compared with outcomes measured\nreporting [205]. Another recent systematic review of the in a time period after it is introduced; this design is sus-\nimpact of CPRs found that the intermediate conse- ceptible to temporal confounding [24]. Finally, a rela-\nquences of a CPR such as clinical management decisions tively low-cost and simple design is a before\u2013after study\nwere the primary outcome in the majority of studies, within the same clinicians. In this design, clinicians are\nwhile few studies aimed to establish the effect of a CPR asked to indicate their treatment or management deci-\non patient outcomes [206]. In addition, in many of the sion or perceived risk of disease for the same patient\nincluded studies, the risk of bias was either high or un- both before, and after, receiving the CPR prediction [24].\nclear [206]. Finally, a study describing the distribution of Single centreimpactstudiesarerecommendedtoinform\nderivation, validation and impact studies in four reviews the planning of multicentre randomised trials [32]. As\nof leading medical journals since 1981 demonstrated with derivation and validation studies, a sample size cal-\nthat a minority of studies concerned CPR impact (10/ culation should be performed, with consideration of all\n201),with thepattern remainingstable overtime[27]. relevant impact measures, and where possible assess-\nment of outcome measures should be blinded to the\nStudydesignforanimpactanalysis CPR predictions and recommendations [32, 33]. Clini-\nBefore carrying out a formal impact study, researchers cians must undergo training in order to correctly inter-\nmust consider whether the CPR is ready for implemen- pretandusetheCPR[17].\ntation [108, 207]. If possible, the predictive performance The impact of CPRs can also be estimated indirectly\nofthe CPR should be verified inthenewsetting,and the usingdecisionanalyticmodelling,whichintegratesinfor-\nCPR tailored to the new setting to enhance performance mation on CPR predictions and information about the\n[108]. The optimal study design for an impact analysis is effectivenessof treatmentsfrom therapeuticintervention\na cluster randomised trial with centres as clusters [22]. studies [215, 216]. Such studies cost less, and take less\nRandomising individual patients is not recommended as time,thanRCTs;however,theyarelimited bythequality\ncliniciansmaylearn theruleandapply ittopatientsran- of available evidence, and only provide theoretical indi-\ndomised to the control group [22]. Randomising clini- cations of the impact CPRs may have on patient out-\ncians is preferable but requires more patients, and may comes. Thus it has been suggested that they should not\nlead to contamination of experience between clinicians replace RCTs but rather be performed as an intermedi-\nin the same centre [24, 208]. An attractive variant of a atesteppriortoanRCT[217].\ncluster randomised trial is the stepped-wedge cluster\nrandomised trial. In a stepped-wedge design, all centres Measuresofimpactofaclinicalpredictionrule\napply care-as-usual, and then use the CPR at different, Duringanimpactanalysisstudy,thesensitivityandspeci-\nrandomly allocated time periods [209]. Thisdesignallows ficity of the CPR should be recalculated to determine its\nfor the comparison of outcomes both within and between accuracyinthenewstudypopulation[17].However,mea-\nhospitals, generates a wealth of data regarding potential suresofCPRaccuracyarenotsynonymouswithmeasures\nbarriers to implementation and is particularly beneficial if of impact, and only represent the potential impact of the\nthe CPR turns out to have a promising effect [210]. When CPR [32]. This is because clinicians are unlikely to follow\nthe outcome of interest in an impact study is clinician be- thelogicoftheCPRoritsrecommendationsineverycase;\nhaviour or decision-making, a cross-sectional randomised they may not use the CPR at all, they may not use it cor-\nstudy without patient follow-up is sufficient, with random- rectly, they may deliberately disregard its predictions or\nisation at either the patient or clinician level. However, to suggestions or they may be unable touse it for other rea-\ndetermine the impact of a CPR on patient outcomes or sons [32]. Measures that are assessed in traditional RCTs\ncost-effectiveness,follow-upofpatientsisessential[22]. includesafety,whichreferstoanyadverseeventsresulting",
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page14of23\nfrom the implementation of an intervention, and efficacy, with and without the condition of interest should be su-\nwhich relates to the extent that an intervention helps to perior to that of unstructured clinical judgement alone.\nimprove patient outcomes, for example by reducing mor- Therefore,avitalmetricisthecomparisonoftheaccuracy\ntality rates [218]. In addition, Reilly and Evans [32] of the CPR-predicted probabilities of disease, or recom-\npropose that the impact of a CPR is assessed in terms of mendeddecisions,withtheaccuracyofcliniciansownes-\nits \u2018safety\u2019 and \u2018efficiency\u2019, where safety is defined as the timated disease probabilities or management decisions\nproportionofpatientsfoundtohavetheoutcomeofinter- [18]. The sensitivity and specificity of clinicians\u2019 predic-\nestandwhoreceivedtheappropriateintervention,andef- tions or decisions are generally measured under usual\nficiency is defined as the proportion of patients without practice,andcomparedtothesensitivityandspecificityof\ntheoutcomeofinterestandwhodidnotreceivetheinter- the CPR predictions or decisions when applied to the\nvention. The sensitivity and specificity of a CPR will only same patients [226, 227]. Some studies have used clinical\nbe the same as its safety and efficiency if clinicians follow vignettes[228]whileothershaveusedmultivariablelogis-\nthe logic and recommendations of the CPR exactly [32]. tic models to assess the added value of a CPR over and\nTherefore,inanimpactanalysisstudy,aCPRmaydemon- above clinical judgement alone [229]. If it can be demon-\nstrate more, or less, actual impact than its potential im- strated that the performance of a CPR is superior to un-\npact. The effect of clinicians\u2019 incorrect use of the CPR, or aided clinician judgement, this may aid clinicians\u2019\ntheir deviations from its logic or suggestions can provide acceptanceanduseoftheCPR[32].Althoughcomparison\nimportant insights into its impact under specific circum- ofaCPRtocliniciansuspicionregularlytakesplaceatthe\nstances,andmayrevealcomplexinteractionsbetweencli- impact analysis stage, some researchers have recom-\nnicians and the CPR [32]. For example, Reilly and mended that this is carried out during the derivation or\ncolleagues [219] found that when clinicians did not con- validation stages, arguing that if the CPR does not add\nsult a CPR for suspected acute cardiac ischemia at all, or anything beyond clinical judgement, then the use of the\noverruled its recommendations, their decisions were less CPR and an impact study would not be warranted [230].\nefficientthaniftheyhadfollowedtheCPRineverycase. In addition, Finnerty and colleagues [231] recommend\nthat comparison is undertaken in multiple settings, as the\nAcceptabilityofaclinicalpredictionrule performance of a CPR may be superior to clinical judge-\nIf the use of a CPR is warranted but it is not used, the ment in certain settings, but inferior or no different in\nconsiderable time, money and effort that goes into its other settings. A recent systematic review comparing\ndevelopment and evaluation is wasted. Assessing the ac- CPRs with clinical judgement concluded that the differ-\nceptability of a CPR is therefore crucial for successful ences between the two methods of judgement are likely\nimplementation. Even valid and reliable CPRs may not due to different diagnostic thresholds, and that the pre-\nbe accepted or used by clinicians [17]. Impact studies ferred judgement method in a given situation would\nallow researchers to evaluate the acceptability of a CPR therefore depend on the relative benefits and harms\nto clinicians, patients or others who may use it, as well resulting from true positive and false positive diagnoses\nas its ease ofuseandbarriers toitsuptake[22]. If aCPR [232].Brownandcolleagues\u2019[200]foundthattheuseand\nproves to be acceptable, its long-term and widespread potential advantages of a CPR may be much more com-\ndissemination and implementation would be justified; if plexthanoriginallythought,andthatCPRsmaybeuseful\nnot, the CPR could undergo modification and further for purposes not previously reported, such as enhancing\nevaluation [48]. Acceptability of a CPR and attitudes to- communicationwithcolleaguesandpatients,andmedico-\nwards it can be determined via survey, qualitative, simu- legalpurposes.Recent studiesinthe childprotectionfield\nlation or clinical vignette studies [33, 48, 220\u2013222]. The havedemonstratedthatCPRs mayprovideclinicians with\nvalidated Ottawa Acceptability of Decision Rules survey additional confidence in their decision-making, even if\ninstrument can be used both to measure the overall ac- they do not alter their management actions based on the\nceptability of a CPR, and to assess specific barriers to its CPRsriskprediction[220,233].\nuse, which can inform potential improvements to the\nCPR as well as the design of dedicated implementation Thefourphasesofimpactanalysisforclinicalprediction\nstrategies [48]. Qualitative studies can be invaluable for rules\ndetermining the acceptability of a CPR but are relatively Despite the abundance of methodological guidelines for\nrare[200,220,222\u2013225]. thederivationandvalidationofCPRs[26],thereisalack\nof clear guidance for the design, conduct and reporting\nComparisonofaclinicalpredictionrulewithunstructured of impact analysis studies of CPRs. To this end, Wallace\nclinicaljudgement and colleagues [33] formulated an iterative four-phased\nFor a CPR to improve the diagnostic accuracy of clini- framework for the impact analysis of CPRs, specifying\ncians, its performance in distinguishing between patients the importance of substantial preparatory and feasibility",
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page15of23\nwork prior to the conduct of a full-scale formal experi- Stage5:cost-effectivenessoftheclinicalpredictionrule\nmental study (Fig. 2). Phase 1 involves determining If an impact analysis study shows that a CPR demon-\nwhether the CPR is ready for impact analysis, i.e. strates safety and efficiency, alters clinician behaviour\nwhether it has been rigorously derived and broadly vali- andimproves clinical care,aformaleconomicevaluation\ndated according to pre-defined methodological stan- can be carried out to determine the cost-effectiveness of\ndards. Phase 2 includes assessing the acceptability of the the CPR. The aim is to establish the health care savings\nCPR and identifying potential barriers to its uptake and associated with routine use of the CPR in clinical prac-\nimplementation, as well as assessing the feasibility of tice [17]. Economic evaluation is usually based on deci-\nconducting an impact study. Evaluating the feasibility of sion analytic models [234]. Any economic evaluation\ncarrying out an impact study involves consideration of must make reasonable assumptions about the accuracy\nmultiple factors including the most appropriate study and effectiveness of the CPR and the costs involved [17].\ndesign for measuring relevant outcomes, and how the Sensitivity analyses should be performed by re-running\nCPR will be delivered at the point of care or integrated models with alternative assumptions, to examine the un-\nintotheclinicalworkflow.Phase3involvesformallytest- certainty of the model projections [234]. In reality, many\ning the impact of the CPR usinga comparative study de- economic evaluations are conducted prior to an impact\nsign. Phase 4 involves long-term dissemination and analysis study or even an external validation study, per-\nimplementation of the CPR, which corresponds to stage haps because they are relatively quick and low cost to\n6inthedevelopmentofCPRs,discussedbelow. perform, and provide a significant part of the justifica-\ntion forthedevelopment andimplementation ofaCPR.\nReportingtheimpactanalysisofaclinicalpredictionrule Stage6:long-termimplementationanddisseminationof\nThere are currently no published reporting guidelines theclinicalpredictionrule\nfor studies analysing the impact of CPRs. This is a gap The gap between evidence and practice has been con-\nin the literature, and a priority for future research. How- sistently demonstrated in health services research [235],\never, researchers assessing the impact of CPRs in an and there is no guarantee that a CPR will be widely dis-\nRCT may refer to guidelines on the reporting of clinical seminated or used, even if it is shown to have a positive\ntrials, such as the Consolidated Standards of Reporting impact on clinical care and cost benefits. Therefore, in\nTrials (CONSORT)statement[218]. order to maximise the uptake of a CPR, an active\nFig.2Thefourphasesofimpactanalysisforaclinicalpredictionrule.ReproducedwithpermissionfromWallaceetal.2011[33]",
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page16of23\nTable4Barrierstotheuseofclinicalpredictionrulesinpractice Table4Barrierstotheuseofclinicalpredictionrulesinpractice\nidentifiedintheliterature identifiedintheliterature(Continued)\nTheme Subtheme Barrier Theme Subtheme Barrier\nKnowledge Awareness Unaware: (cid:129)TheCPRisnotgeneralisabletotheclinician\u2019s\npatient\n(cid:129)ThatCPRexists\n(cid:129)TheCPRisstaticanddoesnotconsiderthe\n(cid:129)Ofclinicalproblemorburdenofclinical\ndynamicnatureofclinicalpractice\nproblemtowhichCPRapplies\n(cid:129)OverrulingtheCPRisoftenjustified\nUnabletochoosefrommultipleCPRs\nDatarequiredfortheCPRisdifficulttoobtain\nFamiliarity UnfamiliarwithCPR\nEnvironmental Lackof:\nUnderstanding Lackofknowledgeandunderstandingofthe\nfactors\npurpose,developmentandapplicationofCPRsin (cid:129)Time\ngeneral\n(cid:129)Organisationalsupport\nForgetting ClinicianforgetstouseCPRdespitebest\n(cid:129)Peersupportforuse\nintentions\nPerceivedincreasedriskoflitigation\nAttitudes Negativebeliefs Beliefthat:\naboutCPRs (cid:129)CPRsthreatenautonomy Insufficientincentivesorreimbursementforuse\noftheCPR\n(cid:129)CPRsaretoo\u2018cook-book\u2019,andoversimplifythe\nAdaptedfromSanders2015[253].CPRclinicalpredictionrule\nclinicalassessmentprocess\n(cid:129)ClinicaljudgementissuperiortoCPRs\n(cid:129)Clinicaljudgementisnoterrorprone dissemination and implementation plan must be in\nplace. Simple passive diffusion of study results via publi-\n(cid:129)UseofCPRscausesintellectuallaziness\ncation in journals or presentations at conferences is un-\n(cid:129)ThedevelopmentoftheCPRwasbiased\nlikely to significantly change clinical practice [236].\n(cid:129)Patientswilldeemclinicianslesscapableif\nusingaCPR Examplesofdisseminationincludeactivelytargetingspe-\n(cid:129)CPRsonlyapplytothelessexperienced cific audiences via direct mail or the press, while imple-\nmentation involves the use of local administrative,\n(cid:129)Probabilitiesarenothelpfulfordecision-making\neducational, organisational and behavioural strategies to\nDislikeoftheterm\u2018rule\u2019\nput the CPR into effect in clinical practice [236]. Active\nClinicianhadafalsenegativeresultwhenusinga\nCPRinthepast broad dissemination of the widely accepted Ottawa ankle\nrule via an educational intervention found no impact of\nExistingCPRsarenotreadyforclinicalapplication\ntheruleonclinicians\u2019useofankleradiography[237],lead-\nOutcome Beliefthat:\nexpectancy ing the authors to recommend implementation strategies\n(cid:129)CPRswillnotleadtoimprovedpatientor\nprocessoutcomes at the local level instead. Some implementation strategies\n(cid:129)TheinformationprovidedbytheCPRisnot havebeenfoundtobemoreeffectivethanothersinchan-\nsufficienttoalterclinicaldecisions ging clinician behaviour. A systematic review found the\nClinician: most effective approaches to be reminders in the form of\n(cid:129)Fearsunintendedconsequencesofuse posters, pocket cards, sheets or computer-embedded\n(cid:129)IsuncertainaboutusingtheCPRinpatients prompts,face-to-facelocalclinicianeducationandtheuse\nwithanatypicalpresentation of multiple interventions simultaneously [238]. Incorpor-\n(cid:129)Worriesthatimprovingefficiencythreatens ationofCPRsintoclinicalguidelinesmayalsobeof bene-\npatientsafety\nfit; a recent study found that clinical guidelines and local\nSelf-efficacy BeliefthattheCPRistoodifficulttouse\npolicies that mandated the use of CPRs were effective in\nClinicianuncertainhowtointerpretoruseCPR increasing their adoption in clinical practice [200]. In\noutput\naddition, the integration of CPRs into the clinical work-\nMotivation ClinicianlacksmotivationtousetheCPR\nflow via electronic health records may promote their use\nBehaviour Patientfactors Patientsexpectationsarenotconsistentwiththe\nCPR [239]. Since impact in a research study does not ensure\nimpact in real-world clinical practice, follow-up of clini-\nFeaturesofthe Clinician:\nCPR cianscanbeconductedtoassessthelong-termuseandef-\n(cid:129)FindsCPRtoocomplicated\nfectoftheCPR[17,33].\n(cid:129)FindsCPR\u2018toomuchtrouble\u2019toapply\nPerceptionthat:\nBarriersandfacilitatorstotheuseofclinicalprediction\n(cid:129)TheCPRisnotanefficientuseoftime\n(cid:129)TheCPRdoesnothavefacevalidityorthat rules\nimportantpredictorsaremissing Clearly,identifyingthebarriersandfacilitatorstotheimple-\n(cid:129)TheCPRdoesnotfitinwithusualworkflowor mentation of CPRs is crucial for the development of tar-\napproachtodecision-making geted implementation strategies that may encourage",
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page17of23\nclinicianstousetheCPR.TheadoptionofCPRsintoclinical impact analysis of existing ones [33]. The CPR must be\npractice is influenced by various factors including clinician presented in full, and the study methods reported ad-\ncharacteristics,patientfactors,featuresoftheCPRitselfand equately,toensureitsquality,riskofbiasandclinicalutil-\nenvironmentalfactors[32,66,221,224,225,240\u2013252]. ity can be evaluated; the TRIPOD guidelines should be\nTable4providesanoverviewofthebarrierstotheadop- followed to ensure completeness of reporting require-\ntionofCPRsidentifiedintheliterature[253],groupedac- ments[36].Feasibilityandpreparatoryworkisessentialto\ncordingtotheireffectonclinicianknowledge,attitudesor determine whether a formal impact study of the CPR is\nbehaviours [254]. Barriers relating to knowledge include warranted [33, 108], and survey and qualitative work\nlackofawarenessoftheCPRortheburdenoftheclinical shouldbeundertakentoverifywhethertheCPRisaccept-\nproblem it applies to, unfamiliarity with the CPR and a able and relevantto clinicians [48, 65, 220, 222]. If a CPR\nlack of understanding of the purpose of CPRs in general isfoundtohaveapositiveimpactonpatientoutcomes,its\n[225, 240\u2013242]. Clinicians may also be unaware of a CPR cost-effectiveness should be evaluated, and a targeted im-\ndue to the increasing volume of CPRs, particularly when plementation and dissemination strategy devised, with\ntheyaredevelopedforthesamecondition[61,243].Com- consideration of possible barriers to implementation, to\nmon barriers relating to clinician attitude include a con- maximiseuptake[17].\nvictionthatclinicaljudgementissuperiortotheCPR,and In summary, the development and evaluation of a ro-\ndistrustoftheaccuracyoftheCPR[32,224,240,241,244, bust, clinically useful CPR with high predictive accuracy\n245]. Barriers relating to behaviour include organisational is challenging, and research in the field concerning der-\nfactors [251], the complexity of the CPR and the time it ivation, validation and impact evaluation continues to\ntakestoapply;surveystudiessuggestthatcliniciansmuch evolve.However,adheringtotheexistingmethodological\nprefer a CPR that is simple to use, memorable and saves standards and recommendations in the literature at\ntime[221,246,247].Complexmodelssuchasthosebased every step will help to ensure a rigorous CPR that has\non machine and artificial learning algorithms may intro- the potential to contribute usefully to clinical practice\nduce additional barriers relating to applicability and us- anddecision-making.\nability, due to their potential lack of reproducibility and\ntransparency [60, 82]. Other studies have demonstrated Abbreviations\nAUROC:Areaunderthereceiveroperatingcharacteristiccurve;CPR:Clinical\nthat clinicians will be unlikely to use a CPR if there are\npredictionrule;EPV:Eventspervariable;IDI:Integrateddiscrimination\npredictors missing which are deemed to be important, or improvement;MAR:Missingatrandom;MCAR:Missingcompletelyat\nif the predictor variables are not logically related to the random;MNAR:Missingnotatrandom;NRI:Netreclassification\nimprovement;RCT:Randomisedcontrolledtrial;ROC:Receiveroperating\noutcome variable [32, 225]. Reilly and Evans [32] offer a\ncharacteristiccurve;TRIPOD:TransparentReportingofamultivariable\nnumberofstrategiesforovercomingbarrierstotheuseof predictionmodelforIndividualPrognosisorDiagnosis\nCPRs. These includeemphasising the discretionaryuse of\nthe CPR, comparing clinical judgement with the CPR, Acknowledgements\nWewouldliketothankHealthandCareResearchWalesforfundingthis\ncheckingwhetheranyexcludedfactorsaffecttheCPRpre-\nwork.\ndictions, performing a simulatedimpact analysis and soli-\nciting clinicians input regarding the logic and format of Funding\ntheCPR,amongothers[32]. ThisworkwassupportedbyHealthandCareResearchWales(grantnumber\nHS-14-24).Thefundershadnoinvolvementinthestudydesign,thecollec-\ntion,analysisorinterpretationofthedata,thewritingofthemanuscriptor\nSummary\nthedecisiontosubmitthemanuscriptforpublication.\nFor CPRs to be useful in clinical practice, they must be\nproperlyplanned[67],derivedusingappropriatestatistical Availabilityofdataandmaterials\ntechniques [23] and externally validated in multiple set- Notapplicable.\ntings and by independent investigators to determine their\nAuthors\u2019contributions\npredictiveaccuracy[148].Inaddition,CPRsmustundergo\nLECconductedtheliteraturesearch,draftedthemanuscript,producedthe\nimpact analysis to determine their effect on clinician be- tables,boxesandfiguresandeditedthemanuscript.DMF,SMandAMK\nhaviourandrelevantpatientoutcomes[22].Therearenu- criticallyrevisedthemanuscriptforimportantintellectualcontent.Allauthors\napprovedthefinalversionsubmittedforpublication.\nmerous factors to consider when deriving, validating and\nassessing the impact of a CPR including the study design,\nEthicsapprovalandconsenttoparticipate\npreparatory work, statistical analysis, modelling strategy, Notapplicable.\nperformance/impact measures, the presentation of the\nCPR and the reporting of the study methodology. New Consentforpublication\nNotapplicable.\nCPRsshouldonlybederivedwhenthereisaclearclinical\nneedforthem[17].Thereisanurgentneedtochangethe\nCompetinginterests\nfocus from the derivation of CPRs, to the validation and Theauthorsdeclarethattheyhavenocompetinginterests.",
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page18of23\nPublisher\u2019s Note 26. SteyerbergE.Clinicalpredictionmodels:apracticalapproachto\nSpringerNatureremainsneutralwithregardtojurisdictionalclaimsin development,validationandupdating.NewYork:Springer-Verlag;2009.\npublishedmapsandinstitutionalaffiliations. 27. SteyerbergEW,MoonsKG,vanderWindtDA,HaydenJA,PerelP,Schroter\nS,etal.Prognosisresearchstrategy(PROGRESS)3:prognosticmodel\nReceived:13August2018Accepted:12May2019 research.PLoSMed.2013;10(2):e1001381.\n28. AltmanDG,RoystonP.Whatdowemeanbyvalidatingaprognostic\nmodel?StatMed.2000;19(4):453\u201373.\n29. HarrellF.Regressionmodelingstrategies:withapplicationstolinearmodels,\nReferences\nlogisticregression,andsurvivalanalysis.NewYork:Springer;2001.\n1. AdamsST,LevesonSH.Clinicalpredictionrules.BMJ.2012;344:d8312.\n30. WynantsL,CollinsGS,VanCalsterB.Keystepsandcommonpitfallsin\n2. BeattieP,NelsonR.Clinicalpredictionrules:whataretheyandwhatdo developingandvalidatingriskmodels.BJOG.2017;124(3):423\u201332.\ntheytellus?AustJPhysiother.2006;52(3):157\u201363.\n31. CollinsGS,MaJ,GerryS,OhumaE,OdondiLO,TrivellaM,etal.Risk\n3. LaupacisA,SekarN,StiellIG.Clinicalpredictionrules.Areviewandsuggested\npredictionmodelsinperioperativemedicine:methodological\nmodificationsofmethodologicalstandards.JAMA.1997;277(6):488\u201394.\nconsiderations.CurrAnesthesiolRep.2016;6(3):267\u201375.\n4. McGinnTG,GuyattGH,WyerPC,NaylorCD,StiellIG,RichardsonWS.Users'\n32. ReillyBM,EvansAT.Translatingclinicalresearchintoclinicalpractice:impactof\ng ruu leid se .Es vt io deth ne cem -be ad si ec dal mlit ee dra ictu inr ee: wX oX rII k: ih no gw grt oo uu ps .e JAa Mrti Acl .e 2s 0a 0b 0o ;2u 8t 4c (1li )n :7ic 9a \u2013l 8d 4e .cision usingpredictionrulestomakedecisions.AnnInternMed.2006;144(3):201\u20139.\n33. WallaceE,SmithSM,Perera-SalazarR,VaucherP,McCowanC,CollinsG,et\n5. HendriksenJM,GeersingGJ,MoonsKG,deGrootJA.Diagnosticand\nprognosticpredictionmodels.JThrombHaemost.2013;11(Suppl1):129\u201341. al.Frameworkfortheimpactanalysisandimplementationofclinical\npredictionrules(CPRs).BMCMedInformDecisMak.2011;11:62.\n6. BouwmeesterW,ZuithoffNP,MallettS,GeerlingsMI,VergouweY,\n34. DebrayTP,VergouweY,KoffijbergH,NieboerD,SteyerbergEW,MoonsKG.\nSteyerbergEW,etal.Reportingandmethodsinclinicalpredictionresearch:\nasystematicreview.PLoSMed.2012;9(5):1\u201312. Anewframeworktoenhancetheinterpretationofexternalvalidation\nstudiesofclinicalpredictionmodels.JClinEpidemiol.2015;68(3):279\u201389.\n7. MallettS,RoystonP,DuttonS,WatersR,AltmanDG.Reportingmethodsin\n35. DebrayTP,DamenJA,RileyRD,SnellK,ReitsmaJB,HooftL,etal.A\nstudiesdevelopingprognosticmodelsincancer:areview.BMCMed.2010;8:20.\nframeworkformeta-analysisofpredictionmodelstudieswithbinaryand\n8. CollinsGS,MallettS,OmarO,YuL-M.Developingriskprediction\ntime-to-eventoutcomes.StatMethodsMedRes.2018.https://doi.org/10.\nmodelsfortype2diabetes:asystematicreview ofmethodologyand\n1177/0962280218785504.\nreporting.BMCMed.2011;9:103.\n36. MoonsKG,AltmanDG,ReitsmaJB,IoannidisJP,MacaskillP,SteyerbergEW,\n9. CollinsGS,deGrootJA,DuttonS,OmarO,ShanyindeM,TajarA,etal.External\netal.Transparentreportingofamultivariablepredictionmodelfor\nvalidationofmultivariablepredictionmodels:asystematicreviewof\nindividualprognosisordiagnosis(TRIPOD):explanationandelaboration.\nmethodologicalconductandreporting.BMCMedResMethodol.2014;14:40.\nAnnInternMed.2015;162(1):W1\u2013W73.\n10. KleinrouwelerCE,Cheong-SeeFM,CollinsGS,KweeA,ThangaratinamS,\n37. LoBWY,FukudaH,NishimuraY,FarrokhyarF,ThabaneL,LevineMAH.\nKhanKS,etal.Prognosticmodelsinobstetrics:available,butfarfrom\napplicable.AmJObstetGynecol.2016;214(1):79\u201390e36. Systematicreviewofclinicalpredictiontoolsandprognosticfactorsin\naneurysmalsubarachnoidhemorrhage.SurgNeurolInt.2015;6:135.\n11. EttemaRG,PeelenLM,SchuurmansMJ,NierichAP,KalkmanCJ,MoonsKG.\nPredictionmodelsforprolongedintensivecareunitstayaftercardiacsurgery: 38. HopperAD,CrossSS,HurlstoneDP,McAlindonME,LoboAJ,Hadjivassiliou\nsystematicreviewandvalidationstudy.Circulation.2010;122(7):682\u20139. M,etal.Pre-endoscopyserologicaltestingforcoeliacdisease:evaluationof\n12. CollinsGS,OmarO,ShanyindeM,YuLM.Asystematicreviewfindsprediction aclinicaldecisiontool.BMJ.2007;334:729.\nmodelsforchronickidneydiseasewerepoorlyreportedandoftendeveloped 39. LaValleyMP,LoGH,PriceLL,DribanJB,EatonCB,McAlindonTE.\nusinginappropriatemethods.JClinEpidemiol.2013;66(3):268\u201377. Developmentofaclinicalpredictionalgorithmforkneeosteoarthritis\n13. NayakS,EdwardsDL,SalehAA,GreenspanSL.Performanceofrisk structuralprogressioninacohortstudy:valueofaddingmeasurementof\nassessmentinstrumentsforpredictingosteoporoticfracturerisk:a subchondralbonedensity.ArthritisResTher.2017;19:95.\nsystematicreview.OsteoporosInt.2014;25(1):23\u201349. 40. SteyerbergEW,MushkudianiN,PerelP,ButcherI,LuJ,McHughGS,etal.\n14. AltmanDG.Prognosticmodels:amethodologicalframeworkandreviewof Predictingoutcomeaftertraumaticbraininjury:developmentand\nmodelsforbreastcancer.CancerInvestig.2009;27(3):235\u201343. internationalvalidationofprognosticscoresbasedonadmission\n15. CollinsGS,MichaelssonK.Fractureriskassessment:stateoftheart, characteristics.PLoSMed.2008;5(8):e165.\nmethodologicallyunsound, orpoorlyreported?CurrOsteoporosRep. 41. FerroJM,Bacelar-NicolauH,RodriguesT,Bacelar-NicolauL,Canh\u00e3oP,\n2012;10(3):199\u2013207. CrassardI,etal.Riskscoretopredicttheoutcomeofpatientswithcerebral\nveinandduralsinusthrombosis.CerebrovascDis.2009;28(1):39\u201344.\n16. WassonJH,SoxHC,NeffRK,GoldmanL.Clinicalpredictionrules.Applications\nandmethodologicalstandards.NEnglJMed.1985;313(13):793\u20138. 42. WooJ,LeungJ,WongS,KwokT,LeeJ,LynnH.Developmentofasimple\n17. StiellI,WellsG.Methodologicstandardsforthedevelopmentofclinical scoringtoolintheprimarycaresettingforpredictionofrecurrentfallsin\ndecisionrulesinemergencymedicine.AnnEmergMed.1999;33(4):437\u201347. menandwomenaged65yearsandoverlivinginthecommunity.JClin\nNurs.2009;18(7):1038\u201348.\n18. GreenSM,SchrigerDL,YealyDM.Methodologicstandardsforinterpreting\nclinicaldecisionrulesinemergencymedicine:2014update.AnnEmerg 43. ScholzNN,B\u00e4slerKK,SaurPP,BurchardiHH,FelderSS.Outcomeprediction\nMed.2014;64(3):286\u201391. incriticalcare:physicians'prognosesvs.scoringsystems.EurJAnaesthesiol.\n2004;21(8):606\u201311.\n19. SteyerbergEW,VergouweY.Towards better clinicalpredictionmodels:\nseven steps fordevelopmentandan ABCDforvalidation.EurHeartJ. 44. KheterpalS,TremperKK,HeungM,RosenbergAL,EnglesbeM,ShanksAM,\n2014;35(29):1925\u201331. CampbellDA.Developmentandvalidationofanacutekidneyinjuryrisk\n20. AltmanDG,VergouweY,RoystonP,MoonsKG.Prognosisandprognostic indexforpatientsundergoinggeneralsurgeryresultsfromanationaldata\nresearch:validatingaprognosticmodel.BMJ.2009;338:b605. set.Anesthesiology.2009;110(3):505\u201315.\n21. MoonsKG,RoystonP,VergouweY,GrobbeeDE,AltmanDG.Prognosisand 45. PaceN,EberhartL,KrankeP.Quantifyingprognosiswithriskpredictions.Eur\nprognosticresearch:what,why,andhow?BMJ.2009;338:b375. JAnaesthesiol.2012;29(1):7\u201316.\n22. MoonsKG,AltmanDG,VergouweY,RoystonP.Prognosisandprognostic 46. SteyerbergEW,VickersAJ,CookNR,GerdsT,GonenM,ObuchowskiN,etal.\nresearch:applicationandimpactofprognosticmodelsinclinicalpractice. Assessingtheperformanceofpredictionmodels:aframeworkforsome\nBMJ.2009;338:b606. traditionalandnovelmeasures.Epidemiology.2010;21(1):128\u201338.\n23. MoonsKG,KengneAP,WoodwardM,RoystonP,VergouweY,AltmanDG, 47. McGinnT.Puttingmeaningintomeaningfuluse:aroadmaptosuccessful\nGrobbeeDE.Riskpredictionmodels:I.development,internalvalidation,and integrationofevidenceatthepointofcare.JMIRMedInform.2016;4(2):e16.\nassessingtheincrementalvalueofanew(bio)marker.Heart.2012;98(9):683\u201390. 48. BrehautJC,GrahamID,WoodTJ,TaljaardM,EaglesD,LottA,etal.\n24. MoonsKG,KengneAP,GrobbeeDE,RoystonP,VergouweY,AltmanDG, Measuringacceptabilityofclinicaldecisionrules:validationoftheOttawa\nWoodwardM.Riskpredictionmodels:II.Externalvalidation,model acceptabilityofdecisionrulesinstrument(OADRI)infourcountries.Med\nupdating,andimpactassessment.Heart.2012;98(9):691\u20138. DecisMak.2010;30(3):398\u2013408.\n25. RoystonP,MoonsKGM,AltmanDG,VergouweY.Prognosisandprognostic 49. SarasinFP,ReymondJM,GriffithJL,BeshanskyJR,SchifferliJA,UngerPF,et\nresearch:developingaprognosticmodel.BMJ.2009;338:b604. al.Impactoftheacutecardiacischemiatime-insensitivepredictive",
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page19of23\ninstrument(ACI-TIPI)onthespeedoftriagedecisionmakingforemergency 75. Labar\u00e8reJ,RenaudB,FineMJ.Howtoderiveandvalidateclinicalprediction\ndepartmentpatientspresentingwithchestpain:acontrolledclinicaltrial.J modelsforuseinintensivecaremedicine.IntensiveCareMed.2014;40(4):513\u201327.\nGenInternMed.1994;9(4):187\u201394. 76. GrobmanWA,StamilioDM.Methodsofclinicalprediction.AmJObstet\n50. StiellIG,McDowellI,NairRC,AetaH,GreenbergG,McKnightRD,AhujaJ. Gynecol.2006;194(3):888\u201394.\nUseofradiographyinacuteankleinjuries:physicians'attitudesandpractice. 77. vandenBoschJE,KalkmanCJ,VergouweY,VanKleiWA,BonselGJ,Grobbee\nCMAJ.1992;147(11):1671\u20138. DE,MoonsKG.Assessingtheapplicabilityofscoringsystemsforpredicting\n51. StiellIG,McKnightR,GreenbergGH,McDowellI,NairRC,WellsGA,etal. postoperativenauseaandvomiting.Anaesthesia.2005;60(4):323\u201331.\nImplementationoftheOttawaanklerules.JAMA.1994;271(11):827\u201332. 78. HilbeJ.Logisticregressionmodels.BocaRaton:Chapman&Hall/CRC;2009.\n52. AnisAH,StiellIG,StewartDG,LaupacisA.Cost-effectivenessanalysisofthe 79. MarshallRJ.Theuseofclassificationandregressiontreesinclinical\nOttawaanklerules.AnnEmergMed.1995;26(4):422\u20138. epidemiology.JClinEpidemiol.2001;54(6):603\u20139.\n53. GrahamID,StiellIG,LaupacisA,McAuleyL,HowellM,ClancyM,etal. 80. StiellIG,GreenbergGH,McKnightRD,NairRC,McDowellI,WorthingtonJR.\nAwarenessanduseoftheOttawaankleandkneerulesin 5countries: Astudytodevelopclinicaldecisionrulesfortheuseofradiographyin\ncanpublicationalonebeenough tochangepractice?AnnEmergMed. acuteankleinjuries.AnnEmergMed.1992;21(4):384\u201390.\n2001;37(3):259\u201366. 81. TopolEJ.High-performancemedicine:theconvergenceofhumanand\n54. DamenJA,HooftL,SchuitE,DebrayTP,CollinsGS,TzoulakiI,etal. artificialintelligence.NatMed.2019;25(1):44\u201356.\nPredictionmodelsforcardiovasculardiseaseriskinthegeneralpopulation: 82. VollmerS,MateenBA,BohnerG,Kir\u00e1lyFJ,GhaniR,JonssonP,etal.Machine\nsystematicreview.BMJ.2016;353:i2416. learningandAIresearchforpatientbenefit:20criticalquestionson\n55. ShariatSF,KarakiewiczPI,MargulisV,KattanMW.Inventoryofprostate transparency,replicability,ethicsandeffectiveness.CoRR.2018;abs/1812.10404.\ncancerpredictivetools.CurrOpinUrol.2008;18(3):279\u201396. 83. VergouweY,RoystonP,MoonsKG,AltmanDG.Developmentand\n56. PerelP,EdwardsP,WentzR,RobertsI.Systematicreviewofprognostic validationofapredictionmodelwithmissingpredictordata:apractical\nmodelsintraumaticbraininjury.BMCMedInformDecisMak.2006;6:38. approach.JClinEpidemiol.2010;63(2):205\u201314.\n57. WesslerBS,LaiYhL,KramerW,CangelosiM,RamanG,LutzJS,KentDM. 84. LittleRJA,RubinDB.Statisticalanalysiswithmissingdata.NewYork:Wiley;2002.\nClinicalpredictionmodelsforcardiovasculardisease:tuftspredictive 85. SterneJAC,WhiteIR,CarlinJB,SprattM,RoystonP,KenwardMG,etal.\nanalyticsandcomparativeeffectivenessclinicalpredictionmodeldatabase. Multipleimputationformissingdatainepidemiologicalandclinical\nCircCardiovascQualOutcomes.2015;8(4):368\u201375. research:potentialandpitfalls.BMJ.2009;338:b2393.\n58. GeersingGJ,BouwmeesterW,ZuithoffP,SpijkerR,LeeflangM,MoonsKG. 86. DondersART,vanderHeijdenGJMG,StijnenT,MoonsKGM.Review:a\nSearchfiltersforfindingprognosticanddiagnosticpredictionstudiesin gentleintroductiontoimputationofmissingvalues.JClinEpidemiol.\nMedlinetoenhancesystematicreviews.PLoSOne.2012;7(2):e32844. 2006;59(10):1087\u201391.\n59. MoonsKG,deGrootJA,BouwmeesterW,VergouweY,MallettS, 87. MoonsKGM,DondersRART,StijnenT,HarrellFE.Usingtheoutcomefor\nAltmanDG,etal. Criticalappraisalanddataextractionforsystematic imputationofmissingpredictorvalueswaspreferred.JClinEpidemiol.\nreviewsofpredictionmodellingstudies:theCHARMSchecklist.PLoS 2006;59(10):1092\u2013101.\nMed. 2014;11(10):e1001744. 88. JanssenKJM,DondersART,HarrellFE,VergouweY,ChenQ,GrobbeeDE,\n60. MoonsKM,WolffRF,RileyRD,WhitingPF,WestwoodM,CollinsGS,etal. MoonsKGM.Missingcovariatedatainmedicalresearch:toimputeisbetter\nPROBAST:atooltoassessriskofbiasandapplicabilityofpredictionmodel thantoignore.JClinEpidemiol.2010;63(7):721\u20137.\nstudies:explanationandelaboration.AnnInternMed.2019;170(1):W1\u2013W33. 89. PedersenAB,MikkelsenEM,Cronin-FentonD,KristensenNR,PhamTM,\n61. CollinsGS,MoonsKG.Comparingriskpredictionmodels.BMJ.2012;344:e3186. PedersenL,PetersenI.Missingdataandmultipleimputationinclinical\n62. DekkerFW,RamspekCL,vanDiepenM.Con:mostclinicalriskscoresare epidemiologicalresearch.ClinEpidemiol.2017;9:157\u201366.\nuseless.NephrolDialTransplant.2017;32(5):752\u20135. 90. vanderHeijdenGJMG,DondersAR,StijnenT,MoonsKGM.Imputationof\n63. MasconiK,MatshaT,ErasmusR,KengneA.Recalibrationinvalidation missingvaluesissuperiortocompletecaseanalysisandthemissing-\nstudiesofdiabetesriskpredictionmodels:asystematicreview.IntJStat indicatormethodinmultivariablediagnosticresearch:aclinicalexample.J\nMedRes.2015;4(4):347\u201369. ClinEpidemiol.2006;59(10):1102\u20139.\n64. BanJW,WallaceE,StevensR,PereraR.Whydoauthorsderivenew 91. RubinDB.Multipleimputationfornonresponseinsurveys.NewYork:Wiley;1987.\ncardiovascularclinicalpredictionrulesinthepresenceofexistingrules?A 92. vanBuurenS,Groothuis-OudshoornK.Mice:multivariateimputationby\nmixedmethodsstudy.PLoSOne.2017;12(6):e0179102. chainedequationsinR.JStatSoftw.2011;45(3):1\u201367.\n65. deSalisI,WhitingP,SterneJA,HayAD. Usingqualitativeresearchto 93. WhiteIR,RoystonP,WoodAM.Multipleimputationusingchained\ninformdevelopmentofadiagnosticalgorithmforUTIinchildren.Fam equations:issuesandguidanceforpractice.StatMed.2011;30(4):377\u201399.\nPract.2013;30(3):325\u201331. 94. CollinsLM,SchaferJL,KamCM.Acomparisonofinclusiveandrestrictivestrategies\n66. HaskinsR,OsmotherlyPG,SouthgateE,RivettDA.Australian inmodernmissingdataprocedures.PsycholMethods.2001;6(4):330\u201351.\nphysiotherapists'prioritiesforthedevelopmentofclinicalpredictionrules 95. GrahamJW.Missingdataanalysis:makingitworkintherealworld.Annu\nforlowbackpain:aqualitativestudy.Physiotherapy.2015;101(1):44\u20139. RevPsychol.2009;60:549\u201376.\n67. PeatG,RileyRD,CroftP,MorleyKI,KyzasPA,MoonsKG,etal.Improving 96. CarpenterJR,KenwardMG,WhiteIR.Sensitivityanalysisaftermultiple\nthetransparencyofprognosisresearch:theroleofreporting,datasharing, imputationundermissingatrandom:aweightingapproach.StatMethods\nregistration,andprotocols.PLoSMed.2014;11(7):e1001671. MedRes.2007;16(3):259\u201375.\n68. AltmanDG.Thetimehascometoregisterdiagnosticandprognostic 97. DemirtasH,SchaferJL.Ontheperformanceofrandom-coefficientpattern-\nresearch.ClinChem.2014;60(4):580\u20132. mixturemodelsfornon-ignorabledrop-out.StatMed.2003;22(16):2553\u201375.\n69. HanK,SongK,ChoiBW.Howtodevelop,validate,andcompareclinical 98. LeurentB,GomesM,FariaR,MorrisS,GrieveR,CarpenterJR.Sensitivity\npredictionmodelsinvolvingradiologicalparameters:studydesignand analysisfornot-at-randommissingdataintrial-basedcost-effectiveness\nstatisticalmethods.KoreanJRadiol.2016;17(3):339\u201350. analysis:atutorial.Pharmacoeconomics.2018;36(8):889\u2013901.\n70. LeeY-h,BangH,KimDJ.Howtoestablishclinicalpredictionmodels. 99. LeacyFP,FloydS,YatesTA,WhiteIR.Analysesofsensitivitytothemissing-\nEndocrinolMetab(Seoul).2016;31(1):38\u201344. at-randomassumptionusingmultipleimputationwithdeltaadjustment:\n71. BiesheuvelCJ,VergouweY,OudegaR,HoesAW,GrobbeeDE,MoonsKG. applicationtoatuberculosis/HIVprevalencesurveywithincompleteHIV-\nAdvantagesofthenestedcase-controldesignindiagnosticresearch.BMC statusdata.AmJEpidemiol.2017;185(4):304\u201315.\nMedResMethodol.2008;8:48. 100. H\u00e9raud-BousquetV,LarsenC,CarpenterJ,DesenclosJ-C,LeStratY.\n72. SandersonJ,ThompsonSG,WhiteIR,AspelundT,PennellsL.Derivationand Practicalconsiderationsforsensitivityanalysisaftermultipleimputation\nassessmentofriskpredictionmodelsusingcase-cohortdata.BMCMedRes appliedtoepidemiologicalstudieswithincompletedata.BMCMedRes\nMethodol.2013;13:113. Methodol.2012;12:73.\n73. NeeRJ,CoppietersMW.Interpretingresearchonclinicalpredictionrulesfor 101. CarpenterJR,KenwardMG.MARmethodsforquantitativedata.In:missing\nphysiotherapytreatments.ManTher.2011;16(2):105\u20138. datainrandomisedcontrolledtrials\u2014apracticalguide.Birmingham:\n74. HancockM,HerbertRD,MaherCG.Aguidetointerpretationofstudies NationalInstituteforHealthResearch;2008.\ninvestigatingsubgroupsofresponderstophysicaltherapyinterventions. 102. GoldsteinH,CarpenterJ,KenwardMG,LevinKA.Multilevelmodelswith\nPhysTher.2009;89(7):698\u2013704. multivariatemixedresponsetypes.StatModel.2009;9(3):173\u201397.",
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page20of23\n103. SchaferJL.Analysisofincompletemultivariatedata.London:Chapman 128. SteyerbergEW,UnoH,IoannidisJPA,vanCalsterB,UkaegbuC,DhingraT,\n&Hall; 1997. etal.Poorperformanceofclinicalpredictionmodels:theharmof\n104. DobsonA,DiggleP,HendersonR.Jointmodellingoflongitudinal commonlyappliedmethods.JClinEpidemiol.2018;98:133\u201343.\nmeasurementsandeventtimedata.Biostatistics.2000;1(4):465\u201380. 129. RoystonP,SauerbreiW.Multivariablemodel-building:apragmaticapproach\n105. RizopoulosD.Jointmodelsforlongitudinalandtime-to-eventdatawith toregressionanalysisbasedonfractionalpolynomialsformodelling\napplicationsinR.NewYork:ChapmanandHall/CRC;2012. continuousvariables.Chichester:Wiley;2009.\n106. MarshallA,AltmanDG,HolderRL,RoystonP.Combiningestimatesof 130. HarrellFEJ,LeeKL,PollockBG.Regressionmodelsinclinicalstudies:\ninterestinprognosticmodellingstudiesaftermultipleimputation:current determiningrelationshipsbetweenpredictorsandresponse.JNatlCancer\npracticeandguidelines.BMCMedResMethodol.2009;9:57. Inst.1988;80(15):1198\u2013202.\n107. MarshallA,AltmanDG,HolderRL.Comparisonofimputationmethodsfor 131. RoystonP,AltmanDG.Regressionusingfractionalpolynomialsof\nhandlingmissingcovariatedatawhenfittingaCoxproportionalhazards continuouscovariates:parsimoniousparametricmodelling.JRStatSocSer\nmodel:aresamplingstudy.BMCMedResMethodol.2010;10:112. CApplStat.1994;43(3):429\u201367.\n108. KappenTH,vanKleiWA,vanWolfswinkelL,KalkmanCJ,VergouweY, 132. Ambler G,SeamanS,OmarRZ.Anevaluationofpenalisedsurvival\nMoonsKGM.Evaluatingtheimpactofpredictionmodels:lessonslearned, methodsfordevelopingprognosticmodelswithrareevents.StatMed.\nchallenges,andrecommendations.BMCDiagnPrognRes.2018;2:11. 2012;31(11\u201312):1150\u201361.\n109. KappenTH,VergouweY,vanKleiWA,vanWolfswinkelL,KalkmanCJ, 133. LeCessieS,VanHouwelingenJC.Ridgeestimatorsinlogisticregression.JR\nMoonsKGM.Adaptationofclinicalpredictionmodelsforapplicationin StatSocSerCApplStat.1992;41(1):191\u2013201.\nlocalsettings.MedDecisMak.2012;32(3):E1\u2013E10. 134. TibshiraniR.Regressionshrinkageandselectionviathelasso.JRStatSoc\n110. JanssenKJM,VergouweY,DondersART,HarrellFE,ChenQ,GrobbeeDE, SeriesBStatMethodol.1996;58(1):267\u201388.\nMoonsKGM.Dealingwithmissingpredictorvalueswhenapplyingclinical 135. HosmerDW,JovanovicB,LemeshowS.Bestsubsetslogisticregression.\npredictionmodels.ClinChem.2009;55(5):994\u20131001. Biometrics.1989;45(4):1265\u201370.\n111. MasconiKL,MatshaTE,ErasmusRT,KengneAP.Effectsofdifferentmissing 136. MantelN.Whystepdownproceduresinvariableselection.\ndataimputationtechniquesontheperformanceofundiagnoseddiabetes Technometrics.1970;12(3):621\u20135.\nriskpredictionmodelsinamixed-ancestrypopulationofSouthAfrica.PLoS 137. MoonsKG,BiesheuvelCJ,GrobbeeDE.Testresearchversusdiagnostic\nOne.2015;10(9):e0139210. research.ClinChem.2004;50(3):473\u20136.\n112. SunGW,ShookTL,KayGL.Inappropriateuseofbivariableanalysistoscreen 138. SteyerbergEW,EijkemansMJC,HabbemaJDF.Stepwiseselectioninsmall\nriskfactorsforuseinmultivariableanalysis.JClinEpidemiol.1996;49(8):907\u201316. datasets:asimulationstudyofbiasinlogisticregressionanalysis.JClin\n113. SteyerbergEW,EijkemansMJC,HarrellFE,HabbemaJDF.Prognostic Epidemiol.1999;52(10):935\u201342.\nmodelingwithlogisticregressionanalysis:insearchofasensiblestrategyin 139. SteyerbergEW,SchemperM,HarrellFE.Logisticregressionmodelingand\nsmalldatasets.MedDecisMak.2001;21(1):45\u201356. thenumberofeventspervariable:selectionbiasdominates.JClin\n114. HarrellFEJ,LeeKL,MarkDB.Multivariableprognosticmodels:issuesin Epidemiol.2011;64(12):1464\u20135.\ndevelopingmodels,evaluatingassumptionsandadequacy,andmeasuring 140. WhittleR,PeatG,BelcherJ,CollinsGS,RileyRD.Measurementerrorandtiming\nandreducingerrors.StatMed.1996;15(4):361\u201387. ofpredictorvaluesformultivariableriskpredictionmodelsarepoorlyreported.\n115. ShmueliG.Toexplainortopredict?StatSci.2010;25(3):289\u2013310. JClinEpidemiol.2018.https://doi.org/10.1016/j.jclinepi.2018.05.008.\n116. PavlouM,AmblerG,SeamanSR,GuttmannO,ElliottP,KingM,OmarRZ. 141. LuijkenK,GroenwoldRHH,vanCalsterB,SteyerbergEW,vanSmedenM.\nHowtodevelopamoreaccurateriskpredictionmodelwhentherearefew Impactofpredictormeasurementheterogeneityacrosssettingson\nevents.BMJ.2015;351:h3868. performanceofpredictionmodels:ameasurementerrorperspective.arXiv:\n117. HeinzeG,DunklerD. Fivemythsaboutvariableselection.TransplInt. 180610495[statME].2018:arXiv:1806.10495.\n2017;30(1):6\u201310. 142. WorsterA,CarpenterC.Incorporationbiasinstudiesofdiagnostictests:\n118. PeduzziP,ConcatoJ,KemperE,HolfordTR,FeinsteinAR.Asimulationstudy howtoavoidbeingbiasedaboutbias.CJEM.2008;10(2):174\u20135.\nofthenumberofeventspervariableinlogisticregressionanalysis.JClin 143. MoonsKG,GrobbeeDE.When shouldweremainblindandwhen\nEpidemiol.1996;49(12):1373\u20139. shouldoureyes remainopenindiagnosticstudies?JClinEpidemiol.\n119. VittinghoffE,McCullochCE.Relaxingtheruleofteneventspervariablein 2002;55(7):633\u20136.\nlogisticandcoxregression.AmJEpidemiol.2007;165(6):710\u20138. 144. WangLE,ShawPA,MathelierHM,KimmelSE,FrenchB.Evaluatingrisk-\n120. Courvoisier DS, Combescure C, Agoritsas T, Gayet-Ageron A, Perneger predictionmodelsusingdatafromelectronichealthrecords.AnnApplStat.\nTV. Performanceof logistic regression modeling: beyond thenumber 2016;10(1):286\u2013304.\nof events per variable, therole of data structure. J Clin Epidemiol. 145. vanDoornS,BrakenhoffTB,MoonsKGM,RuttenFH,HoesAW,\n2011;64(9):993\u20131000. GroenwoldRHH,GeersingGJ.Theeffectsofmisclassificationinroutine\n121. van Smeden M, deGroot JAH, Moons KGM, Collins GS, Altman DG, healthcaredatabases ontheaccuracyofprognosticpredictionmodels:\nEijkemans MJC, Reitsma JB. No rationale for 1 variableper 10 events acasestudy oftheCHA2DS2-VAScscorein atrialfibrillation.BMC\ncriterion for binary logistic regression analysis. BMC Med Res DiagnPrognRes.2017;1:18.\nMethodol. 2016;16:163. 146. BleekerSE,MollHA,SteyerbergEW,DondersAR,Derksen-LubsenG,\n122. vanSmedenM,MoonsKGM,deGrootJAH,CollinsGS,AltmanDG, GrobbeeDE,MoonsKG.Externalvalidationisnecessaryinprediction\nEijkemansMJC,ReitsmaJB.Samplesizeforbinarylogisticprediction research:aclinicalexample.JClinEpidemiol.2003;56(9):826\u201332.\nmodels:beyondeventspervariablecriteria.StatMethodsMedRes.2018. 147. JusticeAC,CovinskyKE,BerlinJA.Assessingthegeneralizabilityof\nhttps://doi.org/10.1177/0962280218784726. prognosticinformation.AnnInternMed.1999;130(6):515\u201324.\n123. OgundimuEO,AltmanDG,CollinsGS.Adequatesamplesizefordeveloping 148. TollDB,JanssenKJ,VergouweY,MoonsKG.Validation,updatingandimpact\npredictionmodelsisnotsimplyrelatedtoeventspervariable.JClin ofclinicalpredictionrules:areview.JClinEpidemiol.2008;61(11):1085\u201394.\nEpidemiol.2016;76:175\u201382. 149. SteyerbergEW,HarrellFEJr,BorsboomGJ,EijkemansMJ,VergouweY,\n124. BattleCE,HutchingsH,EvansPA.Expertopinionoftheriskfactorsfor HabbemaJD.Internalvalidationofpredictivemodels:efficiencyofsome\nmorbidityandmortalityinbluntchestwalltrauma:resultsofanational proceduresforlogisticregressionanalysis.JClinEpidemiol.2001;54(8):774\u201381.\npostalquestionnairesurveyofemergencydepartmentsintheUnited 150. SteyerbergEW.Validationinpredictionresearch:thewastebydata-splitting.\nKingdom.Injury.2013;44(1):56\u20139. JClinEpidemiol.2018.https://doi.org/10.1016/j.jclinepi.2018.07.010.\n125. SauerbreiW,RoystonP,BinderH.Selectionofimportantvariablesand 151. EfronB,TibshiraniR.Anintroductiontothebootstrap.BocaRaton:\ndeterminationoffunctionalformforcontinuouspredictorsinmultivariable Chapman&Hall/CRC;1993.\nmodelbuilding.StatMed.2007;26(30):5512\u201328. 152. GerdsTA,CaiT,SchumacherM.Theperformanceofriskpredictionmodels.\n126. RoystonP,AltmanDG,SauerbreiW.Dichotomizingcontinuouspredictorsin BiomJ.2008;50(4):457\u201379.\nmultipleregression:abadidea.StatMed.2006;25(1):127\u201341. 153. AustinPC,SteyerbergEW.Graphicalassessmentofinternalandexternal\n127. CollinsGS,OgundimuEO,CookJA,ManachYL,AltmanDG.Quantifyingthe calibrationoflogisticregressionmodelsbyusingloesssmoothers.StatMed.\nimpactofdifferentapproachesforhandlingcontinuouspredictorsonthe 2014;33(3):517\u201335.\nperformanceofaprognosticmodel.StatMed.2016;35(23):4124\u201335. 154. HosmerDW,LemeshowS.Appliedlogisticregression.NewYork:Wiley;2000.",
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page21of23\n155. VanCalsterB,NieboerD,VergouweY,DeCockB,PencinaMJ,Steyerberg 181. IvanovJ,TuJV,NaylorCD.Ready-made,recalibrated,orremodeled?Issues\nEW.Acalibrationhierarchyforriskmodelswasdefined:fromutopiato intheuseofriskindexesforassessingmortalityaftercoronaryarterybypass\nempiricaldata.JClinEpidemiol.2016;74:167\u201376. graftsurgery.Circulation.1999;99(16):2098\u2013104.\n156. PencinaMJ,D'AgostinoRBS.Evaluatingdiscriminationofriskprediction 182. SteyerbergEW,BorsboomGJ,vanHouwelingen HC,EijkemansMJ,\nmodels:theCstatistic.JAMA.2015;314(10):1063\u20134. HabbemaJD.Validationandupdatingofpredictivelogisticregression\n157. HanleyJA,McNeilBJ.Themeaninganduseoftheareaunderareceiver models:astudyonsamplesizeandshrinkage.StatMed.2004;23(16):\noperatingcharacteristic(ROC)curve.Radiology.1982;143(1):29\u201336. 2567\u201386.\n158. BaronJA,SorensenHT.Clinicalepidemiology.In:OlsenJ,SaracciR, 183. DeLongER,DeLongDM,Clarke-PearsonDL.Comparingtheareasunder\nTrichopoulosD,editors.Teachingepidemiology:aguideforteachersin twoormorecorrelatedreceiveroperatingcharacteristiccurves:a\nepidemiology,publichealthandclinicalmedicine.NewYork:Oxford nonparametricapproach.Biometrics.1988;44(3):837\u201345.\nUniversityPress;2010.p.411\u201328. 184. DemlerOV,PencinaMJ,D\u2019AgostinoRBS.MisuseofDeLongtesttocompare\n159. VanCalsterB,VickersAJ.Calibrationofriskpredictionmodels:impacton AUCsfornestedmodels.StatMed.2012;31(23):2577\u201387.\ndecision-analyticperformance.MedDecisMak.2014;35(2):162\u20139. 185. PencinaMJ,D'AgostinoRBSr,D'AgostinoRBJr,VasanRS.Evaluatingthe\n160. MeurerWJ,TollesJ.Logisticregressiondiagnostics:understandinghowwell addedpredictiveabilityofanewmarker:fromareaundertheROCcurveto\namodelpredictsoutcomes.JAMA.2017;317(10):1068\u20139. reclassificationandbeyond.StatMed.2008;27(2):157\u201372.\n161. ParikhR,MathaiA,Parikh S,ChandraSekharG,ThomasR. 186. VanCalsterB,VickersAJ,PencinaMJ,BakerSG,TimmermanD,\nUnderstandingandusingsensitivity,specificityandpredictivevalues. SteyerbergEW.Evaluationofmarkersandriskpredictionmodels:\nIndianJOphthalmol.2008;56(1):45\u201350. overviewofrelationshipsbetweenNRIanddecision-analyticmeasures.\n162. S\u00f8reideK.Receiver-operatingcharacteristiccurveanalysisindiagnostic, MedDecisMak.2013;33(4):490\u2013501.\nprognosticandpredictivebiomarkerresearch.JClinPathol.2009;62(1):1\u20135. 187. LeeningMJ,SteyerbergEW,VanCalsterB,D\u2019AgostinoRBSr,PencinaMJ.\n163. EbellMH,LocatelliI,SennN.Anovelapproachtothedeterminationof Netreclassificationimprovementandintegrateddiscrimination\nclinicaldecisionthresholds.BMJEvidBasedMed.2015;20(2):41\u20137. improvementrequirecalibratedmodels:relevancefromamarkerand\n164. VickersAJ,ElkinEB.Decisioncurveanalysis:anovelmethodforevaluating modelperspective.StatMed.2014;33(19):3415\u20138.\npredictionmodels.MedDecisMak.2006;26(6):565\u201374. 188. LeeningMJ,VedderMM,WittemanJC,PencinaMJ, SteyerbergEW.Net\n165. BakerSG,CookNR,VickersA,KramerBS.Usingrelativeutilitycurvesto reclassificationimprovement:computation,interpretation,and\nevaluateriskprediction.JRStatSocSerAStatSoc.2009;172(4):729\u201348. controversies:aliteraturereviewandclinician'sguide. AnnInternMed.\n166. VickersAJ,VanCalsterB,SteyerbergEW.Netbenefitapproaches tothe 2014;160(2):122\u201331.\nevaluationofpredictionmodels,molecularmarkers,anddiagnostic 189. PepeMS,FanJ,FengZ,GerdsT,HildenJ.Thenetreclassificationindex\ntests.BMJ.2016;352:i6. (NRI):amisleadingmeasureofpredictionimprovementevenwith\n167. FeldsteinDA,HessR,McGinnT,MishurisRG,McCullaghL,SmithPD,etal. independenttestdatasets.StatBiosci.2015;7(2):282\u201395.\nDesignandimplementationofelectronichealthrecordintegratedclinical 190. BurchPM,GlaabWE,HolderDJ,PhillipsJA,SauerJM,WalkerEG.Net\npredictionrules(iCPR):arandomizedtrialindiverseprimarycaresettings. reclassificationindexandintegrateddiscriminationindexarenot\nImplementSci.2017;12(1):37. appropriatefortestingwhetherabiomarkerimprovespredictive\n168. VanBelleV,VanCalsterB.Visualizingriskpredictionmodels.PLoSOne. performance.ToxicolSci.2017;156(1):11\u20133.\n2015;10(7):e0132614. 191. HildenJ,GerdsTA.Anoteontheevaluationofnovelbiomarkers:donot\n169. SullivanLM,MassaroJM,D'AgostinoRB.Presentationofmultivariate relyonintegrateddiscriminationimprovementandnetreclassification\ndataforclinicaluse:theFraminghamstudyriskscorefunctions.Stat index.StatMed.2014;33(19):3405\u201314.\nMed. 2004;23(10):1631\u201360. 192. AntoliniL,TassistroE,ValsecchiMG,BernasconiDP.Graphical\n170. ColeTJ.AlgorithmAS281:scalingandroundingregressioncoefficientsto representationsandsummaryindicatorstoassesstheperformanceofrisk\nintegers.JRStatSocSerCApplStat.1993;42(1):261\u20138. predictors.BiomJ.2018.https://doi.org/10.1002/bimj.201700186.\n171. MaguireJL,KulikDM,Laupacis A,KuppermannN,UlerykEM,ParkinPC. 193. Siontis GC,TzoulakiI,SiontisKC,Ioannidis JP.Comparisonsof\nClinicalpredictionrulesforchildren:asystematicreview.Pediatrics. establishedriskpredictionmodels forcardiovasculardisease:systematic\n2011;128(3):e666\u2013e77. review.BMJ. 2012;344:e3318.\n172. KeoghC,WallaceE,O'BrienKK,GalvinR,SmithSM,LewisC,etal. 194. CookNR.Quantifyingtheaddedvalueofnewbiomarkers:howandhow\nDevelopinganinternationalregisterofclinicalpredictionrulesforusein not.BMCDiagnPrognRes.2018;2:14.\nprimarycare:adescriptiveanalysis.AnnFamMed.2014;12(4):359\u201366. 195. FerrantediRuffanoL,HydeCJ,McCafferyKJ,BossuytPMM,DeeksJJ.\n173. StiellIG,GreenbergGH,WellsGA,McDowellI,CwinnAA,SmithNA,etal. Assessingthevalueofdiagnostictests:aframeworkfordesigningand\nProspectivevalidationofadecisionrulefortheuseofradiographyinacute evaluatingtrials.BMJ.2012;344:e686.\nkneeinjuries.JAMA.1996;275(8):611\u20135. 196. WhiteH.Theory-basedimpactevaluation:principlesandpractice.JDev\n174. Vergouwe Y, Steyerberg EW, Eijkemans MJC, Habbema JDF. Effect.2009;1(3):271\u201384.\nSubstantial effective sample sizes wererequired for external validation 197. MooreGF,AudreyS,BarkerM,BondL,BonellC,HardemanW,etal.Process\nstudies of predictive logistic regression models. J Clin Epidemiol. evaluationofcomplexinterventions:MedicalResearchCouncilguidance.\n2005;58(5):475\u201383. BMJ.2015;350:h1258.\n175. CollinsGS,OgundimuEO,AltmanDG.Samplesizeconsiderationsforthe 198. DowdingD,LichtnerV,ClossSJ.UsingtheMRCframeworkforcomplex\nexternalvalidationofamultivariableprognosticmodel:aresamplingstudy. interventionstodevelopclinicaldecisionsupport:acasestudy.StudHealth\nStatMed.2016;35(2):214\u201326. TechnolInform.2017;235:544-8.\n176. VergouweY,MoonsKGM,SteyerbergEW.Externalvalidityofriskmodels: 199. NobleD,MathurR,DentT,MeadsC,GreenhalghT.Riskmodelsandscores\nuseofbenchmarkvaluestodisentangleacase-mixeffectfromincorrect fortype2diabetes:systematicreview.BMJ.2011;343:d7163.\ncoefficients.AmJEpidemiol.2010;172(8):971\u201380. 200. BrownB,Cheraghi-SohiS,JakiT,SuT-L,BuchanI,SperrinM.Understanding\n177. vanKlaverenD,G\u00f6nenM,SteyerbergEW,VergouweY.Anewconcordance clinicalpredictionmodelsas\u2018innovations\u2019:amixedmethodsstudyinUK\nmeasureforriskpredictionmodelsinexternalvalidationsettings.StatMed. familypractice.BMCMedInformDecisMak.2016;16:106.\n2016;35(23):4136\u201352. 201. CraigP,DieppeP,MacintyreS,MichieS,NazarethI,PetticrewM.\n178. BanJ-W,StevensR,PereraR.Predictorsforindependentexternalvalidation Developingandevaluatingcomplexinterventions:thenewMedical\nofcardiovascularriskclinicalpredictionrules:coxproportionalhazards ResearchCouncilguidance.BMJ.2008;337:a1655.\nregressionanalyses.BMCDiagnPrognRes.2018;2:3. 202. LeeTH.Evaluatingdecisionaids.JGenInternMed.1990;5(6):528\u20139.\n179. SiontisGCM,TzoulakiI,CastaldiPJ,IoannidisJPA.Externalvalidationofnew 203. KappenTH,VergouweY,vanWolfswinkelL,KalkmanCJ,MoonsKG,vanKlei\nriskpredictionmodelsisinfrequentandrevealsworseprognostic WA.Impactofaddingtherapeuticrecommendationstoriskassessments\ndiscrimination.JClinEpidemiol.2015;68(1):25\u201334. fromapredictionmodelforpostoperativenauseaandvomiting.BrJ\n180. JanssenKJM,MoonsKGM,KalkmanCJ,GrobbeeDE,VergouweY.Updating Anaesth.2015;114(2):252\u201360.\nmethodsimprovedtheperformanceofaclinicalpredictionmodelinnew 204. MichieS,JohnstonM.Changingclinicalbehaviourbymakingguidelines\npatients.JClinEpidemiol.2008;61(1):76\u201386. specific.BMJ.2004;328(7435):343\u20135.",
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page22of23\n205. WallaceE,UijenMJM,ClyneB,ZarabzadehA,KeoghC,GalvinR,etal. 228. ReillyBM,EvansAT,SchaiderJJ,WangY.Triageofpatientswithchestpain\nImpactanalysisstudiesofclinicalpredictionrulesrelevanttoprimarycare:a intheemergencydepartment:acomparativestudyofphysicians'decisions.\nsystematicreview.BMJOpen.2016;6(3):e009957. AmJMed.2002;112(2):95\u2013103.\n206. SandersSL,RathboneJ,BellKJL,GlasziouPP,DoustJA.Systematicreviewof 229. BroekhuizenBD,SachsA,JanssenK,GeersingGJ,MoonsK,HoesA,Verheij\ntheeffectsofcareprovidedwithandwithoutdiagnosticclinicalprediction T.Doesadecisionaidhelpphysicianstodetectchronicobstructive\nrules.BMCDiagnPrognRes.2017;1:13. pulmonarydisease?BrJGenPract.2011;61(591):e674\u2013e79.\n207. KappenT,PeelenLM.Predictionmodels:therighttoolfortheright 230. SchrigerDL,NewmanDH.Medicaldecisionmaking:let'snotforgetthe\nproblem.CurrOpinAnesthesiol.2016;29(6):717\u201326. physician.AnnEmergMed.2012;59(3):219\u201320.\n208. CampbellMK,ElbourneDR,AltmanDG.CONSORTstatement:extensionto 231. FinnertyN,RodriguezR,CarpenterC,SunB,TheyyunniN,OhleR,etal.\nclusterrandomisedtrials.BMJ.2004;328(7441):702\u20138. Clinicaldecisionrulesfordiagnosticimagingintheemergencydepartment:\n209. HemmingK,HainesTP,ChiltonPJ, GirlingAJ, LilfordRJ. Thestepped aresearchagenda.AcadEmergMed.2015;22(12):1406\u201316.\nwedgeclusterrandomisedtrial:rationale,design,analysis,and 232. SandersS,DoustJ, GlasziouP.Asystematicreviewofstudies\nreporting.BMJ. 2015;350:h391. comparingdiagnosticclinical predictionruleswithclinicaljudgment.\n210. PoldervaartJM,ReitsmaJB,KoffijbergH,BackusBE,SixAJ,DoevendansPA, PLoSOne.2015;10(6):e0128233.\nHoesAW.TheimpactoftheHEARTriskscoreintheearlyassessmentof 233. CowleyLE,FarewellDM,KempAM.Potentialimpactofthevalidated\npatientswithacutechestpain:designofasteppedwedge,cluster predictingabusiveheadtrauma(PredAHT)clinicalpredictiontool:aclinical\nrandomisedtrial.BMCCardiovascDisord.2013;13:77. vignettestudy.ChildAbuseNegl.2018;86:184\u201396.\n211. HayesRJ,MoultonLH.Clusterrandomisedtrials.BocaRaton:CRCPress;2017. 234. PetrouS,GrayA.Economicevaluationusingdecisionanalyticalmodelling:\n212. CampbellMK,ElbourneDR,AltmanDG.CONSORTgroup.CONSORT design,conduct,analysis,andreporting.BMJ.2011;342:d1766.\nstatement:extensiontoclusterrandomisedtrials.BMJ.2004;328(7441): 235. GrimshawJ,ShirranL,ThomasR,MowattG,FraserC,BeroL,etal.Changing\n702\u20138. providerbehavior:anoverviewofsystematicreviewsofinterventions.Med\n213. RutterfordC,CopasA,EldridgeS.Methodsforsamplesizedeterminationin Care.2001;39(8Suppl2):II2\u2013II45.\nclusterrandomizedtrials.IntJEpidemiol.2015;44(3):1051\u201367. 236. StiellIG,BennettC.Implementationofclinicaldecisionrulesinthe\n214. HemmingK,EldridgeS,ForbesG,WeijerC,TaljaardM.Howtodesign emergencydepartment.AcadEmergMed.2007;14(11):955\u20139.\nefficientclusterrandomisedtrials.BMJ.2017;358:j3064. 237. CameronC,NaylorCD.NoimpactfromactivedisseminationoftheOttawa\n215. SchaafsmaJD,vanderGraafY,RinkelGJ,BuskensE.Decisionanalysisto anklerules:furtherevidenceoftheneedforlocalimplementationof\ncompletediagnosticresearchbyclosingthegapbetweentest practiceguidelines.CMAJ.1999;160(8):1165\u20138.\ncharacteristicsandcost-effectiveness.JClinEpidemiol.2009;62(12):1248\u201352. 238. DavisDA,Taylor-VaiseyA.Translatingguidelinesintopractice.A\n216. KoffijbergH,vanZaaneB,MoonsKG.Fromaccuracytopatientoutcome systematicreviewoftheoreticconcepts,practicalexperienceand\nandcost-effectivenessevaluationsofdiagnostictestsandbiomarkers:an researchevidenceintheadoptionofclinicalpracticeguidelines.CMAJ.\nexemplarymodellingstudy.BMCMedResMethodol.2013;13:12. 1997;157(4):408\u201316.\n217. SiontisKC,SiontisGC,Contopoulos-IoannidisDG,IoannidisJP.Replyto 239. KatzMH.Integratingpredictionrulesintoclinicalworkflow.JAMAIntern\nletterbyFerrantediRuffanoetal.:patientoutcomesinrandomized Med2013;173(17):1591\u201391.\ncomparisonsofdiagnostictestsarestilltheultimatejudge.JClinEpidemiol. 240. BoutisK,ConstantineE,SchuhS,PecaricM,StephensD,NarayananUG.\n2016;69:267\u20138. Pediatricemergencyphysicianopinionsonankleradiographclinical\n218. MoherD,HopewellS,SchulzKF,MontoriV,G\u00f8tzschePC,DevereauxPJ,et decisionrules.AcadEmergMed.2010;17(7):709\u201317.\nal.CONSORT2010explanationandelaboration:updatedguidelinesfor 241. PluddemannA,WallaceE,BankheadC,KeoghC,VanderWindtD,\nreportingparallelgrouprandomisedtrials.BMJ.2010;340:c869. LassersonD,etal.Clinicalpredictionrulesinpractice:reviewofclinical\n219. ReillyBM,EvansAT,Schaider JJ, DasK,CalvinJE,MoranLA,etal. guidelinesandsurveyofGPs.BrJGenPract.2014;64(621):e233\u2013e42.\nImpactofaclinicaldecisionruleonhospitaltriageofpatientswith 242. KappenTH,vanLoonK,KappenMA,vanWolfswinkelL,VergouweY,van\nsuspectedacutecardiacischemiain theemergencydepartment.JAMA. KleiWA,etal.Barriersandfacilitatorsperceivedbyphysicianswhenusing\n2002;288(3):342\u201350. predictionmodelsinpractice.JClinEpidemiol.2016;70:136\u201345.\n220. CowleyLE,MaguireS,FarewellDM,Quinn-ScogginsHD,FlynnMO,Kemp 243. KeoghC,FaheyT.Clinicalpredictionrulesinprimarycare:whatcanbe\nAM.Acceptabilityofthepredictingabusiveheadtrauma(PredAHT)clinical donetomaximisetheirimplementation?ClinEvid.2010.https://core.ac.uk/\npredictiontool:aqualitativestudywithchildprotectionprofessionals.Child download/pdf/60774649.pdf.Accessed12June2018.\nAbuseNegl.2018;81:192\u2013205. 244. RunyonMS,RichmanPB,KlineJA.Emergencymedicinepractitioner\n221. BallardDW,RauchwergerAS,ReedME,VinsonDR,MarkDG,OffermanSR,et knowledgeanduseofdecisionrulesfortheevaluationofpatientswith\nal.Emergencyphysicians'knowledgeandattitudesofclinicaldecision suspectedpulmonaryembolism:variationsbypracticesettingandtraining\nsupportintheelectronichealthrecord:asurvey-basedstudy.AcadEmerg level.AcadEmergMed.2007;14(1):53\u20137.\nMed.2013;20(4):352\u201360. 245. PearsonSD,GoldmanL,GarciaTB,CookEF,LeeTH.Physicianresponsetoa\n222. JohnsonEL,HollenLI,KempAM,MaguireS.Exploringtheacceptabilityofa predictionruleforthetriageofemergencydepartmentpatientswithchest\nclinicaldecisionruletoidentifypaediatricburnsduetochildabuseor pain.JGenInternMed.1994;9(5):241\u20137.\nneglect.EmergMedJ.2016;33(7):465\u201370. 246. BrehautJC,StiellIG,VisentinL,GrahamID.Clinicaldecisionrules\"inthereal\n223. MullenS,Quinn-ScogginsHD,NuttallD,KempAM.Qualitativeanalysisof world\":howawidelydisseminatedruleisusedineverydaypractice.Acad\nclinicianexperienceinutilisingtheBuRNtool(burnsriskassessmentfor EmergMed.2005;12(10):948\u201356.\nneglectorabusetool)inclinicalpractice.Burns.2018;44(7):1759\u201366. 247. BrehautJC,StiellIG,GrahamID.Willanewclinicaldecisionrulebewidely\n224. HaskinsR,OsmotherlyPG,SouthgateE,RivettDA.Physiotherapists' used?ThecaseoftheCanadianC-spinerule.AcadEmergMed.2006;13(4):\nknowledge,attitudesandpracticesregardingclinicalpredictionrulesfor 413\u201320.\nlowbackpain.ManTher.2014;19(2):142\u201351. 248. GrahamID,StiellIG,LaupacisA,O'ConnorAM,WellsGA.Emergency\n225. KellyJ,SterlingM,RebbeckT,BandongAN,LeaverA,MackeyM,RitchieC. physicians'attitudestowardanduseofclinicaldecisionrulesfor\nHealthpractitioners'perceptionsofadoptingclinicalpredictionrulesinthe radiography.AcadEmergMed.1998;5(2):134\u201340.\nmanagementofmusculoskeletalpain:aqualitativestudyinAustralia.BMJ 249. EichlerK,ZollerM,TschudiP,SteurerJ.Barrierstoapplycardiovascular\nOpen.2017;7(8):e015916. predictionrulesinprimarycare:apostalsurvey.BMCFamPract.2007;8:1.\n226. AtabakiSM,HoyleJDJ,SchunkJE,MonroeDJ,AlpernER,QuayleKS,etal. 250. BeutelBG,TrehanSK,ShalvoyRM,MelloMJ.TheOttawakneerule:\nComparisonofpredictionrulesandcliniciansuspicionforidentifying examininguseinanacademicemergencydepartment.WestJEmergMed.\nchildrenwithclinicallyimportantbraininjuriesafterbluntheadtrauma. 2012;13(4):366\u201372.\nAcadEmergMed.2016;23(5):566\u201375. 251. SheehanB,NigrovicLE,DayanPS,KuppermannN,BallardDW,\n227. MahajanP,KuppermannN,TunikM,YenK,AtabakiSM,LeeLK,etal. AlessandriniE,etal.Informingthedesignofclinicaldecisionsupport\nComparisonofcliniciansuspicionversusaclinicalpredictionrulein servicesforevaluationofchildrenwithminorbluntheadtraumainthe\nidentifyingchildrenatriskforintra-abdominalinjuriesafterblunttorso emergencydepartment:asociotechnicalanalysis.JBiomedInform.\ntrauma.AcadEmergMed.2015;22(9):1034\u201341. 2013;46(5):905\u201313.",
        "Cowleyetal.DiagnosticandPrognosticResearch (2019) 3:16 Page23of23\n252. vanderSteenJT,AlbersG,Licht-StrunkE,MullerMT,RibbeMW.Avalidated\nriskscoretoestimatemortalityriskinpatientswithdementiaand\npneumonia:barrierstoclinicalimpact.IntPsychogeriatr.2011;23(1):31\u201343.\n253. SandersS.Clinicalpredictionrulesforassistingdiagnosis(doctoralthesis).\nAustralia:FacultyofHeathSciences&Medicine,BondUniversity;2015.\n254. CabanaMD,RandCS,PoweNR,WuAW,WilsonMH,AbboudPA,RubinHR.\nWhydon'tphysiciansfollowclinicalpracticeguidelines?Aframeworkfor\nimprovement.JAMA.1999;282(15):1458\u201365."
    ]
}