{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cdafe36-c50b-4ac6-8514-8903a04f46c9",
   "metadata": {},
   "source": [
    "# Demo QA session\n",
    "\n",
    "This notebook demonstrates a Question-answering session using a set of queries that will be answered using an article from a source directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e558e78f-0bdf-472c-bf78-c66bc414af97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\junio\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\PyPDF2\\__init__.py:21: DeprecationWarning: PyPDF2 is deprecated. Please move to the pypdf library instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "REPO_ROOT = \"..\\\\\" # enter path too the rapidreview-copilot repository\n",
    "\n",
    "import sys\n",
    "sys.path.append(REPO_ROOT)\n",
    "import os\n",
    "from rrc.text_extraction import PDFExtractor\n",
    "from rrc.run_session import RapidReviewSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474f0a7c-2f2a-4ee2-92f9-4cc2b5f4f316",
   "metadata": {},
   "source": [
    "## Question-answering\n",
    "\n",
    "This section demonstrates a question answering using `RapidReviewSession`. *Add more description here on what RapidReviewSession does, specifically inputs needed for the class and the `run_query` method of the class, as well as the outputs expected.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21620caa-99d8-4f81-836b-e62105d887bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever MAX SEQ LENGTH: 1000000000000000019884624838656\n",
      "QA model MAX SEQ LENGTH (Input limit): 512\n"
     ]
    }
   ],
   "source": [
    "# init RapidReviewSession\n",
    "sess = RapidReviewSession(\"./articles/\", \n",
    "                          (\"facebook/dpr-question_encoder-single-nq-base\", \"facebook/dpr-ctx_encoder-single-nq-base\"),\n",
    "                          \"MBZUAI/LaMini-GPT-1.5B\",\n",
    "                          100,\n",
    "                          200,\n",
    "                          50,\n",
    "                          use_gpu = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update\n",
    "prompt = \"\"\"Generate an answer with the information provided in the paragraphs. Do not repeat text\n",
    "                             \\n\\n Paragraphs: {join(documents)} \\n\\n Question: {query} \\n\\n Answer:\"\"\"\n",
    "query = \"Where was the study conducted?\"\n",
    "# Tsai et al. - 2019 - Data science for extubation prediction and value o\n",
    "params = {\n",
    "    \"retriever\": {\"filters\":{\"article_id\": \"a5049cdf-cea7-413d-82d8-446e4cbc8f1d\"}, \"top_k\" : 3}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 96.34it/s]\n",
      "c:\\Users\\junio\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Writing Documents: 10000it [00:00, 35635.76it/s]          \n",
      "Documents Processed: 10000 docs [00:38, 261.03 docs/s]         \n",
      "Query filters are not implemented for the FAISSDocumentStore.\n",
      "The prompt has been truncated from 415 tokens to 412 tokens so that the prompt length and answer length (100 tokens) fit within the max token limit (512 tokens). Shorten the prompt to prevent it from being cut off\n",
      "c:\\Users\\junio\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\generation\\utils.py:1411: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W': <Answer {'answer': '\\n\\nThe study was conducted at multiple hospitals, including in our case hospitals.', 'type': 'generative', 'score': None, 'context': None, 'offsets_in_document': None, 'offsets_in_context': None, 'document_ids': ['302e4d402e39329e02abfb000cfffe01', '244a045f460b324a2c3d33f66184fec8', '1b490570b990733178d988c927ed054c'], 'meta': {'prompt': 'Generate an answer with the information provided in the paragraphs. Do not repeat text\\n                             \\n\\n Paragraphs: 362 ) withawaiverofinformedconsent. inourempiricalstudy, thedataiscollected from intellivue clinical information portfolio ( icip ) including patient data and several electronic health records from october 2015 to september 2016. the imbalanced panel datasets including severaltablesregardingbiochemistry, arterialbloodgas ( abg ), bloodcell, glasgowcomascale ( gcs ), apache, extubation, etc. are collected from different information systems, in our case hospitals. thereare23var , 1709 8of11 j. clin. med. 2019, 8, x for peer review 8 of 11 days 1. 0 evpi 0. 8 eve 0. 6 0. 4 0. 2 0. 0 failure 199 : 1 149 : 1 124 : 1 94 : 1 64 : 1 44 : 1 24 : 1 13 : 1 9 : 1 4 : 1 3 : 1 2 : 1 1 : 1 rate 0. 5 % 0. 7 % 0. 8 % 1. 1 % 1. 5 % 2. 2 % 4. 0 % 7. 1 % 10. m. - h. h. ; formalanalysis, t. - l. t. ; investigation, m. - h. h. ; methodology, t. - l. t. andc. - y. l. ; projectadministration, w. - w. l. ; resources, m. - h. h. and w. - w. l. ; software, t. - l. t. ; supervision, c. - y. l. ; validation, c. - y. l. ; writing — originaldraft, t. - l. \\n\\n Question: Where was the study conducted? '}}>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run_query(prompt, query, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71995b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever MAX SEQ LENGTH: 1000000000000000019884624838656\n",
      "QA model MAX SEQ LENGTH (Input limit): 512\n"
     ]
    }
   ],
   "source": [
    "# init RapidReviewSession\n",
    "sess = RapidReviewSession(\"./articles/\", \n",
    "                          (\"facebook/dpr-question_encoder-single-nq-base\", \"facebook/dpr-ctx_encoder-single-nq-base\"),\n",
    "                          \"MBZUAI/LaMini-GPT-1.5B\",\n",
    "                          100,\n",
    "                          200,\n",
    "                          70,\n",
    "                          use_gpu = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update\n",
    "prompt = \"\"\"Generate an answer with the information provided in the paragraphs. Do not repeat text\n",
    "                             \\n\\n Paragraphs: {join(documents)} \\n\\n Question: {query} \\n\\n Answer:\"\"\"\n",
    "query = \"Where was the study conducted?\"\n",
    "# D'Andrea et al. - 2020 - A bronchial-airway gene-expression classifier to i\n",
    "params = {\n",
    "    \"retriever\": {\"filters\":{\"article_id\": \"1cdb31a4-64cc-4d23-b662-924d12bf93ca\"},\"top_k\" : 3},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 139.12it/s]\n",
      "Writing Documents: 10000it [00:00, 34835.89it/s]          \n",
      "Documents Processed: 10000 docs [00:37, 268.24 docs/s]         \n",
      "Query filters are not implemented for the FAISSDocumentStore.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W': <Answer {'answer': ' The study was conducted in the U.S.', 'type': 'generative', 'score': None, 'context': None, 'offsets_in_document': None, 'offsets_in_context': None, 'document_ids': ['d1900a2a4e9da9652c409b651d524dd0', '19c7627cc8d635d8825c511c7b1d8e75', '8e75a47b7a923d6b9662f3449de39ace'], 'meta': {'prompt': 'Generate an answer with the information provided in the paragraphs. Do not repeat text\\n                             \\n\\n Paragraphs: location - based strategy and 7. 18 % ( 95 % ci, the proportion of cancers that went undetected at the end 4. 13 – 11. 4 % ) with the simplified strategy. in the actual clinical of the first screening round was 4. 65 % ( 95 % ci, 3. 23 – 6. 62 % ) setting, thesepatientsarereferredtofollow - upandwillundergo the second ldct. however, in our model, we assumed that theyprogressed tostage iito penalize b ##follow - up, exclud - rules ing background mortality, were 3. 25 % ( 95 % ci, 1. 90 – 4. 94 % ) of following the current guidelines, 3. 27 % ( 95 % ci, 1. 98 – 4. 88 % ) ii use ; oa adopting the location - based strategy and 3. 26 % ( 95 % ci, articles 31. 91 – 4. 63 % ) withthesimplifiedstrategy. are governed – – 00.. 110000 – – 00.. 00 , because rules wedgeresectionandtherestextentofresection ( 93 % lobectomy ofthehighnegativepredictivevalueofthebgcanalysisforthe of and7 % segmentectomy10 – 13 ; table1 ). peripheralcancers. 9thesubsequentcaremanagementremained use ; oa in the location - based strategy, bronchoscopy plus bgc unchangedfromthestandardstrategy ( fig. 1c ). articles were used for patients with moderate / \\n\\n Question: Where was the study conducted? \\n\\n Answer:'}}>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run_query(prompt, query, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question that is completely out of context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "057e4910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever MAX SEQ LENGTH: 1000000000000000019884624838656\n",
      "QA model MAX SEQ LENGTH (Input limit): 512\n"
     ]
    }
   ],
   "source": [
    "# init RapidReviewSession\n",
    "sess = RapidReviewSession(\"./articles/\", \n",
    "                          (\"facebook/dpr-question_encoder-single-nq-base\", \"facebook/dpr-ctx_encoder-single-nq-base\"),\n",
    "                          \"MBZUAI/LaMini-GPT-1.5B\",\n",
    "                          100,\n",
    "                          200,\n",
    "                          70,\n",
    "                          use_gpu = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update\n",
    "prompt = \"\"\"Generate an answer with the information provided in the paragraphs. Do not repeat text\n",
    "                             \\n\\n Paragraphs: {join(documents)} \\n\\n Question: {query} \\n\\n Answer:\"\"\"\n",
    "query = \"What is the prices for first bidding in January 2020?\"\n",
    "\n",
    "params = {\n",
    "    \"retriever\": {\"filters\":{\"article_id\": \"6786b903-b18e-45d4-b202-d957b6b70431\"},\"top_k\" : 3},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 95.39it/s]\n",
      "Writing Documents: 10000it [00:00, 25937.31it/s]          \n",
      "Documents Processed: 10000 docs [00:49, 200.80 docs/s]         \n",
      "Query filters are not implemented for the FAISSDocumentStore.\n",
      "c:\\Users\\junio\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\generation\\utils.py:1411: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W': <Answer {'answer': ' The prices for first bidding in January 2020 are not provided in the given paragraph.', 'type': 'generative', 'score': None, 'context': None, 'offsets_in_document': None, 'offsets_in_context': None, 'document_ids': ['9b372a9b95f086ed56e41b832bd4f7fe', 'e6221fd636514db33a19b914eee73408', '9ceb658ec6c6c57abafc7dda480c17d4'], 'meta': {'prompt': 'Generate an answer with the information provided in the paragraphs. Do not repeat text\\n                             \\n\\n Paragraphs: sesilevel. usedinschedulingliteraturewhichiscalledunitpenaltyofjobj. ( 2 ) the greeter desk has an exponentially distributed service unitpenaltycanbedefinedas : time. 8 ( 3 ) the patients ’ arrival process is a non - stationary poisson > < 1 ; if c j > d j process. u ¼ 0 ; otherwise ð3þ j > : 3. 4. input / output inotherwords, whenthetardinessisgreaterthan0, we timetobed _ esi5 1. 99 111. 44 128. 57 144. 04 137. 03 2. 40 114. 04 128. 50 133. 54 135. 56 2. 35 114. 92 125. 37 132. 23 141. 49 2. 11 114. 64 124. 08 133. 17 140. 49 2. 11 116. 54 127. 86 133. 17 147. 47 2. 57 113. 57 122. 23 132. 80 134. 54 2. 21 113. 77 127. 80 142. 41 141. 86 2 fahp – fahp – fahp – maut ) maut ) maut ) maut ) maut ) < 0. 5min 25 / 26 – – – – < 15min – 100 / 100 – – – < 30min – 56 / 66 64 / 67 – – < 60min – – – 61 / 34 – < 120min – – – – 70 / 25 interpreted carefully, because any patient who is waiting longer thantheyshouldaspertheiracuitylevelwillbeadverselyaffected. accordingly, we re \\n\\n Question: What is the prices for first bidding in January 2020? \\n\\n Answer:'}}>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run_query(prompt, query, params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
