{
    "article_id": "5b7bf1a7-8c10-4aa8-968b-d93a9a4d8b45",
    "extracted_text": "JOURNAL OF MEDICAL INTERNET RESEARCH Rogers et al\nOriginal Paper\nOptimizing the Implementation of Clinical Predictive Models to\nMinimize National Costs: Sepsis Case Study\nParker Rogers1, MA; Aaron E Boussina2, MSc; Supreeth P Shashikumar2, PhD; Gabriel Wardi3,4, MD, PhD; Christopher\nA Longhurst2, MSc, MD; Shamim Nemati2, PhD\n1Department of Economics, University of California, San Diego, La Jolla, CA, United States\n2Department of Biomedical Informatics, University of California, San Diego, La Jolla, CA, United States\n3Department of Emergency Medicine, University of California, San Diego, La Jolla, CA, United States\n4Division of Pulmonary, Critical Care and Sleep Medicine, University of California, San Diego, La Jolla, CA, United States\nCorresponding Author:\nParker Rogers, MA\nDepartment of Economics\nUniversity of California, San Diego\n9500 Gilman Drive\nLa Jolla, CA, 92093\nUnited States\nPhone: 1 405 850 4751\nEmail: parogers@ucsd.edu\nAbstract\nBackground: Sepsis costs and incidence vary dramatically across diagnostic categories, warranting a customized approach for\nimplementing predictive models.\nObjective: The aim of this study was to optimize the parameters of a sepsis prediction model within distinct patient groups to\nminimize the excess cost of sepsis care and analyze the potential effect of factors contributing to end-user response to sepsis alerts\non overall model utility.\nMethods: We calculated the excess costs of sepsis to the Centers for Medicare and Medicaid Services (CMS) by comparing\npatients with and without a secondary sepsis diagnosis but with the same primary diagnosis and baseline comorbidities. We\noptimized the parameters of a sepsis prediction algorithm across different diagnostic categories to minimize these excess costs.\nAt the optima, we evaluated diagnostic odds ratios and analyzed the impact of compliance factors such as noncompliance, treatment\nefficacy, and tolerance for false alarms on the net benefit of triggering sepsis alerts.\nResults: Compliance factors significantly contributed to the net benefit of triggering a sepsis alert. However, a customized\ndeployment policy can achieve a significantly higher diagnostic odds ratio and reduced costs of sepsis care. Implementing our\noptimization routine with powerful predictive models could result in US $4.6 billion in excess cost savings for CMS.\nConclusions: We designed a framework for customizing sepsis alert protocols within different diagnostic categories to minimize\nexcess costs and analyzed model performance as a function of false alarm tolerance and compliance with model recommendations.\nWe provide a framework that CMS policymakers could use to recommend minimum adherence rates to the early recognition and\nappropriate care of sepsis that is sensitive to hospital department-level incidence rates and national excess costs. Customizing\nthe implementation of clinical predictive models by accounting for various behavioral and economic factors may improve the\npractical benefit of predictive models.\n(J Med Internet Res 2023;25:e43486) doi: 10.2196/43486\nKEYWORDS\nsepsis; machine learning; evaluation; utility assessment; workflow simulation; simulation; model; implementation; data; acute\nkidney injury; injury; technology; care; diagnosis; clinical; cost\nhttps://www.jmir.org/2023/1/e43486 J Med Internet Res 2023 | vol. 25 | e43486 | p. 1\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Rogers et al\npeople worldwide and accounts for over 11 million deaths per\nIntroduction\nyear [18]. In 2018, the US Medicare program (including\nfee-for-service and Medicare Advantage) incurred US $41.5\nRecent advancements in machine learning (ML) and the\nbillion in sepsis-related inpatient hospital admissions and skilled\nproliferation of health care data have led to widespread\nnursing facility care costs [19].\nexcitement about using these technologies to improve care [1,2].\nPredictive analytic models in domains such as sepsis [3-5], acute We propose a framework for improving the implementation of\nkidney injury [6], respiratory failure [7], and general ML-based electronic health record alerts. Our framework aims\ndeterioration [8] have been proposed to improve the timely to minimize the costs of sepsis to payers, which are potentially\nadministration of lifesaving treatments and mitigate expensive avoidable through early detection, timely administration of\ndownstream complications. It has been argued that a more antibiotics, and prevention of overtreatment (ie, excess costs)\ntailored approach that accounts for implementation constraints [5,20,21]. Importantly, these costs can differ by diagnostic\nthat may differ across care settings can further enhance the category (and by extension, hospital departments) due to\nadoption of such systems [9]. differences in incidence rates, patient susceptibility, and\nphysician adherence. Thus, an additional contribution of this\nDespite its importance, the process of implementing predictive\nwork is our estimation of the excess costs of sepsis at the\nanalytics solutions has received little attention relative to the\ndiagnostic-category and national level, that is, the costs paid by\ndevelopment of the underlying ML models [10]. Algorithms\nthe Centers for Medicare and Medicaid Services (CMS). Our\nare becoming more sophisticated, and the infrastructure that\noptimization framework uses these cost estimates and selects\nallows real-time interoperable deployment of predictive analytics\nspecific decision thresholds for each diagnostic category,\nsolutions is expanding [11,12]. This increase in potential and\ndiffering from other cost-benefit frameworks that set decision\ncomplexity underscores the practical importance of\nthresholds uniformly [22,23]. We simulate how thresholds and\nunderstanding the implementation policy layer, which captures\nmodel outcomes can crucially depend on physician adherence\nthe clinical workflow, response protocols, and operational\nand sepsis incidence rates. In summary, we provide a framework\nconstraints. Notably, the dominant evaluation methods within\nthat CMS policymakers could use to recommend minimum\nthe ML community, such as the area under the receiver operating\nadherence rates to the early recognition and appropriate care of\ncharacteristic curve, often do not consider the effect of this\nsepsis that is sensitive to hospital department-level incidence\npolicy layer on model performance [13]. Moreover, such\nrates and national excess costs. This tailored approach results\nperformance metrics do not consider the user response to\nin higher cost savings and diagnostic accuracy.\nprediction and the effectiveness of the treatment protocols [14].\nHowever, the operational constraints can often go beyond\nMethods\nbehavioral factors and may encompass quality improvement\nmandates and cost-saving objectives [15].\nWe conducted a retrospective observational study with the\nThis work focuses on the management of sepsis\u2014a common following 3 broad steps: data collection, excess cost estimation,\nand lethal condition caused by a dysregulated host response to and cost minimization (Figure 1). This was done in accordance\ninfection [16]\u2014although our framework can be applied to other with STROBE (Strengthening the Reporting of Observational\nhospital-acquired conditions [17]. Sepsis afflicts over 49 million Studies in Epidemiology) guidelines [24].\nhttps://www.jmir.org/2023/1/e43486 J Med Internet Res 2023 | vol. 25 | e43486 | p. 2\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Rogers et al\nFigure 1. Overall framework for assessment of attributable cost to sepsis and optimization of predictive model parameters. (A) Data collection, (B)\nData manipulation, (C) Minimizing additional costs from sepsis by choosing sensitivity/specificity pairs across departments. AUROC: area under the\nreceiver operating characteristic curve; DRG: diagnosis-related group; MDC: major diagnostic category; MS-DRG: Medicare Severity Diagnosis-Related\nGroup; UC: University of California.\npossible principal diagnoses into 25 mutually exclusive\nEthics Approval\ndiagnosis areas, which roughly correspond to hospital\nThe use of deidentified data utilized in this study was approved departments.\nby the institutional review board of University of California\nExcess Cost of Sepsis\n(UC) San Diego (approval 800257). The requirement for\ninformed consent was waived by the institutional review board Our efforts to quantify the costs of missed diagnoses (ie, false\ncommittee, as the use of deidentified retrospective data does negatives) provide a new estimate of the avoidable costs of\nnot require patient consent under the Health Insurance severe sepsis and septic shock across broad diagnostic\nPortability and Accountability Act privacy regulations. categories. To quantify, we used granular insurance claims data\nunder the Medicare prospective payment system. We focused\nData Sets and Definitions\non hospitalized Medicare patients, as payments are specific to\nWe collected Medicare claims data from patients 18 years or DRGs\u2014a payment classification system determined mainly by\nolder at UC San Diego Health (UCSDH), an academic health the diagnosis that caused a patient to become hospitalized. This\nsystem, between October 2016 and July 2020. These data system groups clinically similar conditions that require similar\nincluded the following necessary components: (1) the Medicare levels of inpatient resources. This categorization also allows us\nSeverity Diagnosis-Related Groups (DRGs) [25] diagnosis code to show the public value of our optimization routine. We\nfor each patient and their corresponding DRG weights, (2) the excluded patients from sepsis-related DRGs (870, 871, 872)\ntotal amount paid by Medicare for the patient, and (3) the from our analysis because our objective was to assess the excess\nCharlson comorbidity index of the patient upon admission. We inpatient costof sepsis for other DRGs. As such, we gathered\nincluded patients with International Classification of all patients with severe sepsis and septic shock in nonsepsis\nDiseases-Tenth Revision (ICD-10) codes for severe sepsis DRGs and a group of control patients in those same DRGs. This\n(ICD-9: 99592 and ICD-10: R6520) and septic shock (ICD-9: strategy allowed a cost comparison between individuals with\n78552 and ICD-10: R6521). We selected these because of their similar primary diagnoses (ie, underlying conditions) but\ninclusion in the CMS Quality Measure for Severe Sepsis and different secondary sepsis diagnoses. These data included 670\nSeptic Shock, which has impacted sepsis care across the United patients diagnosed with severe sepsis and septic shock across\nStates and provides a standardized approach to management 131 DRGs and 19,565 control group patients.\n[26]. Throughout this paper, the term \u201csepsis\u201d refers to the\nWe adjusted for other underlying factors that drive cost\ndefinitions of severe sepsis and septic shock. The major\ndifferences between patients with sepsis and no sepsis by\ndiagnostic categories (MDCs) are formed by dividing all\nmatching a comparison individual to each patient with sepsis\nhttps://www.jmir.org/2023/1/e43486 J Med Internet Res 2023 | vol. 25 | e43486 | p. 3\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Rogers et al\n[27]. For each patient with sepsis, this matching procedure to reduce the costs of sepsis, the specificity of the model\nselected from all comparison individuals within the same DRG decreases, increasing the false alarm rate. As noted above, false\ncode/weight the patient with the most similar Charlson alarms can also be costly: treating patients with broad-spectrum\ncomorbidity index to the given patient with sepsis. This antibiotics can cause adverse effects and is expensive. Thus,\nmatching procedure does not guarantee conditional the algorithm must balance the trade-off between the cost of\nindependence (ie, causality between sepsis and excess costs), undertreatment and overtreatment.\nbut we use it to approximate excess costs for the sake of\nLet FN represent the number of false negatives (ie, the missed\nsimulation. Further, limiting the selection to patients within the i\ncases of sepsis) within a given MDC category, and let Cost_FN\nsame DRG weight accounts for changes in DRG payments over i\ntime. With sets of patients with sepsis matched to control represent the cost of missing sepsis within this category. The\npatients, we subtracted the Medicare payments made for the miss rate (ie, 1 \u2013 sens i) is a quantity that depends on the selection\nmatched patients from the payments made for the patients with of the risk score threshold within the given MDC category i.\nsepsis. This difference represents the excess costs that Medicare Furthermore, let the estimated functional form f( ) provide a\npaid for sepsis above the underlying costs attributable to the mapping from the chosen sensitivity to the false positive rate\nprimary patient diagnosis. (or false alarm rate). Note that this function is constrained by\nthe model AUC and reflects the balance of model sensitivity\nWe repeated this procedure for all patients with sepsis to form\nand false alarms (see fifth point in Multimedia Appendix 1).\na distribution of excess costs across DRGs. We then averaged\nThis function may also vary by MDC, but for simplicity, we\nthese DRG-specific excess cost estimates by MDC, which\nuse a common functional form f( ). The optimization routine is\ncomprises 16 mutually exclusive diagnosis areas within our\ngiven by the following formula:\ndata set [28]. We show that the added costs from sepsis\ndiagnoses vary dramatically by these diagnostic categories and,\nby extension, different hospital departments.\nIn an effort to calculate the national excess cost of sepsis, we\nthen scaled our excess cost estimates to the national level to\nshow the public impact of early detection and treatment (see Notice that the algorithm chooses sensitivity values (ie, sens)\ni\nMultimedia Appendix 1 for more details). To scale, we first across 16 broad diagnostic categories (ie, i) to minimize costs.\nmultiplied UCSDH payments by the ratio of UCSDH payments The left-hand side of the objective function captures the excess\nto average US payments by DRG [29]. Then, we scaled the total costs or the cost of false negatives: the MDC\u2019s average cost of\npatients treated at UCSDH to the national number of patients false negatives multiplied by the number of patients with sepsis\nwith sepsis by using the share of Medicare patients treated at in the diagnostic category (ie, N_septic) multiplied by the miss\ni\nUCSDH. Lastly, we aggregated the payments across all patients. rate. The right-hand side of the objective function captures the\nWe have validated this scaling approach, as shown in costs of false positives: the false alarm rate multiplied by the\nMultimedia Appendix 1, and we found that we closely estimated number of patients who are not septic in the MDC (ie,\nthe total national inpatient sepsis costs documented in Medicare N_controls) multiplied by the average costs of false negatives\ni\ncost data [30] (among sepsis DRGs 870-872) by scaling UCSDH divided by the conversion factor \u03b1.This conversion factor is a\ntotal sepsis costs to the national level.\nvariable that maps the cost of false positives to the cost of false\nModeling and Optimization negatives, as there may be costs of overtreatment (eg,\nadministering antibiotics if patients do not have sepsis). Our\nWe used the sepsis prediction model by Shashikumar et al [5] simulations, as detailed below, consider various levels of \u03b1,\nto develop an optimization framework that chooses the model\u2019s\nallowing for comparisons across different parameter\nclassification thresholds to minimize the additional costs from\nassumptions. We also included parameters in the model that\nsepsis by the MDCs. In the context of sepsis prediction,\ncharacterize physician adherence to sepsis alarms and tolerances\nclassification thresholds determine above which probability the\nto false alarms (ie, overtreatment). For simplicity, our model\nmodel tags a patient as septic. Although we optimized across\nimplicitly assumes that most sepsis costs are associated with\ndiagnostic categories, our routine could also be implemented\nthe downstream consequences of sepsis, such as organ failure,\nacross hospital departments or, alternatively, across more\nneed for intensive care, and prolonged hospitalization [15]. As\ngranular patient subpopulations. The intuition behind the value\nsuch, we assume the costs of broad-spectrum antibiotics and\nof our implementation rests on the idea that diagnostic categories\nother early sepsis treatments are negligible and thus excluded\nmay determine whether patients with sepsis are costly relative\nfrom our analysis [31].\nto patients with no sepsis, which could potentially merit\ncustomized classification thresholds that account for these Simulations\ncategory-specific nuances. Additionally, departments could\nWe simulate a series of outcomes by implementing sepsis\nhave different rates of sepsis, which may require different\nprediction algorithms with flexible classification thresholds.\nthresholds to avoid a large number of missed detections. By\nSimulation parameters and definitions are provided in Table 1.\nallowing algorithmic sensitivity to adjust to these idiosyncrasies,\nThese parameters constitute several factors in the policy layer\nML algorithms may further reduce costs. Our optimizer is\nof ML algorithm implementation and may vary across hospitals\nconstrained by the predictive model\u2019s area under the curve\nand departments. There are potentially other factors when\n(AUC): as the optimizer chooses a higher sensitivity to sepsis\nimplementing an algorithm that will affect outcomes (eg, the\nhttps://www.jmir.org/2023/1/e43486 J Med Internet Res 2023 | vol. 25 | e43486 | p. 4\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Rogers et al\neffectiveness of treatment), but we focus on a few salient factors stemming not from imperfect algorithms but from imperfect\nthat have arisen, namely, antimicrobial resistance and issues adherence to alarm triggers.\nTable 1. Simulation parameters.\nParameter Description Range\nCost of false alarms (\u03b1) The costs associated with overtreating sepsis (eg, costs of antibiotics, patient side effects) 17-27\nPhysician adherence (\u03b3) The rate at which physicians comply with the algorithm recommendations to treat 0.5-1.0\nArea under the curve The area under the receiver operating characteristic curve, which is a commonly used 0.82, 0.87, 0.9\nmeasure of predictive accuracy\nDiagnostic odds ratio Odds of a positive test in patients with disease relative to the odds of a positive test in 10-120\npatients without disease\nComparison to the Uniform Classification Threshold\nModel Performance and False Alarm Tolerance\nWe calculated the excess costs if the algorithm implementers\nThe first simulation illustrates the cost savings generated when\nuse a uniform 80% sensitivity, representing a clinically useful\nchoosing classification thresholds across diagnostic categories.\ntarget detection rate [5]. We calculated excess costs at different\nThe simulation presents cost savings achieved when using 3\nfalse alarm costs, physician adherence, and accuracy levels, and\ndifferent artificial intelligence models [5] with various levels\nwe calculated the DORs at the optima.\nof predictive performance (ie, receiver operating characteristic\ncurve and AUC). These 3 artificial intelligence models are taken\nResults\nfrom the literature, and we apply them \u201cout-of-the-box\u201d by\nfeeding them into our optimization framework. Each model\u2019s\nCalculation of Excess Costs of Sepsis\nreceiver operating characteristic curve determines the levels of\nFigure 2shows the distribution of mean excess inpatient sepsis\nsensitivity and specificity that the algorithm can achieve and\npayments by DRG. The distribution\u2019s mean is US $23,929, and\ndetermines the trade-offs between underdiagnosis and\nits median is US $8124. Importantly, this implies that, on\noverdiagnosis. We also simulated excess cost outcomes over a\naverage, patients with sepsis generate US $24,000 more charges\nrange of different tolerances to false alarms (eg, higher tolerance\nthan patients who are not septic within the same DRG (matched\nmeans that the costs of overtreatment are lower). This exercise\non baseline severity). Differences between payments for patients\nillustrates the returns of allowing flexible classification\nwithin the same DRG weight exist because Medicare reimburses\nthresholds across diagnostic categories for various ML\nextra for costlier hospital encounters. Patients with high\nalgorithms and cost assumptions. We then calculated and\ncost-to-charge ratios receive additional payments to compensate\npresented the diagnostic odds ratios (DORs) at each accuracy\nfor hospital losses, called as outlier payments [29]. Thus, if the\nlevel and cost assumption, given the optimized classification\ncosts of sepsis treatment or other nonsepsis treatments exceed\nthresholds.\na certain threshold, Medicare compensates the hospital a certain\nPhysician Adherence percentage of the costs above the standard Medicare payment.\nWe then reformulated the optimizer to account for physician Hence, outlier payments drive the difference in Medicare\nadherence. For a given classification threshold, low adherence payments within the same DRG weight. Notice that outlier\nleads to a lower detection rate as alarms are ignored. To illustrate payments also explain why some patients with sepsis are less\nthe effects of physician adherence on costs, we ran a similar costlier than patients with no sepsis: outlier payments for these\nsimulation to the above, but rather than considering 3 models patients with no sepsis happen to be higher for other care\nof differing accuracy, we varied the adherence rate. Hence, the unrelated to sepsis. DRGs in the left tail of the distribution are\nsimulation calculated excess costs at the set of optima for those in the \u201cInfectious and Parasitic Diseases, Systemic or\ndifferent adherence parameters and costs of false alarms. Lower Unspecified Sites\u201d MDC code, which suggests that sepsis may\nlevels of \u03b3 indicate a lower level of physician adherence (see lead to better treatment outcomes or, conversely, sepsis may\nequation S2 in Multimedia Appendix 1). hasten hospital discharge through death. By contrast, DRGs in\nthe \u201cPre-MDC\u201d seem to trigger outlier payments that are quite\nComparison to the Uniform Classification Threshold\nlarge relative to patients with no sepsis. The aggregated excess\nChosen by Optimizer costs by MDC category are presented in Table S1 of Multimedia\nWe underscored the gains from optimizing classification Appendix 1, which shows that sepsis can additionally cost\nthresholds by department. To this end, we did the same set of Medicare up to US $85,000 per patient.\nsimulations when allowing only 1 classification threshold across\nThe second set of results describe the outcomes of a simulation\ndepartments. We then calculated the excess costs for different\nof excess cost savings and DORs achieved by ML algorithms\nfalse alarm costs and accuracy levels at the optimal threshold.\nwith fine-tuned classification thresholds. We estimate that the\nWe also calculated the DORs at these optima.\nexcess cost for inpatient sepsis cases in the United States is US\n$5.2 billion per year before predictive analytics implementation\n(see Multimedia Appendix 1for details). Note that this estimate\ndoes not consider those patients whose primary diagnostic\nhttps://www.jmir.org/2023/1/e43486 J Med Internet Res 2023 | vol. 25 | e43486 | p. 5\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Rogers et al\ncategory is sepsis. Rather, it includes those who belong to results describes 3 simulation routines that differ by the degrees\nnonsepsis DRGs who have secondary sepsis diagnoses. The of freedom with which classification thresholds are chosen: (1)\nformer group incurs a total cost of roughly the same amount as corresponding to 80% sensitivity, (2) uniform across all\nthe excess costs associated with our study\u2019s patient cohort (see diagnostic categories, and (3) distinct and optimized for each\nFigure 3). Additionally, our excess cost estimate ignores excess diagnostic category. We present cost savings for each degree\nutilization of inpatient providers, skilled nursing facilities, and of freedom across various assumptions on ML accuracy and\ncosts incurred due to the high 30-day sepsis readmission rates, false-positive costs. Our second set of results provides the DORs\nwhich is estimated to be 20% [32,33]. Thus, our estimate likely for degrees of freedom (1-3) at the optima chosen to minimize\nprovides a lower bound on excess costs. costs across the same ML accuracy and false-positive cost\nassumptions.\nOur simulation results show the savings achieved with our\nimplementation across various assumptions. Our first set of\nFigure 2. Distribution of mean excess sepsis payments over all diagnosis-related groups. This is the distribution of excess costs, as presented in Figure\n3, but limited to the University of California San Diego Health cohort.\nFigure 3. Venn diagram of the Medicare inpatient population (2016-2019) by diagnosis-related group and severe sepsis diagnosis. The US $5 billion\ntotal costs of severe sepsis and sepsis diagnosis-related groups with severe sepsis or septic shock International Classification of Diseases codes were\ncalculated using University of California San Diego Health Medicare claims data and scaled to the national level. Note that these are total costs rather\nthan excess costs. DRG: diagnosis-related group; ICD: International Classification of Diseases.\nthat as the cost of false positives decreases (ie, higher \u03b1 values),\nCost Savings\nclassification thresholds are chosen more aggressively, which\nUniform Classification Threshold leads to higher cost savings as more patients with sepsis are\ndiagnosed and treated. Similarly, as the predictive power of the\nThe first results detail cost savings when using a uniform\nmodel increases (ie, higher AUC), savings increase. The most\nrecommendation of 80% sensitivity and applying it throughout\ninfluential factor in cost savings is the model\u2019s predictive power,\nthe hospital at different false-positive costs and various levels\nwith excess cost savings ranging from US $2.3 billion to US\nof ML accuracy. Note, this implementation differs from the\n$3.9 billion.\nother two as the threshold is not optimized. Figure 4A shows\nhttps://www.jmir.org/2023/1/e43486 J Med Internet Res 2023 | vol. 25 | e43486 | p. 6\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Rogers et al\nFigure 4. (A) Model cost savings when threshold is 80% sensitivity across departments. (B) Model cost savings when one threshold is chosen, but it\nis the same across departments. (C) Model cost savings when threshold is chosen across departments. (D) Model cost savings by each model type (A),\n(B), and (C). The cost savings estimates in (D) are for area under the curve=0.9 and \u03b1=20 across the 3 models. We choose \u03b1=20 to align with the\nmaximum penalty for false alarms in the PhysioNet challenge [4]. AUC: area under the curve; ROC: receiver operating characteristic curve.\nmillion relative to uniform thresholds (US $4.3 billion cost\nUniform Classification Threshold Chosen by Optimizer\nsavings with uniform and US $4.6 billion with heterogeneous)\nInstead of relying on a uniform recommended threshold, and almost US $700 million compared to the 80% standard.\nimplementers may choose one to minimize costs throughout Cost savings exhibit similar patterns across \u03b1 and AUC values\nthe hospital. The simulation of this implementation shows to as the above models.\nwhat extent cost savings would differ. Figure 4B shows that for\nevery AUC-\u03b1 pair, cost savings are higher when the threshold Comparison of Cost Savings Across Degrees of Freedom\nis chosen. Where savings are the highest, an optimized uniform Figure 4D shows that heterogenous thresholds would increase\nthreshold can save over US $400 million relative to the uniform cost savings by almost US $700 million each year, relative to\nrecommended level (US $3.9 billion cost savings with 80% 80% uniform thresholds and by as much as US $300 million\nuniform and US $4.3 billion cost savings with uniform chosen). each year, relative to a uniform chosen threshold. These\nCost savings exhibit similar patterns across \u03b1 and AUC values calculations assume an AUC of 0.9 and an \u03b1 of 20 across the\nas the above model. 3 models. An \u03b1 of 20 aligns with the maximum penalty for false\nalarms in the PhysioNet challenge [4], and an AUC of 0.9 is\nHeterogenous Classification Thresholds Chosen by\nclose to the predictive accuracy of the latest advancement in\nOptimizer\nsepsis predictive analytics by Shashikumar et al [5].\nFurther, implementers could optimize thresholds across broad\nDOR: Objective Measure of Accuracy\ndiagnostic categories (or hospital departments). Figure 4C shows\nthat the gains from choosing heterogenous thresholds by MDCs Uniform Classification Threshold\nare the highest for lower-accuracy models. This discrepancy is\nWe present an objective measure of accuracy, called the DOR,\nillustrated by the difference between cost savings in the uniform\nattained at each AUC-\u03b1 pair, given the optimal thresholds.\nmodel versus the heterogeneous model, with cost savings at\nFigure 5A illustrates that the highest levels of diagnostic\nAUC of 0.82 as high as US $3.7 billion when using\naccuracy are achieved when costs are the lowest, suggesting\nheterogeneous thresholds compared to US $3 billion with the\nthat cost minimization can simultaneously maximize algorithmic\nuniform model. At the pair where the highest savings are\nperformance. Naturally, more predictive models also lead to\nachieved, heterogeneous thresholds can save over US $300\nhigher DOR values.\nhttps://www.jmir.org/2023/1/e43486 J Med Internet Res 2023 | vol. 25 | e43486 | p. 7\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Rogers et al\nFigure 5. (A) Model diagnostic odds ratio when threshold is 80% sensitivity across departments. (B) Model diagnostic odds ratio when one threshold\nis chosen, but it is the same across departments. (C) Model diagnostic odds ratio when threshold is chosen across departments. (D) Model diagnostic\nodds ratio by each model type (A), (B), and (C). The cost savings estimates in (D) are for area under the curve=0.9 and \u03b1=20 across the 3 models. We\nchoose \u03b1=20 to align with the maximum penalty for false alarms in the PhysioNet challenge [4]. AUC: area under the curve; ROC: receiver operating\ncharacteristic curve.\nUniform Classification Threshold Chosen by Optimizer Discussion\nOptimizing the uniform threshold leads to higher DORs at each\nThis work estimates the national excess costs of sepsis to CMS\nAUC-\u03b1 pair. This improvement is prominent in most accurate\nand provides a framework for implementing predictive models\nmodels, where DOR can differ by as much as 30 between\nin clinical settings. Our framework focuses on the policy\ndifferent degrees of freedom (Figure 5B).\ninterface layer of ML implementation, as shown in Figure 6,\nHeterogenous Classification Thresholds Chosen by and chooses classification thresholds or the points above which\nOptimizer a patient is deemed septic across broad diagnostic categories to\nminimize the costs of undertreatment and overtreatment. We\nHeterogenous thresholds further increase the DOR at every\nillustrate that implementing such algorithms nationwide could\npoint relative to the previous 2 alternatives. In Figure 5C, we\npotentially save the CMS over US $4.6 billion each year from\nsee that DOR reaches up to 116 at the highest point.\ninpatient hospital-related costs alone. As much as 12.3% of\nComparison of Cost Savings Across Degrees of Freedom these savings are attributable to our framework for\nimplementation alone, relative to adhering to uniform\nFigure 5D shows that DOR can increase by as much as 50 when\nclassification thresholds. We find that diagnostic accuracy would\nswitching from a uniform recommended threshold to\nalso improve by as much as 68%.\nheterogeneous thresholds, even though DOR is not directly\nmaximized. Interestingly, minimizing excess sepsis costs also Our work expands the frontier of research on clinical predictive\nleads to higher DOR. models in several directions. First, we provide a methodology\nfor calculating the excess costs of a given condition and apply\nSavings When Accounting for Provider Adherence\nthat method to sepsis care. Second, to our knowledge, we are\nWe present results from a set of simulations that fix AUC at\nthe first to provide a framework for optimizing the parameters\n0.87 but which vary the costs of false positives and physician\nof predictive models according to the patient subpopulation.\nadherence to alarm triggers. Not surprisingly, savings are the\nThird, our framework is the first to explicitly balance the costs\nhighest when adherence is high (see Figure S1 in Multimedia\nof undertreatment (ie, false negatives) and overtreatment (ie,\nAppendix 1). This result highlights the value of adequate\nfalse positives) by using a constrained optimization routine.\ntraining and quality controls to ensure that physicians and\nFourth, we allow for a flexible set of hospital-specific\nfrontline workers who interact with these technologies use them\nparameters that can be rationalized and set by the implementer.\nappropriately. Measures to improve physician adherence to\nAmong these, we include the possibility of imperfect adherence\nalarm triggers could increase cost savings by as much as US $1\nto triggered alarms (ie, behavioral failures) or other factors that\nbillion (US $3 billion at \u03b3=0.5, \u03b1=17; US $4 billion at \u03b3=1.0,\nmight influence the effectiveness of the sepsis treatments, given\n\u03b1=17).\nthe alarm is followed (imperfect treatment). We also include a\nflexible parameter identifying the costs of false positives (ie,\nhttps://www.jmir.org/2023/1/e43486 J Med Internet Res 2023 | vol. 25 | e43486 | p. 8\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Rogers et al\novertreatment). Since this cost is a difficult value to ascertain We show that across various assumptions on physician\nand is specific to a given hospital and condition, we allow the adherence and overtreatment costs, our framework can\nuser to set this parameter at a level that they deem reasonable. dramatically increase excess cost savings.\nFigure 6. Clinical decision support implementation layers. These layers (and the corresponding key attributes) include the (1) platform layer\n(interoperability, scalability, and fault-tolerant), (2) artificial intelligence layer (accuracy, generalizability, and interoperability), (3) policy layer (specific\nand applicable to local hospital workflows, optimality with respect to enterprise\u2019s objectives), and (4) behavioral layer (usability, compliance).\nBy contrast, recent work in predictive analytics considers the example, only includes patients with ICD codes corresponding\ncost of prediction in terms of the number of laboratory tests and to severe sepsis and septic shock. By contrast, if the inclusion\ntheir associated costs [32]. However, these approaches overlook criteria were expanded to cover patients with any sepsis ICD\nthe more significant costs incurred from avoidable hospital code [34] that maps to the sepsis DRG codes (ie, 870-872), the\nexpenses and insurance payouts that could be prevented by more excess cost savings could double (see Multimedia Appendix\ntimely and appropriate health care. Our implementation directly 1). Moreover, if predictive technologies were deployed beyond\nminimizes these costs to optimize predictive analytics. Our inpatient settings such as in outpatient clinics, skilled nursing\napproach also allows hospitals and practitioners to reap savings facilities, or via at-home wearable devices [35], cost savings\nunder current DRG-based payment models and value-based could further increase.\ncare systems [33]. For example, under the increasingly used\nLastly, the cost of false alarms can greatly affect the potential\nmodel of capitation payments, hospitals are allotted a payment\nfor cost savings. If the costs of sepsis overtreatment are high\nfor a fixed number of patient lives. Our implementation allows\nrelative to the costs of undertreatment (eg, worst-case\nhospitals to optimize their predictive analytics within patient\nantimicrobial resistance scenarios), cost savings are limited.\nsubgroups and provide targeted treatment depending on the\nIdentifying these costs, thus, is critical to identifying optimal\nneeds of those subgroups. Excess cost savings from this targeted\nclassification thresholds. However, these costs could vary by\napproach would be directly reaped by hospitals, incentivizing\nhospital or department and may merit more specific calculations.\nthe adoption of new prediction technologies.\nOur analysis, of course, has limitations. First, it is difficult to\nA comparison of results across different model parameter values\nestimate the true excess costs of sepsis. Our estimates, which\nand inclusion criteria offers several broader insights. First,\ncompare patients within the same DRG and with similar baseline\nimproving provider compliance to algorithmic recommendations\ncomorbidity indices, attempt to isolate the effect of sepsis on\ncan yield substantial cost savings. These savings are as large as\nexcess costs. Our estimates, however, are an imperfect attempt\nthose reaped when setting classification thresholds by broad\nat identifying the causal effect of sepsis on costs and could\ndiagnostic categories, highlighting the importance of dedicating\ninclude other factors that increase costs apart from sepsis.\ntime and resources to the behavioral layer (see Figure 5) of the\nSecond, our analysis uses data from only one hospital. Obtaining\nclinical decision support process. By improving compliance to\nfine-grained costs from hospitals is an arduous process; thus,\nalgorithmic recommendations and optimizing model parameters\nwe are limited by our sample size. Further, we do not account\nby patient subpopulation, costs can be further reduced by as\nfor the value of lives saved from improved treatment and any\nmuch as 40%. Thus, the value proposition of new predictive\ncosts incurred after discharge, despite readmissions from sepsis\nmodels depends on how well algorithms are implemented.\nbeing extremely common and expensive [36]. Thus, we analyzed\nSecond, our model could be extended to allow provider the excess costs of patients with sepsis for whom sepsis is a\ncompliance rates that vary by department. These heterogenous nonprimary diagnosis while accounting for other primary\ncompliance rates could, in turn, affect cost-savings outcomes. reasons for hospital admission. This allowed us to analyze\nFurther, one could simulate the potential savings of educational avoidable costs that could be prevented by early sepsis detection\ninterventions that improve compliance rates within during hospital care. Third, there are other factors not discussed\nlow-compliance departments. here that could push providers to not respond to alerts (eg, wrong\nperson alerted, outdated data, repeated alerts). Finally, a patient\u2019s\nThird, broadening the inclusion criteria of these technologies\nMDC category is often not known until discharge, which may\nmay lead to much higher excess cost savings. Our strategy, for\nhttps://www.jmir.org/2023/1/e43486 J Med Internet Res 2023 | vol. 25 | e43486 | p. 9\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Rogers et al\ncomplicate prospective patient-level analysis. However, our We show that fine-tuning prediction technologies to perform\nproposal is focused on driving department-level policies from well under behavioral and cost constraints can improve patient\nretrospective data for the implementation of predictive analytic outcomes while reducing health care spending. We estimate\nalgorithms. Further, recent work has demonstrated the feasibility that CMS could save over US $4.6 billion each year from\nof predicting DRG codes in real time [37,38]. Despite these inpatient hospital-related costs alone and that diagnostic\nlimitations, we believe that our analysis serves as a useful accuracy would improve by as much as 68% through the use\nframework for the deployment of predictive analytics in clinical of an ML algorithm to predict sepsis. Our results suggest that\nsettings and underscores the potential savings when these models the value proposition of new prediction technologies can be\nare deployed in a manner that directly considers costs. improved through fine-tuning within a clinical setting.\nProspective studies are needed to validate these findings.\nAcknowledgments\nSN has received fundings from the National Institutes of Health (R01LM013998, R01HL157985, R35GM143121). GW is\nsupported by the National Institute of General Medical Sciences of the National Institutes of Health (K23GM37182). We would\nlike to thank Julie King, Director of Decision Support at University of California San Diego Health, for providing operational\ncontext and feedback on analyses methods used in this study.\nData Availability\nThe financial data underlying this study cannot be shared publicly due to the proprietary nature of the data. Centers for Medicare\nProvider Utilization and Payment Data (inpatient) used for the extrapolation of costs and case-mix adjustments can be found at\n[30] and [39]. The supplementary material in Multimedia Appendix 1 is available in the Journal of the American Medical\nInformatics Association online.\nAuthors' Contributions\nPR and SN conceived the project and the initial analysis plan. AEB and SPS helped with data collection. GW and CAL provided\ndomain expertise on the health care delivery factors. PR wrote the code and set up the simulation analysis. All authors contributed\nto the interpretation of the findings and the final preparation of the manuscript.\nConflicts of Interest\nSN, SPS, and AEB are cofounders and hold equity in Healcisio Inc, a startup company, which is developing products related to\nclinical predictive analytics. The terms of this arrangement have been reviewed and approved by the University of California San\nDiego in accordance with its conflict of interest policies.\nMultimedia Appendix 1\nSupplementary material.\n[DOCX File , 177 KB-Multimedia Appendix 1]\nReferences\n1. Bates DW, Saria S, Ohno-Machado L, Shah A, Escobar G. Big data in health care: using analytics to identify and manage\nhigh-risk and high-cost patients. Health Aff (Millwood) 2014 Jul;33(7):1123-1131. [doi: 10.1377/hlthaff.2014.0041]\n[Medline: 25006137]\n2. Rajkomar A, Dean J, Kohane I. Machine Learning in Medicine. N Engl J Med 2019 Apr 04;380(14):1347-1358. [doi:\n10.1056/nejmra1814259]\n3. Nemati S, Holder A, Razmi F, Stanley MD, Clifford GD, Buchman TG. An Interpretable Machine Learning Model for\nAccurate Prediction of Sepsis in the ICU. Crit Care Med 2018 Apr;46(4):547-553 [FREE Full text] [doi:\n10.1097/CCM.0000000000002936] [Medline: 29286945]\n4. Reyna MA, Josef CS, Jeter R, Shashikumar SP, Westover MB, Nemati S, et al. Early Prediction of Sepsis From Clinical\nData: The PhysioNet/Computing in Cardiology Challenge 2019. Crit Care Med 2020 Feb;48(2):210-217 [FREE Full text]\n[doi: 10.1097/CCM.0000000000004145] [Medline: 31939789]\n5. Shashikumar SP, Wardi G, Malhotra A, Nemati S. Artificial intelligence sepsis prediction algorithm learns to say \"I don't\nknow\". NPJ Digit Med 2021 Sep 09;4(1):134 [FREE Full text] [doi: 10.1038/s41746-021-00504-6] [Medline: 34504260]\n6. Toma\u0161ev N, Glorot X, Rae JW, Zielinski M, Askham H, Saraiva A, et al. A clinically applicable approach to continuous\nprediction of future acute kidney injury. Nature 2019 Aug;572(7767):116-119 [FREE Full text] [doi:\n10.1038/s41586-019-1390-1] [Medline: 31367026]\nhttps://www.jmir.org/2023/1/e43486 J Med Internet Res 2023 | vol. 25 | e43486 | p. 10\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Rogers et al\n7. Shashikumar SP, Wardi G, Paul P, Carlile M, Brenner LN, Hibbert KA, et al. Development and Prospective Validation of\na Deep Learning Algorithm for Predicting Need for Mechanical Ventilation. Chest 2021 Jun;159(6):2264-2273 [FREE Full\ntext] [doi: 10.1016/j.chest.2020.12.009] [Medline: 33345948]\n8. Rothman MJ, Rothman SI, Beals J. Development and validation of a continuous measure of patient condition using the\nElectronic Medical Record. J Biomed Inform 2013 Oct;46(5):837-848 [FREE Full text] [doi: 10.1016/j.jbi.2013.06.011]\n[Medline: 23831554]\n9. Wong A, Otles E, Donnelly JP, Krumm A, McCullough J, DeTroyer-Cooley O, et al. External Validation of a Widely\nImplemented Proprietary Sepsis Prediction Model in Hospitalized Patients. JAMA Intern Med 2021 Aug 01;181(8):1065-1070\n[FREE Full text] [doi: 10.1001/jamainternmed.2021.2626] [Medline: 34152373]\n10. DECIDE-AI Steering Group. DECIDE-AI: new reporting guidelines to bridge the development-to-implementation gap in\nclinical artificial intelligence. Nat Med 2021 Feb;27(2):186-187. [doi: 10.1038/s41591-021-01229-5] [Medline: 33526932]\n11. Amrollahi F, Shashikumar S, Kathiravelu P, Sharma A, Nemati S. AIDEx-an open-source platform for real-time forecasting\nsepsis and a case study on taking ML algorithms to production. 2020 Jul Presented at: Annual International Conference of\nthe IEEE Engineering in Medicine & Biology Society (EMBC); July 20-24; Montreal, QC, Canada p. 5610-5614. [doi:\n10.1109/embc44109.2020.9175947]\n12. Brant EB, Kennedy JN, King AJ, Gerstley LD, Mishra P, Schlessinger D, et al. Developing a shared sepsis data infrastructure:\na systematic review and concept map to FHIR. NPJ Digit Med 2022 Apr 04;5(1):44 [FREE Full text] [doi:\n10.1038/s41746-022-00580-2] [Medline: 35379946]\n13. Reyna MA, Nsoesie EO, Clifford GD. Rethinking Algorithm Performance Metrics for Artificial Intelligence in Diagnostic\nMedicine. JAMA 2022 Jul 26;328(4):329-330. [doi: 10.1001/jama.2022.10561] [Medline: 35802382]\n14. Jung K, Kashyap S, Avati A, Harman S, Shaw H, Li R, et al. A framework for making predictive models useful in practice.\nJ Am Med Inform Assoc 2021 Jun 12;28(6):1149-1158 [FREE Full text] [doi: 10.1093/jamia/ocaa318] [Medline: 33355350]\n15. Leisman DE, Doerfler ME, Ward MF, Masick KD, Wie BJ, Gribben JL, et al. Survival Benefit and Cost Savings From\nCompliance With a Simplified 3-Hour Sepsis Bundle in a Series of Prospective, Multisite, Observational Cohorts. Critical\nCare Medicine 2017;45(3):395-406. [doi: 10.1097/ccm.0000000000002184]\n16. Singer M, Deutschman CS, Seymour CW, Shankar-Hari M, Annane D, Bauer M, et al. The Third International Consensus\nDefinitions for Sepsis and Septic Shock (Sepsis-3). JAMA 2016 Feb 23;315(8):801-810 [FREE Full text] [doi:\n10.1001/jama.2016.0287] [Medline: 26903338]\n17. Hospital-acquired conditions. Centers for Medicare & Medicaid Services. URL: https://www.cms.gov/Medicare/\nMedicare-Fee-for-Service-Payment/HospitalAcqCond/Hospital-Acquired_Conditions[accessed 2020-10-12]\n18. Rudd KE, Johnson SC, Agesa KM, Shackelford KA, Tsoi D, Kievlan DR, et al. Global, regional, and national sepsis\nincidence and mortality, 1990\u20132017: analysis for the Global Burden of Disease Study. The Lancet 2020\nJan;395(10219):200-211. [doi: 10.1016/S0140-6736(19)32989-7]\n19. Buchman TG, Simpson SQ, Sciarretta KL, Finne KP, Sowers N, Collier M, et al. Sepsis Among Medicare Beneficiaries.\nCritical Care Medicine 2020;48(3):276-288. [doi: 10.1097/ccm.0000000000004224]\n20. Kumar A, Roberts D, Wood KE, Light B, Parrillo JE, Sharma S, et al. Duration of hypotension before initiation of effective\nantimicrobial therapy is the critical determinant of survival in human septic shock*. Critical Care Medicine\n2006;34(6):1589-1596. [doi: 10.1097/01.ccm.0000217961.75225.e9]\n21. Seymour CW, Gesten F, Prescott HC, Friedrich ME, Iwashyna TJ, Phillips GS, et al. Time to Treatment and Mortality\nduring Mandated Emergency Care for Sepsis. N Engl J Med 2017 Jun 08;376(23):2235-2244. [doi: 10.1056/nejmoa1703058]\n22. McIntosh E, Donaldson C, Ryan M. Recent advances in the methods of cost-benefit analysis in healthcare. Matching the\nart to the science. Pharmacoeconomics 1999 Apr;15(4):357-367. [doi: 10.2165/00019053-199915040-00003] [Medline:\n10537954]\n23. Weiner MG, Sheikh W, Lehmann HP. Interactive Cost-benefit Analysis: Providing Real-World Financial Context to\nPredictive Analytics. AMIA Annu Symp Proc 2018;2018:1076-1083. [Medline: 30815149]\n24. von Elm E, Altman DG, Egger M, Pocock SJ, G\u00f8tzsche PC, Vandenbroucke JP, STROBE Initiative. The Strengthening\nthe Reporting of Observational Studies in Epidemiology (STROBE) Statement: guidelines for reporting observational\nstudies. Int J Surg 2014 Dec;12(12):1495-1499 [FREE Full text] [doi: 10.1016/j.ijsu.2014.07.013] [Medline: 25046131]\n25. Baker JJ. Medicare payment system for hospital inpatients: diagnosis-related groups. J Health Care Finance 2002;28(3):1-13.\n[Medline: 12079147]\n26. Sep-1 Quality Measure. URL: https://www.qualitynet.org/files/5d55acfdc84b454088432340?filename=2-1-SEP-v5-7.pdf\n[accessed 2020-10-11]\n27. Todd P. Matching estimators. In: The New Palgrave Dictionary of Economics. London: Palgrave Macmillan; 2016:1-11.\n28. Design and development of the diagnosis related group (DRG). Centers for Medicare & Medicaid Services. URL: https:/\n/tinyurl.com/269shrwn[accessed 2020-10-11]\n29. Krinsky S, Ryan AM, Mijanovich T, Blustein J. Variation in Payment Rates under Medicare's Inpatient Prospective Payment\nSystem. Health Serv Res 2017 Apr;52(2):676-696 [FREE Full text] [doi: 10.1111/1475-6773.12490] [Medline: 27060973]\nhttps://www.jmir.org/2023/1/e43486 J Med Internet Res 2023 | vol. 25 | e43486 | p. 11\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Rogers et al\n30. Medicare provider utilization payment data. Centers for Medicare and Medicaid Services. URL: https://www.cms.gov/\nResearch-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/Medicare-Provider-Charge-Data/Inpatient[accessed\n2020-10-11]\n31. Pepper DJ, Natanson C, Eichacker PQ. Ann Intern Med 2018 Apr 17;168(8):610. [doi: 10.7326/l18-0140]\n32. Erion G, Janizek JD, Hudelson C, Utarnachitt RB, McCoy AM, Sayre MR, et al. A cost-aware framework for the development\nof AI models for healthcare applications. Nat Biomed Eng 2022 Dec;6(12):1384-1398 [FREE Full text] [doi:\n10.1038/s41551-022-00872-8] [Medline: 35393566]\n33. Scott BC, Eminger TL. Bundled Payments: Value-Based Care Implications for Providers, Payers, and Patients. Am Health\nDrug Benefits 2016 Dec;9(9):493-496 [FREE Full text] [Medline: 28465776]\n34. ICD-10-CM/PCS MS-DRGv33 definitions manual. Centers for Medicare & Medicaid Services. URL: https://www.cms.gov/\nicd10manual/version33-fullcode-cms/fullcode_cms/P0328.html[accessed 2020-10-11]\n35. Conroy B, Silva I, Mehraei G, Damiano R, Gross B, Salvati E, et al. Real-time infection prediction with wearable\nphysiological monitoring and AI to aid military workforce readiness during COVID-19. Sci Rep 2022 Mar 08;12(1):3797\n[FREE Full text] [doi: 10.1038/s41598-022-07764-6] [Medline: 35260671]\n36. Gadre SK, Shah M, Mireles-Cabodevila E, Patel B, Duggal A. Epidemiology and Predictors of 30-Day Readmission in\nPatients With Sepsis. Chest 2019 Mar;155(3):483-490. [doi: 10.1016/j.chest.2018.12.008] [Medline: 30846065]\n37. Liu J, Capurro D, Nguyen A, Verspoor K. Early prediction of diagnostic-related groups and estimation of hospital cost by\nprocessing clinical notes. NPJ Digit Med 2021 Jul 01;4(1):103 [FREE Full text] [doi: 10.1038/s41746-021-00474-9]\n[Medline: 34211109]\n38. Islam MM, Li G, Poly TN, Li Y. DeepDRG: Performance of Artificial Intelligence Model for Real-Time Prediction of\nDiagnosis-Related Groups. Healthcare (Basel) 2021 Nov 25;9(12):1632 [FREE Full text] [doi: 10.3390/healthcare9121632]\n[Medline: 34946357]\n39. Extrapolation of Costs and Case-Mix Adjustments. URL: https://www.cms.gov/files/zip/fy-2021-ipps-fr-case-mix-index-file.\nzip[accessed 2023-01-16]\nAbbreviations\nAUC: area under the curve\nCMS: Centers for Medicare and Medicaid Services\nDOR: diagnostic odds ratio\nDRG: diagnosis-related group\nICD: International Classification of Diseases\nMDC: major diagnostic category\nML: machine learning\nSTROBE: Strengthening the Reporting of Observational Studies in Epidemiology\nUCSDH: University of California San Diego Health\nEdited by T Leung; submitted 13.10.22; peer-reviewed by M Kapsetaki, SD Boie; comments to author 23.11.22; revised version\nreceived 08.12.22; accepted 23.12.22; published 13.02.23\nPlease cite as:\nRogers P, Boussina AE, Shashikumar SP, Wardi G, Longhurst CA, Nemati S\nOptimizing the Implementation of Clinical Predictive Models to Minimize National Costs: Sepsis Case Study\nJ Med Internet Res 2023;25:e43486\nURL: https://www.jmir.org/2023/1/e43486\ndoi: 10.2196/43486\nPMID:\n\u00a9Parker Rogers, Aaron E Boussina, Supreeth P Shashikumar, Gabriel Wardi, Christopher A Longhurst, Shamim Nemati. Originally\npublished in the Journal of Medical Internet Research (https://www.jmir.org), 13.02.2023. This is an open-access article distributed\nunder the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits\nunrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of\nMedical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on\nhttps://www.jmir.org/, as well as this copyright and license information must be included.\nhttps://www.jmir.org/2023/1/e43486 J Med Internet Res 2023 | vol. 25 | e43486 | p. 12\nXSL FO (page number not for citation purposes)\n\u2022\nRenderX"
}