{
    "article_id": "13b29c13-6bd7-44ef-8775-654e70b6115b",
    "extracted_text": "JOURNAL OF MEDICAL INTERNET RESEARCH Tardini et al\nOriginal Paper\nOptimal Treatment Selection in Sequential Systemic and\nLocoregional Therapy of Oropharyngeal Squamous Carcinomas:\nDeep Q-Learning With a Patient-Physician Digital Twin Dyad\nElisa Tardini1,2, BSc, MSc; Xinhua Zhang1, BSc, MSc, PhD; Guadalupe Canahuate3, BSc, MSc, PhD; Andrew\nWentzel1, BSc, MSc; Abdallah S R Mohamed4,5, MSc, MD; Lisanne Van Dijk4, PhD; Clifton D Fuller4,5, BSc, MD,\nPhD; G Elisabeta Marai1, PhD\n1Department of Computer Science, University of Illinois at Chicago, Chicago, IL, United States\n2Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milan, Italy\n3Department of Electrical and Computer Engineering, University Of Iowa, Iowa City, IA, United States\n4MD Anderson Cancer Center, Houston, TX, United States\n5Department of Radiation Oncology, The University of Texas, Austin, TX, United States\nCorresponding Author:\nElisa Tardini, BSc, MSc\nDepartment of Computer Science\nUniversity of Illinois at Chicago\n851 S Morgan St\nChicago, IL, 60607\nUnited States\nPhone: 1 3127092826\nEmail: elisa.tardini@mail.polimi.it\nAbstract\nBackground: Currently, selection of patients for sequential versus concurrent chemotherapy and radiation regimens lacks\nevidentiary support and it is based on locally optimal decisions for each step.\nObjective: We aim to optimize the multistep treatment of patients with head and neck cancer and predict multiple patient\nsurvival and toxicity outcomes, and we develop, apply, and evaluate a first application of deep Q-learning (DQL) and simulation\nto this problem.\nMethods: The treatment decision DQL digital twin and the patient\u2019s digital twin were created, trained, and evaluated on a data\nset of 536 patients with oropharyngeal squamous cell carcinoma with the goal of, respectively, determining the optimal treatment\ndecisions with respect to survival and toxicity metrics and predicting the outcomes of the optimal treatment on the patient. Of\nthe data set of 536 patients, the models were trained on a subset of 402 (75%) patients (split randomly) and evaluated on a separate\nset of 134 (25%) patients. Training and evaluation of the digital twin dyad was completed in August 2020. The data set includes\n3-step sequential treatment decisions and complete relevant history of the patient cohort treated at MD Anderson Cancer Center\nbetween 2005 and 2013, with radiomics analysis performed for the segmented primary tumor volumes.\nResults: On the test set, we found mean 87.35% (SD 11.15%) and median 90.85% (IQR 13.56%) accuracies in treatment\noutcome prediction, matching the clinicians\u2019outcomes and improving the (predicted) survival rate by +3.73% (95% CI \u20130.75%\nto 8.96%) and the dysphagia rate by +0.75% (95% CI \u20134.48% to 6.72%) when following DQL treatment decisions.\nConclusions: Given the prediction accuracy and predicted improvement regarding the medically relevant outcomes yielded by\nthis approach, this digital twin dyad of the patient-physician dynamic treatment problem has the potential of aiding physicians\nin determining the optimal course of treatment and in assessing its outcomes.\n(J Med Internet Res 2022;24(4):e29455) doi: 10.2196/29455\nKEYWORDS\ndigital twin dyad; reinforcement learning; head and neck cancer\nhttps://www.jmir.org/2022/4/e29455 J Med Internet Res 2022 | vol. 24 | iss. 4 | e29455 | p. 1\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Tardini et al\nrisk-prediction models (eg, American Joint Committee on\nIntroduction\nCancer [AJCC] staging) incorporated in clinical decision support\nsystems do not by themselves systematically direct clinicians\nBackground\nto select an appropriate treatment that incorporates both\nHead and neck cancer, which includes cancers of the larynx,\noncologic and toxicity end points.\nthroat, lips, mouth, nose, and salivary glands, is now an\nepidemic, with 65,000 new cases in the United States annually Furthermore, disposition to initial IC is then followed by a\n[1], whose treatment is, as in many other types of cancers, a second responsive disposition to either RT or concurrent\ndynamic and complex process. This therapy process involves chemoradiotherapy. Inferring the optimal treatment policies for\nmaking multiple, patient-specific treatment decisions to multistage decisions (eg, which treatment to administer initially\nmaximize efficacy\u2014for example, reduction in tumor size, time and then after observing treatment response; Figure 1) post hoc\nof local region control, and survival time\u2014while minimizing is challenging because an optimal therapy sequence cannot be\nside effects [2-4]. For example, a specific patient may undergo readily pieced togetherfrom several single-stage decisions.\nradiotherapy (RT) alone, RT with concurrent chemotherapy\nFor this reason, in the absence of rigorous clinical trials\n(CC), or induction chemotherapy (IC) [5]. After each round of\ncomparing adaptive IC permutations with concurrent RT, group\nIC, a decision must be made whether to continue IC or start\ncomparison is exceedingly difficult because simple models that\neither RT or CC. These decisions are currently taken by\naccount for confounders at initial disposition (eg, propensity\nclinicians or multidisciplinary tumor boards based on pretherapy\nscores) are unequipped to incorporate sequential decision\npatient characteristics or crude heuristics. Notably, current\nprocesses (eg, the choice of CC afterIC).\nFigure 1. Overview of the therapy selection process, which shows two distinct phases: initial therapeutic selection and subsequent therapeutic selection.\nconcept adapted to health research from the industrial world,\nDigital Twinning\nwhere a digital replica (digital twin) of a physical entity or\nTo address multistage models of therapy selection that process is virtually recreated, with similar elements and\nincorporate both relevant cancer and side-effect considerations, dynamics, to perform real-time optimization and testing [6]. In\nwe introduce an approach based on digital twinning, a new health care, coupled digital twins, that is, digital twin dyads,\nhttps://www.jmir.org/2022/4/e29455 J Med Internet Res 2022 | vol. 24 | iss. 4 | e29455 | p. 2\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Tardini et al\ncould be created for both patients and for the therapy process which choices are optimal and which are not. Q-learning is thus\nand used to inform in a quantitative manner adaptive therapy a type of machine learning that enables systems to automatically\ndecision-making and allow personalization and optimization of learn and improve from experience without being explicitly\nhealth outcomes, prediction and prevention of adverse events, programmed. Q-learning has been shown to lead to valid results\nand planning interventions [7]. By leveraging a large number in a variety of medical problems, including the definition of a\nof head and neck cancer cases collected at a single institutional sequential multiple-assignment randomized trial [8,9], the\nhead and neck data tumor board at the MD Anderson Cancer optimal treatment of depression [8] and\nCenter (MDACC), we propose a methodology approach to Attention-Deficit/Hyperactivity Disorder [9], and the\nleverage deep Q-learning (DQL) as a method to construct a breastfeeding habits that maximize child vocabulary\ndigital twin dyad for simulation of therapy outcomes and development [10].\npotential implementation as a clinical decision aid. Q-learning\nWe used DQL to find a treatment policy that maximizes a linear\nis a recently developed machine learning method for supervised\ncombination of multiple patient outcomes; for example,\nvariable selection and weighting accounting for iterative\ntoxicological and survival outcomes. We considered a 3-step\nprocesses [8].\nMarkov decision process (MDP), with 3 actions in each episode\nIn this paper, we apply for the first time Q-learning methodology corresponding to the three treatment decision points for each\nto dynamically select treatment based on multiple clinically patient:\nrelevant outcomes from data specific to patients with head and\n1. Decision 1 (D1): IC or not\nneck cancer. We use these methods to construct and develop\n2. Decision 2 (D2): CC or RT alone\noptimal dynamic treatment strategies, that is, digital twins of\n3. Decision 3 (D3): neck dissection (ND) or not\nthe therapy process. In conjunction with simulation models of\npatient data, the treatment prescription models form a More details on the setup of the MDP are described in the\npatient-physician (prescriber) digital twin dyad in which the following sections, including the reward functions and state\ntreatment prescription models act as a physician avatar by variables.\nidentifying the optimal treatment for the patient, whereas the\nPatient Data Set\nsimulation models represent the patient by predicting the\noutcome of the treatment sequence. We evaluate the results of We performed a retrospective review of 536 patients with\nthis digital twin dyad approach on a curated data set of patients oropharyngeal squamous cell carcinoma who were treated at\nwith head and neck cancer. the MDACC between 2005 and 2013 (Tables 1-3). Radiomics\nanalysis was performed [13,14] for the segmented [15,16]\nMethods primary tumor volumes. Only patients with a minimum\nfollow-up of 4 years or who died within 4 years were included\nOverview in the data set. The 536 examples were partitioned into 2 distinct\nsets for training and testing using a 75% (n=402)-25% (n=134)\nA state-of-the-art machine learning method applicable to the\nrandom split. To save space, in Table 1, the results of all binary\noptimal therapy process problem is reinforcement learning (RL),\nfeatures are shown only for 1 outcome; the others can be derived\nin particular DQL [8-12]. DQL aims to solve problems in which\ndirectly by subtracting from 100%. For example, the figures for\na model has to choose among a series of options to maximize\nsex being female are 65 (12.1%), 47 (11.7%), and 18 (13.4%),\na certain goal in the given situation: the model observes a set\nunder the respective column headings.\nof actions and the outcome these actions have, thus learning\nhttps://www.jmir.org/2022/4/e29455 J Med Internet Res 2022 | vol. 24 | iss. 4 | e29455 | p. 3\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Tardini et al\nTable 1. Demographics of pretreatment features (before decision 1 [D1]: induction chemotherapy or not; N=536).\nCharacteristics All patients (N=536) Training set (n=402) Testing set (n=134)\nGroup 1: Pretreatment features (before D1)\nAge (years) at diagnosis, mean (SD) 58.9 (9.5) 58.5 (9.4) 60.2 (9.6)\nPathological grade, n (%)\nI 6 (1.1) 2 (0.5) 4 (3)\nII 154 (28.7) 114 (28.4) 40 (29.9)\nIII 274 (51.1) 206 (51.2) 88 (65.7)\nIV 3 (0.6) 1 (0.2) 2 (1.5)\nNot available 99 (18.5) 79 (19.7) 20 (14.9)\nSex (male), n (%) 471 (87.9) 355 (88.3) 116 (86.6)\nHPVaor P16bstatus, n (%)\nNegative 43 (8) 33 (8.2) 10 (7.5)\nPositive 305 (56.9) 228 (56.7) 77 (57.5)\nUnknown 188 (35.1) 141 (35.1) 47 (35.1)\nTccategory, n (%)\nT1 113 (21.1) 87 (21.6) 26 (19.4)\nT2 219 (40.9) 156 (38.8) 63 (47)\nT3 116 (21.6) 91 (22.6) 25 (18.7)\nT4 86 (16) 67 (16.7) 19 (14.2)\nTxd 2 (0.4) 1 (0.2) 1 (0.7)\nNecategory (8th editionf), n (%)\nN0g 20 (3.7) 14 (3.5) 6 (4.5)\nN1 249 (46.5) 181 (45) 68 (50.7)\nN2 250 (46.6) 194 (48.3) 56 (41.8)\nN3 17 (3.2) 13 (3.2) 4 (3)\nAJCCh(8th edition), n (%)\nI 186 (34.7) 137 (34.1) 49 (36.6)\nII 81 (15.1) 63 (15.7) 18 (13.4)\nIII 64 (11.9) 44 (10.9) 20 (14.9)\nIV 203 (37.9) 157 (39.1) 46 (34.3)\nNot available 2 (0.3) 1 (0.2) 1 (0.7)\nSmoking status at diagnosis, n (%)\nCurrent 115 (21.5) 85 (21.1) 30 (22.4)\nFormer 203 (37.9) 151 (37.6) 52 (38.8)\nNever 218 (40.7) 166 (41.3) 52 (38.8)\nSmoking status\nPacks per year, mean (SD) 17.7 (23.7) 16.7 (22.9) 20.5 (26)\nNot available, n (%) 28 (4.7) 21 (5.2) 7 (5.2)\nAspiration rate before therapy (no), n (%) 16 (3) 14 (3.5) 2 (1.5)\nNumber of affected lymph nodes, mean (SD) 2.0 (1.3) 2.1 (1.3) 1.8 (1)\nTumor laterality, n (%)\nBilateral 21 (3.9) 16 (4) 5 (3.7)\nhttps://www.jmir.org/2022/4/e29455 J Med Internet Res 2022 | vol. 24 | iss. 4 | e29455 | p. 4\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Tardini et al\nCharacteristics All patients (N=536) Training set (n=402) Testing set (n=134)\nLeft 242 (45.1) 188 (46.8) 54 (40.3)\nRight 273 (50.9) 198 (49.3) 75 (56)\nTumor subsite, n (%)\nBase of tongue 266 (49.6) 204 (50.7) 62 (46.3)\nTonsil 223 (41.6) 158 (39.3) 65 (48.5)\nOther 47 (8.8) 40 (10) 7 (5.2)\nRace, n (%)\nAfrican American or Black 16 (3) 10 (2.5) 6 (4.5)\nAsian 4 (0.7) 3 (0.7) 1 (0.7)\nHispanic or Latino 21 (3.9) 17 (4.2) 4 (3)\nNative American 1 (0.2) 1 (0.2) 0 (0)\nWhite or other 494 (92.2) 371 (92.3) 123 (91.8)\naHPV: human papillomavirus.\nbP16: protein expression 16.\ncT: primary tumor.\ndTx: no information about the primary tumor or it cannot be measured.\neN: lymph nodes.\nfAmerican Joint Committee on Cancer\u2019s Cancer Staging Manual, 8th edition.\ngN0: nearby lymph nodes do not contain cancer.\nhAJCC: American Joint Committee on Cancer.\nhttps://www.jmir.org/2022/4/e29455 J Med Internet Res 2022 | vol. 24 | iss. 4 | e29455 | p. 5\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Tardini et al\nTable 2. Feature demographics before and after decision junctions (N=536).\nCharacteristics All patients (N=536), n (%) Training set (n=402), n (%) Testing set (n=134), n (%)\nGroup 2: Post\u2013induction chemotherapy\u2013decision features (after D1aand before D2b)\nPrescribed chemotherapy\nNone 342 (63.8) 250 (62.2) 92 (68.7)\nDoublet 41 (7.6) 32 (8) 9 (6.7)\nTriplet 143 (26.7) 111 (27.6) 32 (23.9)\nQuadruplet 7 (1.3) 7 (1.7) 0 (0)\nNot otherwise specified 3 (0.6) 2 (0.5) 1 (0.7)\nChemotherapy modification 85 (15.9) 65 (16.2) 20 (14.9)\nChemotherapy modification type\nNo dose adjustment 451 (84.1) 336 (83.6) 115 (85.8)\nDose modified 21 (3.9) 16 (4) 5 (3.7)\nDose delayed 10 (1.9) 9 (2.2) 1 (0.7)\nDose cancelled 18 (3.4) 13 (3.2) 5 (3.7)\nDose delayed and modified 6 (1.1) 5 (1.2) 1 (0.7)\nRegimen modification 29 (5.4) 22 (5.5) 7 (5.2)\nUnknown 1 (0.2) 1 (0.2) 0 (0)\nDose-limiting toxicity 95 (17.7) 73 (18.2) 22 (16.4)\nDose-limiting toxicity g rade (also included for dermatological, neurological, gastrointestinal, hematological, nephrological, vascular,\nand infection [pneumonia])\n0 446 (83.2) 334 (83.1) 112 (83.6)\n1 7 (1.3) 6 (1.5) 1 (0.7)\n2 33 (6.2) 26 (6.5) 7 (5.2)\n3 41 (7.6) 29 (7.2) 12 (9)\n4 9 (1.7) 7 (1.7) 2 (1.5)\nImaging (yes) 194 (36.2) 152 (37.8) 42 (31.3)\nComplete response, primary (1c, as opposed to 0d) 84 (15.7) 67 (16.7) 17 (12.7)\nComplete response, nodal (1) 16 (3) 14 (3.5) 2 (1.5)\nParietal response, primary (1) 89 (16.6) 70 (17.4) 19 (14.2)\nParietal response, nodal (1) 156 (29.1) 125 (31.1) 31 (23.1)\nStable disease, primary (1) 11 (2.1) 8 (2) 3 (2.2)\nStable disease, nodal (1) 10 (1.9) 6 (1.5) 4 (3)\nGroup 3: Post\u2013concurrentchemotherapy\u2013decision features (after D2 and before D3e)\nConcurrent chemotherapy regimen\nNone 126 (23.5) 89 (22.1) 37 (27.6)\nPlatinum based 257 (47.9) 198 (49.3) 59 (44)\nCetuximab based 129 (24.1) 95 (23.6) 34 (25.4)\nOther 24 (4.5) 20 (5) 4 (3)\nConcurrent chemotherapy modification (1) 99 (18.5) 77 (19.2) 22 (16.4)\nComplete response, primary 2 (1) 450 (84.1) 336 (83.8) 114 (85.1)\nComplete response, nodal 2 (1) 247 (46.1) 186 (46.3) 61 (45.5)\nParietal response, primary 2 (1) 77 (14.4) 58 (14.4) 19 (14.2)\nParietal response, nodal 2 (1) 257 (47.9) 191 (47.5) 66 (49.3)\nhttps://www.jmir.org/2022/4/e29455 J Med Internet Res 2022 | vol. 24 | iss. 4 | e29455 | p. 6\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Tardini et al\nCharacteristics All patients (N=536), n (%) Training set (n=402), n (%) Testing set (n=134), n (%)\nStable disease, primary 2 (1) 2 (0.4) 2 (0.5) 0 (0)\nStable disease, nodal 2 (1) 10 (1.9) 6 (1.5) 4 (3)\nDose-limiting toxicity 2 (also included for dermatolog- 102 (19) 80 (19.9) 22 (16.4)\nical, neurological, gastrointestinal, hematological,\nnephrological, vascular, and other)\nGroup 4: Primary outcomes after D3\nFour-year overall survival (alive) 457 (85.3) 344 (85.6) 113 (84.3)\nFeeding tube 6 months (yes) 98 (18.3) 77 (19.2) 21 (15.7)\nAspiration rate after therapy (yes) 98 (18.3) 79 (19.7) 19 (14.2)\nDysphagia (yes) 154 (28.7) 122 (30.3) 32 (23.9)\naD1: decision 1 (induction chemotherapy or not).\nbD2: decision 2 (concurrent chemotherapy or radiotherapy alone).\ncThe patient survived for at least four years after the treatment ended.\ndAll other events.\neD3: decision 3 (neck dissection or not).\nTable 3. Demographics of physicians\u2019decisions (N=536).\nCharacteristics All patients (N=536), n (%) Training set (n=402), n (%) Testing set (n=134), n (%)\nTreatment decisions (made by physicians)\nD1a: yes 194 (36.2) 152 (37.8) 42 (31.3)\nD2b: yes 410 (76.5) 313 (77.9) 97 (72.4)\nD3c: yes 111 (20.7) 84 (20.9) 27 (20.1)\naD1: decision 1 (induction chemotherapy or not).\nbD2: decision 2 (concurrent chemotherapy).\ncD3: decision 3 (neck dissection or not).\nwith and without the inclusion of radiomics features [19,20].\nEthics Approval\nThe reward is 0 for D1 and D2 and equal to equation (1) for\nThe data were collected after approval from the MDACC D3. As a result, there is no need for a discount factor (or,\ninstitutional review board (PA16-0303 and retrospective equivalently, set it to 1), and the total reward is exactly equation\nRCR03-0800). (1).\nModeling The state variables are illustrated in Tables 1and 2, where all\nWe focused on two outcome measures: (1) four-year overall the features are divided into four groups separated by the state\nsurvival(OS) as a single binary dichotomized outcome measure in which those features were used:\n(ie, the patient survived for at least four years after the treatment\n1. Group 1: pretreatment features (before D1)\nended, coded as 1, with all other events coded 0) and (2) the\n2. Group 2: post\u2013IC-decision features (after D1 and before\ncombination of OS and dysphagia (DP) as a multi-outcome\nD2)\nmeasure. DPis defined as either feeding-tube dependence(FT)\n3. Group 3: post\u2013CC-decision features (after D2 and before\nor aspiration rate (AR) 6 months after the end of treatment\nD3)\n[17,18]. Note that although OS is encoded as a binary value,\n4. Group 4: primary outcomes after ND decision (after D3)\nthe outcome of treatment depends on the external situation and\nthe treatment sequence applied; that is, both OS and DP are The features in Table 1were used for the initial state s0 of the\ninfluenced by the treatment sequence applied. As a result, the MDP and are denoted as group 1. In Table 2, the features in\nwhole problem is not a simple regression but bona fide RL with group 2 combined with group 1 and a 1-hot vector of D1 were\nunknown transition probability. The combined outcome measure used for state s1; the features in group 3 combined with groups\nwas computed only at the final step using the following formula: 1-2 along with a 1-hot vector of D1 and D2 were used for state\ns2. As a result, the features included at each decision point\nOS\u2013(FT+AR After Therapy\u2013AR Before Therapy) (1)\nrepresent the complete history of the patient up to the current\nEquation (1) was used as the total reward in training the DQL treatment decision. The features in group 4 were onlyused to\nmodels. For each of these scenarios, the models were trained evaluate the reward as formulated in equation (1) and notused\nhttps://www.jmir.org/2022/4/e29455 J Med Internet Res 2022 | vol. 24 | iss. 4 | e29455 | p. 7\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Tardini et al\nas learning features. A detailed description of all variables is DQL Neural Modeling\ngiven in Table S1 in Multimedia Appendix 1, and we have\nFigure 2shows an overview of the training process. A separate\nsummarized the demographics of physicians\u2019decisions in Table\nNN model was trained for each of the decision points D1-D3.\n3.\nEach model was constructed recursively based on the previous\nPreprocessing model results at the subsequent decision point or the outcome\n(single or combined) in the case of D3. The models were trained\nThe data set was randomly split into training (402/536, 75%)\nto optimize the total rewards without any discounting factor,\nand testing (134/536, 25%) sets. To reduce the radiomic feature\nthat is, the combined outcome of equation (1).\ndimensionality (approximately 1000) [21], we applied principal\ncomponent analysis and kept the 6 top components, which The first model to be trained was Q3, which represents ND\nexplain 90% of the overall feature variance. No blind assessment (D3), based on the final outcomes, the treatment decisions made\nof the decisions or outcomes was made. Unknown human in D3, and the patient\u2019s history before D3. We tuned the learning\npapillomavirus status was handled using a distinguished value rate so that the mean reward converged smoothly instead of\n(0). Missing values for all other covariates were handled using fluctuating drastically. The training for D3 was terminated when\nsingle imputation: median for numerical variables and mode the NN weights had converged. Next, the model for D2 was\nfor categorical variables. The ordinal covariates pathological trained based on the result of Q3 instead of the final outcomes,\ngrade, T (primary tumor) category, N (lymph nodes) category, and D1 was trained based on the result of Q2. The models were\nAJCC staging, and prescribed chemotherapy (none, single, constructed and trained using the PyTorch framework with\ndoublet, triplet, or quadruplet) were coded as numerical features. graphics processing unit acceleration. Once the models had been\nAfter these preprocessing steps, all features were rescaled to trained, they were used in a forward order, as opposed to the\nthe (\u20131 to +1) range, as is standard in neural network (NN) training order, to prescribe the optimal treatment at each decision\ntraining. step. This is illustrated in Figure 3.\nFigure 2. Overview of deep Q-learning model training. RL: reinforcement learning.\nFigure 3. Overview of applying deep Q-learning model to make treatment prescriptions. RL: reinforcement learning.\nWe constructed multiple shallow-to-deep NNs with an computational cost of bootstrapping, we will report in the\nincreasing number of layers until the deepest model showed Resultssection the performance of survival and toxicity under\npoor performance because of overfitting. We sampled 1000 all possible numbers of hidden layers from 1 to 8, instead of\nseparate training sets from the initial training data and trained performing the 5-fold cross-validation on all hyperparameters\na separate model on each of these sets, thus obtaining such as the number of nodes in each layer.\nbootstrapped models with 95% CIs. Because of the high\nhttps://www.jmir.org/2022/4/e29455 J Med Internet Res 2022 | vol. 24 | iss. 4 | e29455 | p. 8\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Tardini et al\nBy prescribing an optimal treatment at each treatment junction, vector of D1. The architecture is demonstrated in Figure 4. D3\nthe DQL models constructed a digital twin of the decision was treated similarly with input features from groups 1-3, along\nprocess, with the goal of finding an optimal treatment plan that with a 1-hot vector of D1 and D2. The full details of the SVC\nmay differ from the physician\u2019s original decisions. The trained are provided in Table S2 in Multimedia Appendix 1. The C, \u03b3,\nmodels and the code to compute the treatment decisions have and class weights of each SVC were tuned through 5-fold\nbeen made available on GitHub [22]. cross-validation over the F1score on the training data because\ndifferent values are needed for optimally predicting different\nTreatment Simulator for Evaluating DQL\nfeatures. Some features such as FT have quite imbalanced\nAs the DQL goal is not to replicate clinicians\u2019decisions but to values, and to address this, we set the weights of each training\nfind an optimal, potentially different treatment, our evaluation example to be inversely proportional to the frequency of its\nincludes building a treatment simulator (TS) model that, given class, hence placing more emphasis on less-common classes.\na patient\u2019s history and the prescribed treatment, predicts the The accuracy of the TS in predicting the next-stage feature value\noutcome of that treatment. The TS consists of a transition model (instead of the treatment decision) was assessed with 95% CIs\nfor each intermediate and final outcome measure, built using a by using out-of-bag evaluation of 1000 models trained on\nsupport vector classifier (SVC). For example, in the case of D1, stratified bootstrapped samples.\nan SVC was trained for each group 2 feature in Table 2 to\nThe TS serves as an in silico digitaltwinof the patient treatment\npredict, as output, that feature\u2019s value resulting from D1, and\nbecause we can use it to dynamically simulate the patient\u2019s in\nthe input of these SVCs is all the Table 1features, that is, group\nvivo course as a function-given treatment policy, without having\n1. For D2, SVC will predict for group 3 features in Table 2\nto physically treat the patient.\nusing, as input, features from groups 1-2, along with a 1-hot\nFigure 4. Illustration of the treatment simulator for D2. Those for D1 and D3 are similar, and their input features are from group 1 and groups 1-3,\nrespectively. SVC: support vector classifier. D1: decision 1. D2: decision 2. D3: decision 3.\nas decision trees could be customized for a single-step\nProtocol of Evaluating DQL\nprediction, they do not account for the sequential nature of this\nThe DQL models were evaluated against the TS because our decision-making process. Furthermore, ultimately, evaluating\ngoal is not to replicate physicians\u2019decisions but to learn from such rule-based approaches would encounter the same what-if\nthe final reward and then quantitatively evaluate the treatment questions, that is, off-policy evaluation. Indeed, this has been\ndecisions learned by the DQL model. Such what-if questions a long-standing open problem in RL, and we hope that our\nare standard in off-policy evaluation in RL (in off-policy digital twin approach may provide a new partialsolution.\nevaluation, one evaluates a policy without being able to\nAlthough we tested the DQL models against the TS that allows\nimplement it in the real environment). The state-of-the-art\non-policy evaluation, we emphasize two important\napproaches fall into three categories [23]: (1) direct approach\nconsiderations in the evaluation protocol:\nwhere a model of the environment is fit (same as what we do),\n(2) importance sampling, and (3) a combination of the 2. 1. TS was not used for training. Instead, we intentionally\nImportance sampling is known to suffer from high variance and trained DQL on a tabular observation data set of 402\nthus would require a large number of samples, whereas our test patients. This is because if we did train on the TS, the\nset consisted of 134 patients. Similarly, Gottesman et al [24] learned model would overfit the simulated environment,\ndetailed this difficulty along with several possible scenarios, thereby overestimating the test performance (which is also\nbut no conclusion was drawn regarding which metric to use. measured from the TS). This deliberate decoupling of\nYauney and Shah [25] evaluated the learned policy through training and testing strategy, which is also adopted by\nsimulated clinical trials, an approach identical to ours. Yauney and Shah [25], is aimed specifically to ensure the\nfairness of the comparison. Again, note that although the\nAt the same time, to the best of our knowledge, there is no\nTS can be directly used to optimize the policy through any\nexisting rule-based approach (eg, decision trees) that is suitable\nmodel-based RL, we intentionally refrained from doing so\nfor this task. We note that although very generic methods such\nhttps://www.jmir.org/2022/4/e29455 J Med Internet Res 2022 | vol. 24 | iss. 4 | e29455 | p. 9\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Tardini et al\nand followed the model-free DQL. This ensures a fair accuracy is only concerned with the final outcome features in\ntesting, noting that the TS is also used in generating the group 4 of Table 2. It uses the TS to generate a simulated 3-step\ntesting trajectory. trajectory for each patient by following the 3 treatment decisions\n2. The learned agent did not have access to the TS at test time, from the physician and compares the final outcome with the\nand the decisions were based solely on the current state. ground truth.\nThe TS was invoked only to simulate the environment, that\nThe DQL models were then evaluated by comparing the OS\nis, generating the consequent state arising from the proposed\nand DP rates (as computed by the TS) resulting from the DQL\ndecision and treatment, allowing the performance to be\ntreatment decisions with the outcomes observed under physician\nevaluated. This was consistent with the model-free nature\ntreatment on a separate test set. To facilitate interpretation, we\nof the DQL and ensured a fair evaluation by avoiding\ncomputed the similarity between each of the DQL model\u2019s\npeeking into the real dynamics under which the test was\ndecisions and the physicians\u2019 decisions, considering each\nconducted.\ndecision point independently. This evaluation does not need the\nIncidentally, even if the TS wereavailable for decision-making TS. To further support interpretation, the policy followed by\n(that is, the planning setting), there would still be significant each model was analyzed by computing the increase (or\nobstacles. In open-loop planning, a sequence of actions (3 decrease) in prescription rate for each treatment decision\ntreatment decisions in our application) is chosen beforeactually compared with the physicians\u2019ad hoc prescriptions to express\nperforming any of them, that is, later actions neither await nor whether the model was more (or less) likely to prescribe a\nrespond to the outcome of the preceding actions. In this case, certain treatment when compared with actual physicians.\none only needs to compute 8 scores and select the optimal one.\nWe also evaluated the DQL treatment decisions by examining\nHowever, even in such an overly simplistic solution, one still\ncompliance with the National Comprehensive Cancer Network\nneeds to compute the expected reward, which relies on\nguidelines of acceptable care [26], which state that eligible\nintegration over the stochastic outcome of the actions, that is,\npatients with advanced-stage cancer (T3-4 or N1-3) must be\nstates s1-s3. Mathematically, it solves\nprescribed chemotherapy, either IC (D1) or CC (D2). These\nguidelines or restrictions were not explicitly imposed during\nmodel training.\nWe first report the performance of the TS and the simulation\nAlthough sampling is a natural approach to it, the high performance of the DQL models and compare the DQL\ndimensionality of the state space demands a large amount of recommendations with the physician decision process, both in\nsamples from the TS to accurately compute the expected reward. terms of per-decision similarity and overall similarity, that is,\naveraging the similarity for each decision point for each model.\nIn practice, closed-loop planning is clearly preferred, where\nTo report compliance, and to ensure quality and facilitate\nlater actions are chosen to best respond to the outcome of\nreproducibility, we provide a formal presentation of the\npreceding decisions and treatments, leading to the mathematical\nTransparent Reporting of a Multivariable Prediction Model for\noptimization formulation as\nIndividual Prognosis or Diagnosis checklist, formalized in Table\nS3 in Multimedia Appendix 1.\nResults\nAs a result, we must compute the state value (V[s]-functions)\nAccuracy of TS Models\nor the state-action value (Q[s,a]-functions). Because of the\ncomplexity of state space, both of them are nontrivial, even The complete 1-stepprediction accuracy of each TS model (with\ngiven the TS. Compared with open-loop planning, an additional 95% CIs) is presented in Table 4. The average bootstrapped\nlayer of difficulty is incurred here because one needs to estimate prediction accuracy of the individual TS models was 87.35%\n8 functionsinstead of 8 real numbers. (SD 11.15%), and the median accuracy was 92.07% (IQR\n13.56%). At the whole trajectory level, the average\nTo summarize, this patient treatment digital twin approach\nstart-to-finishprediction accuracy on the test set outcomes was\nenables us to simulate the results of applying the Q-learning\n83.21% (SD 1.54%), with 83.96% (SD 0.37%) accuracy for\nmodels to patients and to compare the outcomes with those\nOS, 82.46% (SD 1.87%) for DP, 88.43% (SD 1.87%) for FT\nresulting from the clinicians\u2019decisions. Fairness was also upheld\nand 83.58% (SD 0.75%) for AR. Please note that these accuracy\nby not using the TS in either training or decision-making at\nvalues are neither in terms of treatment prediction nor\ntesting time.\ncomparable with physician\u2019s treatment D1, D2, and D3. Instead,\nEvaluation Metrics the TS predicts the patient\u2019s feature or state (eg, complete\nresponse or nodal) resulting from a treatment decision given in\nThe TS performance was evaluated by 2 accuracies without\nthe data and compares it with the ground truth outcome in the\nrunning the DQL. The 1-step accuracy follows the trajectory\ndata set. Therefore, this accuracy should not be compared with\nfrom the data set and, at each of the 3 decision junctions,\nthe frequency of matching physician decisions (which is 70.4%,\npredicts the resulting feature value after practicing the\nas we will show in the Similarity to Physicianssection).\nphysician\u2019s treatment and then compares it with the ground\ntruth outcome in the data set. In contrast, the start-to-finish\nhttps://www.jmir.org/2022/4/e29455 J Med Internet Res 2022 | vol. 24 | iss. 4 | e29455 | p. 10\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Tardini et al\nTable 4. One-step prediction accuracy of treatment simulation (with 95% CIs) based on out-of-bag evaluation of 1000 stratified bootstrapped samples.\nPredicted outcome Accuracy without radiomics (%; 95% CI) Accuracy with radiomics (%; 95% CI)\nOverall survival (4 years) 78.23 (73.20-82.92) 78.95 (74.29-83.09)a\nFeeding tube (6 months) 74.37 (68.81-79.40) 74.74 (68.53-80)\nAspiration rate after therapy 75 (69.38-80) 73.96 (68.04-78.76)\nPrescribed chemotherapy (single, doublet, triplet, quadruplet, 83 (77.32-87.57) 82.77 (78.06-87.13)\nnone, or not otherwise specified)\nChemotherapy modification (yes or no) 82.09 (76.96-86.34) 80.22 (75.98- 84.82)\nDose modified 92.39 (89.23-94.95) 94.50 (92.31-96.39)\nDose delayed 92.39 (89.12-95.17) 92.35 (88.56-95.52)\nDose cancelled 91.58 (87.68-94.77) 93.37 (90.05-96.15)\nRegimen modification 93.54 (84.36-95.88) 91.79 (54.7-95.05)\nDLTb(yes or no) 81.51 (77.25-85.42) 81.77 (77.34-85.79)\nDLT: dermatological 92.77 (23.95-95.29) 90.58 (87.05-93.3)\nDLT: neurological 92.17 (88.66-95.1) 92.27 (88.83-95.26)\nDLT: gastrointestinal 89.60 (85.86-92.96) 90.36 (86.8-93.36)\nDLT: hematological 90.10 (86.17-93.23) 91.84 (88.02-94.47)\nDLT: nephrological 99.03 (98-100) 98.50 (96.55-99.52)\nDLT: vascular 98.45 (96.45-100) 98.50 (96.86-100)\nDLT: infection (pneumonia) 98.98 (94.42-100) 98.44 (96.37-99.50)\nDLT: other 95.08 (90.82-97.57) 92.35 (83.17-96.98)\nDLT: grade 73.85 (53.84-79.9) 77.02 (72.55-81.48)\nNo imaging (0=no and 1=yes) 100 (100-100) 100 (100-100)\nComplete response, primary 83.51 (78.82-87.56) 84.02 (79.58-88.05)\nComplete response, nodal 94.79 (90.5-97.03) 94.82 (89.64-97.4)\nParietal response, primary 81.47 (76.84-86.27) 80.32 (75.89-84.85)\nParietal response, nodal 92.93 (90-95.65) 92.93 (90.05-95.52)\nStable disease, primary 95.10 (91.96-97.84) 96.35 (92.96-98.03)\nStable disease, nodal 96.58 (94.47-98.05) 97.50 (96.08-98.55)\nConcurrent chemotherapy regimen 70 (64.68-75.27) 65.99 (59.91-71.8)\nConcurrent chemotherapy modification (yes or no) 70.53 (64.92-76.06) 71.43 (65.68-76.68)\nComplete response, primary 2 79.22 (23.03-85.22) 77.35 (29.95-84.57)\nComplete response, nodal 2 55.50 (49.01-61.54) 56.25 (50-61.94)\nParietal response, primary 2 78.92 (74.26-83.25) 83.66 (79.90-86.60)\nParietal response, nodal 2 52.50 (46.19-58.03) 52.85 (46.46-58.62)\nStable disease, primary 2 99.48 (98.46-100) 99.48 (98.41-100)\nStable disease, nodal 2 96.50 (94.12-98.04) 96.92 (94.36-98.45)\nDLT: dermatological 2 91.99 (87.63-95.17) 94.95 (91.53-97.07)\nDLT: neurological 2 95.79 (5.96-97.46) 91.97 (88.29-94.69)\nDLT: gastrointestinal 2 89.74 (85.22-93.65) 91.13 (87.50-94.06)\nDLT: hematological 2 92.71 (89.42-95.16) 93.23 (90.10-95.57)\nDLT: nephrological 2 92.25 (88.17-97.94) 96.53 (93.62-98.48)\nDLT: vascular 2 100 (99.45-100) 100 (99.02-100)\nDLT: other 2 93.97 (89.73-96.86) 93.24 (89.23-96.14)\nhttps://www.jmir.org/2022/4/e29455 J Med Internet Res 2022 | vol. 24 | iss. 4 | e29455 | p. 11\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Tardini et al\naValues in italics indicate whether higher accuracy is achieved by including or excluding radiomics.\nbDLT: dose-limiting toxicity.\nOS rate of 88.31% (95% CI 85.32%-92.04%; training set) and\nPerformance of DQL in OS and DP\n88.06% (95% CI 83.58%-93.53%; test set). With respect to DP,\nRecall from group 4 in Table 2 that the baseline outcomes the same 2-layer model showed a +3.98% (95% CI \u20131.24% to\nobserved under physician care are 85.57% (training set) and 9.2%) improvement on training data, with 73.63% (95% CI\n84.33% (test set) OS rate of staying alive and 69.65% (training 68.41%-78.86%) of simulated patients not exhibiting DP under\nset) and 76.12% (test set; absence of) DP rate. the model\u2019s treatment decisions. This 2-layer model yielded a\n+0.75% (95% CI \u20134.48% to 6.72%) improvement on the test\nThe complete performance of all DQL models on simulated\nset, from the baseline 76.12% to 76.87% (95% CI\npatient outcomes is presented in Table S4 in Multimedia\n71.64%-82.84%).\nAppendix 1. For models trained to predict both OS and DP, the\nselected models were the ones with 2-3 hidden layers, which To assess model parsimony (ie, the minimum number of layers\noutperformed physician outcomes for OS. For predicting OS for maintaining equivalent predictive performance), Figure 5\non the test data, the best model with radiomics had the highest shows a comparison of DQL models with different numbers of\naverage predicted OS rate but had higher variance and a worse layers on simulated test data for the combined outcome models\nlower bound of 95% CI (+5.22%, 95% CI \u20132.26% to 10.45%) (OS and DP) and with and without radiomics features. Broadly,\ncompared with the best model without radiomics (+4.48%, 95% neither simpler models with <2 layers nor models with >4 layers\nCI \u20131.49% to 9.7%). For DP, models without radiomics performed as effectively as the 2-layer model. In Figure 5,\noutperformed models with radiomics in terms of both average continuous lines show the average performance of the\nand lower bounds in terms of simulated patient outcomes. bootstrapped models, whereas highlighted areas represent the\n95% CIs. Dashed lines show the empirical patient outcomes\nFor the purposes of this paper, we consider the best model to\nobserved under the physicians\u2019 decisions. Models with 1-4\nbe the 2-layer NNs without radiomic features because it had the\nlayers had the highest performance and lower variance, whereas\nbest lower bounds on predicted OS and DP for all models, while\nmodels with >4 layers overfit the data. Furthermore, models\nstill affording a good average performance. This model yielded\nwithout radiomics had better overall performance for toxicity\na median OS improvement, compared with physicians\u2019results,\noutcomes. Models with radiomics had slightly higher\nof +2.74% (95% CI \u20130.25% to 6.47%; training set) and +3.73%\nperformance for OS outcomes but had higher variance and worse\n(95% CI \u20130.75% to 8.96%; test set), with an absolute highest\nlower bounds than models trained without radiomics.\nhttps://www.jmir.org/2022/4/e29455 J Med Internet Res 2022 | vol. 24 | iss. 4 | e29455 | p. 12\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Tardini et al\nFigure 5. Model performance for the combined outcome (overall survival+dysphagia) models without (left) and with radiomics (right). The figure\nshows the performance for overall survival (top) and toxicity (dysphagia; bottom), with varying numbers of layers showing treatment simulation results\non the test data.\nCompliance With National Comprehensive Cancer\nSimilarity to Physicians\nNetwork Guidelines\nThe similar rates (with 95% CIs) with respect to physicians\u2019\nThe distributions (with 95% CIs) of the T and N stages of\ntreatment twinning, both per-decision and overall similarity,\npatients in the test set, separated by chemotherapeutic treatment\nacross all models are presented in Table S5 in Multimedia\nprescribed by the best-performing model, are presented in Table\nAppendix 1. We reiterate that the goal of DQL is not to replicate\n5.\nclinicians\u2019decisions but to find an optimal, albeit potentially\ndifferent, treatment. However, it is clearly of interest to measure The rates at which models choose a certain policy compared\nthe similarity as a reference. In terms of overall similarity of with the physicians\u2019treatment rate at each decision point are\nthe in silico Q-learning treatment policies compared with those shown in Figure 6. Gray lines represent the 95% CIs. The\nactually delivered ad hoc in vivo by physicians, our best model numbers on top of the bars show for how many patients (out of\n(OS+DP, 2 layers, and no radiomics) showed an overall 70.4% 134) the Q-learning model recommended that treatment. The\n(95% CI 65.34%-73.63%) similarity to the physician decisions IC prescription rate varies in a similar way between OS and\non the training set (ie, the model chooses the same treatment as OS+DP, CC is significantly more frequent in OS+DP models,\nthe physicians for 70.4% of the considered treatment decisions) whereas ND is consistently less frequent in OS+DP. The\nand 69.65% (95% CI 63.43%-73.38%) on the test set, although best-performing model in terms of simulated outcomes (OS+DP,\nanother model (the 3-layer OS+DP model without radiomics, 2 layers, and no radiomics) had a higher IC (D1) rate (2.99%\nwhich performed consistently worse in simulation for all increase in prescription rate compared with physicians\u2019\noutcomes) did show higher similarity rates. prescriptions for 46 patients, 95% CI \u201314.93% to 26.88%) and\none of the highest CC (D2) rates (21.64% increase, 126 patients,\n95% CI \u20132.99% to 27.61%), as well as the lowest ND (D3) rate\n(20.15% decrease, 0 patients, 95% CI \u201320.15% to \u201311.19%).\nhttps://www.jmir.org/2022/4/e29455 J Med Internet Res 2022 | vol. 24 | iss. 4 | e29455 | p. 13\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Tardini et al\nTable 5. Tumor stage demographics of patients based on the chemotherapeutic treatment decisions of the best-performing model (n=134).\nDemographics Chemotherapy No chemotherapy, no induction chemotherapy,\nradiotherapy alone (%; 95% CI)\nInduction chemotherapy No induction chemotherapy,\nconcurrent chemotherapy\n(%; 95% CI)\nConcurrent chemothera- Radiotherapy alone\npy (%; 95% CI) (%; 95% CI)\nTacategory\nT1 23.08 (0-65.38) 3.85 (0-26.92) 69.23 (26.92- 96.15) 0 (0-23.08)\nT2 25.40 (6.35-55.56) 3.17 (0-22.22) 66.67 (38.06-88.89) 0 (0-20.63)\nT3 32 (8-64.1) 4 (0-28) 60 (28-88) 0 (0-16)\nT4 36.84 (5.26-84.21) 5.26 (0-31.58) 52.63 (10.53-94.74) 0 (0-15.79)\nTxb 0 (0-100) 0 (0-100) 100 (0-100) 0 (0-100)\nNccategory\nN0d 20 (0-100) 0 (0-40) 60 (0-100) 0 (0-40)\nN1 17.39 (0-73.91) 0 (0-30.43) 73.91 (17.39-95.65) 0 (0-21.74)\nN2 29.41 (9.80-56.89) 3.92 (0-22.55) 62.75 (36.27-81.37) 0 (0-17.65)\nN3 25 (0-100) 0 (0-50) 50 (0-100) 0 (0-25)\nN category (8th editione)\nN0 16.67 (0-100) 0 (0-33.33) 66.67 (0-100) 0 (0-33.33)\nN1 22.06 (2.94-60.29) 2.94 (0-26.47) 70.59 (30.88-92.65) 0 (0-22.06)\nN2 33.93 (8.93-69.64) 3.57 (0-26.79) 58.93 (25-83.93) 0 (0-14.29)\nN3 25 (0-100) 0 (0-50) 50 (0-100) 0 (0-25)\naT: primary tumor.\nbTx: no information about the primary tumor or it cannot be measured.\ncN: lymph nodes.\ndN0: nearby lymph nodes do not contain cancer.\neAmerican Joint Committee on Cancer\u2019s Cancer Staging Manual, 8th edition.\nhttps://www.jmir.org/2022/4/e29455 J Med Internet Res 2022 | vol. 24 | iss. 4 | e29455 | p. 14\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Tardini et al\nFigure 6. Absolute increase (or decrease) of treatment decision rate compared with physicians\u2019decisions. The plots refer to decisions 1 (top), 2 (middle),\nand 3 (bottom) on the test set and for models considering only overall survival as an outcome measure (left) or overall survival+dysphagia (right) without\nradiomics. Y: yes.\ndeployed virtually in real time. Because of the computational\nComputational Cost\ncost of bootstrapping, we only used 5-fold cross-validation to\nThe training time for a single DQL model did not significantly tune the TS hyperparameters using SVCs, whereas for the other\nvary between shallower and deeper NNs and was just a few backbone hyperparameters such as the number of layers, we\nminutes on average for a complete model. With 1000-sample opted to report the performance of OS and DP under all possible\nbootstrapping, the training time was accordingly longer, costing numbers of hidden layers from 1 to 8 instead of performing\n>24 hours to generate the results shown in Figure 5. However, cross-validation.\nthese models are computationally inexpensive and can be\nhttps://www.jmir.org/2022/4/e29455 J Med Internet Res 2022 | vol. 24 | iss. 4 | e29455 | p. 15\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Tardini et al\nClinical Case Review The patient we considered in the second case study featured\ndisagreement only in the first decision. The treatment sequence\nAs there is no practical way of verifying counterfactual what-if\nprescribed by their clinician team was D1: not IC, D2: CC, and\nscenarios in actual patient care, we performed a post hoc case\nD3: not ND, whereas the DQL sequence was D1: IC, D2: CC,\nreview of selected divergence of the policy prediction from\nand D3: not ND. Upon examining the medical records, the\ndelivered care. We herein report 2 case representative studies\noncologists noted that the patient had only 1 functioning kidney;\nof patient-specific DQL treatment decisions\u2014one differed from,\ntherefore, in the first stage, the team decided to prescribe a\nwhereas the other mostly concurred with, the original decisions\nlow-dose chemotherapy regimen treatment as a precaution to\nof the treatment team of physicians\u2014with discussion and input\nprevent renal injury [32]. In their assessment, our dyad system\nfrom oncologists at the MDACC. These 2 case studies were\nperformed well, given the input specifications of this case, and\nselected by performing 1000 bootstrapped trials on the entire\nthe difference in therapy selection was attributed to occult (but\ndata set (randomly partitioning it into training and testing), then\nclinically meaningful) comorbid disease variables not included\nrecording the frequency with which the DQL prediction agreed\nin the decision platform that influenced the physicians\u2019process.\nwith the physician\u2019s (among the 1000 bootstrapped trials). We\nused the smallest geometric mean value to select the first case Overall, the physician review in both these instances that we\nstudy. The second case study was selected for high values of investigated in detail suggests that, in the absence of specific\nagreement rates in D2 and D3 but a low value of agreement local practices or occult clinical features not included in this\nrates in D1. decision platform, the DQL recommendation would have been\na good strategy and that the dyad provided \u201cclinically acceptable\nThe patient in the first case study differed in every decision:\nrecommendations.\u201d\nthe treatment sequence prescribed by their clinician team was\nD1: IC, D2: RT, and D3: ND, whereas the DQL sequence was\nDiscussion\nD1: not IC, D2: CC, and D3: not ND. During our discussion,\nupon retrieving and examining the medical records, the\nPrincipal Findings\noncologists described this case as having \u201ca very unique and\nstrange presentation\u201d with bilateral disease involving the The high average, median, and overall accuracies provided by\nretropharyngeal lymph node (RPN). As the MDACC has the TS in predicting the outcomes of treatments indicate that\nhistorically associated RPN involvement with increased the TS is a valid digital twin for the treatment process when\nmetastatic risk in published series [27,28], the patient was predicting the outcome of a treatment sequence. Our results also\nprescribed IC in D1 as part of an informal local policy for cases indicate that the Q-learning models indeed capture the nature\nwith perceived high risk of distant metastases or unsalvageable of the dynamic treatment problem and provide a valid solution.\nnodal failure (eg, retropharyngeal recurrence). The patient Our models showed consistent improvements for all the outcome\nexhibited a substantive response with respect to the response features taken into account, as well as moderate similarity to\nevaluation criteria in solid tumors, wherein the primary tumor physicians\u2019decisions. Overall, these results indicate that DQL\nvolume and index RPN had clinical complete response; modeling can serve as a digital twin of the treatment decision\ntherefore, in D2, the physicians prescribed RT alone. The patient process and TS modeling can serve as a digital twin of the\nexhibited a sizable response again, this time to the primary patient treatment. When combined, DQL and TS constitute a\ntumor. After RT, there was a notation by the radiologist of a valid patient-physician digital twin dyad for optimal policy\nnegative positron emission tomography scan (eg, no evidence determination in sequential systemic and locoregional therapy\nof metabolic uptake); however, the nodal remnant was evident of oropharyngeal squamous carcinomas.\nand \u201cmalignancy could not be excluded.\u201d Consequently, in D3,\nFurthermore, our results show that the DQL models that consider\nthe physicians prescribed, as a precaution, a completion ND on\nOS+DP outperform models considering only OS in terms of\nthe lymph node but found no cancer, only necrotic tissue. In\nsimulated survival rate. As the absence of DP (FT or AR)\nthe oncologists\u2019 assessment, the DQL sequence would\nsymptoms is positively correlated with OS, maximizing these\napproximate typical standard of care more than the delivered\nindirectly helps maximize OS-model performance as well.\ntreatment in terms of general community practice. In this case,\nthe MDACC team altered the treatment based on additional Moreover, OS+DP models show higher similarity to actual\nlocal information related to the RPN. However, in their physician decisions because they represent a finer-grained\nassessment, most other centers would not alter treatment based approximation of the decision process than models that include\non this typically not collectedinformation because RPN status only OS as an outcome, including more of the features\nis not a formal component of staging materials or risk categories considered by the physician when choosing an optimal\nfor oropharyngeal cancer [29,30] nor of AJCC staging systems treatment.\n[31], and many, if not most, practices would treat this case as\nSurprisingly, given the abundance of data on radiomics models\nconcurrent chemoradiotherapy. In summary, this was an\nfor head and neck cancer [13,33-40], Q-learning models without\nextremely unusual, unique case where additional unannotated\nradiomics yielded a better performance than models that\nlocal information made the difference between the DQL and\nincluded radiomics, in terms of simulated outcomes and\nthe prescriber\u2019s sequence. Future work that includes nodal\nvariance, for both training and testing data. The most evident\ninvolvement methodology [3,4] not currently reflected in the\nexample is given by the simulated DP: none of the models\nAJCC 8th Edition could address this type of borderline case.\ntrained with radiomics features managed to improve the outcome\nobserved after physicians\u2019treatment in the test set (Figure 5,\nhttps://www.jmir.org/2022/4/e29455 J Med Internet Res 2022 | vol. 24 | iss. 4 | e29455 | p. 16\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Tardini et al\nbottom right). From these results, the addition of textural self-referential. However, the TS is a necessary approach before\nfeatures failed to improve model performance and instead prospective application because evaluating the models based\nsignificantly increased the performance variance of the on physician similarity alone would not reflect the purpose of\nbootstrapped models. DQL. Intuitively, the goal of DQL is not to replicate the\ndecisions taken by physicians in the data set but to learn from\nOur findings also justify the choice of a deep NN model instead\nthese decisions and their effect to discern between optimal and\nof a regular linear model: whereas by using DQL we reduce\nnonoptimal choices with respect to a given outcome measure.\nmodel parsimony, we can see that the results of the linear models\n(ie, the 0\u2013hidden-layers NNs) are comparatively suboptimal to Furthermore, because we train our digital twin dyad on a\ndeeper models in terms of simulated performance, CI variance, representative cohort from a single cancer center (MDACC),\nand similarity. the physician decision or prescribing heuristics reflected may\nnot be fully generalizable to other facilities with other\nFurthermore, per Table 5, the best-performing model did not\npractitioners. However, the physician prescriptions at the\nviolate the standard of care regarding chemotherapeutic\nMDACC are aligned with the state of the art in the field. In\ntreatment of patients because all patients with stages T3-4 or\nparticular, we note that whereas 2 studies [41,42] have\nN1-3 cancer were prescribed either IC (D1) or CC (D2), with\nquestioned the relevance of IC to treatment, both studies have\nmost of them being prescribed at least CC, showing that clinical\nfailed to accrue and thus are null. Our modeling approach could\napplicability was maintained.\nconceivably be implemented and extended to generate similar\nWhen comparing OS-only models with OS+DP models, the digital twin dyads across other or multiple institutions.\nprescription rates presented in Figure 5showed 2 separate trends\nConclusions\nfor the 2 categories: whereas the IC (D1) prescription rate varied\nsimilarly for the OS and OS+DP models, the rates of CC (D2) In conclusion, we constructed a DQL modeling approach to\nand ND (D3) were significantly different between the 2 make optimized sequential treatment decisions based on a set\ncategories. In general, OS+DP models tended to have a higher of desired outcomes in head and neck cancer therapy and paired\nrate of CC (D2) and a lower rate of ND (D3). In other words, it with a simulation of the treatment process for evaluation\nmodels that also consider toxicity as an outcome measure purposes. This modeling approach represents, to our knowledge,\nbalanced a more aggressive chemotherapeutic treatment with the first application of DQL with simulation as a digital twin\na lower rate of ND, which is consistent with the known positive dyad to simultaneously represent both state-specific patient\ncorrelation between surgery and DP symptoms such as FT and data and physician or prescriber policies for head and neck\nAR. squamous carcinoma. Furthermore, this work is the first reported\nimplementation of DQL for DP and OS composite-outcome\nLimitations\nmodeling. Our approach further demonstrates the technical\nAlthough the proposed approach was shown to be effective in feasibility of such a digital twin dyad and provides a\ndynamically selecting optimal treatment strategy for patients benchmarking data set and relevant code for model\nwith oropharyngeal squamous cell carcinoma, it is not without dissemination, site-specific implementation, and iterative model\nlimitations. Because of the retrospective nature of the data set, improvement. Carrying out a prospective clinical study\nour Q-learning models had to be evaluated through the TS, a application could further confirm the validity of this approach\nsupervised learning model, which might be seen as as part of the standard of care.\nAcknowledgments\nThe authors thank all members of the Electronic Visualization Laboratory, members of the MD Anderson Head and Neck Cancer\nQuantitative Imaging Collaborative Group, and the authors\u2019collaborators at the University of Iowa and University of Minnesota.\nThis work was directly supported by the National Institutes of Health (NCI-R01-CA214825 and NCI-R01CA225190) and the\nNational Science Foundation (CNS-1625941 and CNS-1828265). Direct infrastructure support was provided for this project by\nthe multidisciplinary Stiefel Oropharyngeal Research Fund of the University of Texas MD Anderson Cancer Center Charles and\nDaneen Stiefel Center for Head and Neck Cancer, the MD Anderson Cancer Center Support Grant (P30CA016672), and the MD\nAnderson Program in Image Guided Cancer Therapy. CDF received funding and salary support unrelatedto this project during\nthe period of study execution from the National Institutes of Health ([R25EB025787-01, 1R01DE025248/R56DE025248, and\nR01DE028290], 1R01CA218148, P30CA016672, and P50 CA097007), NSF (1933369), and the Sabin Family Foundation. CDF\nhas received unrelated direct industry grant support as well as honoraria and travel funding from Elekta AB that are not relevant\nto this project.\nData Availability\nThe data set used in the data analysis is publicly available [43].\nAuthors' Contributions\nET, XZ, GC, CDF, AW, and GEM designed and developed the machine learning models and were responsible for data extraction\nand curation, statistical analysis, and interpretation. LVD, ASRM, and CDF were responsible for direct patient care provision,\nhttps://www.jmir.org/2022/4/e29455 J Med Internet Res 2022 | vol. 24 | iss. 4 | e29455 | p. 17\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Tardini et al\ndirect clinical data collection, interpretation, and analytic support. GC supervised statistical analysis, data extraction, and analytic\nsupport and is the guarantor of statistical quality. ET, XZ, AW, GC, LVD, ASRM, CDF, and GEM were responsible for manuscript\nwriting and editing. XZ, GC, CDF, and GEM, as the primary investigators, conceived, coordinated, and directed all study activities\nand were responsible for data collection, project integrity, manuscript content, editorial oversight, and correspondence. All authors\nmade substantial contributions to the conception or design of the work or the acquisition, analysis, or interpretation of data; drafted\nthe manuscript or revised it critically for important intellectual content; gave final approval of the version to be published; and\nagreed to be accountable for all aspects of the work in ensuring that questions related to the accuracy or integrity of any part of\nthe work are appropriately investigated and resolved.\nConflicts of Interest\nNone declared.\nMultimedia Appendix 1\nSupplementary Tables 1-5.\n[DOCX File , 52 KB-Multimedia Appendix 1]\nReferences\n1. Adelstein DJ, Ridge JA, Gillison ML, Chaturvedi AK, D'Souza G, Gravitt PE, et al. Head and neck squamous cell cancer\nand the human papillomavirus: summary of a National Cancer Institute State of the Science Meeting, November 9-10,\n2008, Washington, D.C. Head Neck 2009 Nov;31(11):1393-1422. [doi: 10.1002/hed.21269] [Medline: 19787782]\n2. Multidisciplinary Larynx Cancer Working Group. Conditional survival analysis of patients with locally advanced laryngeal\ncancer: construction of a dynamic risk model and clinical nomogram. Sci Rep 2017 Mar 09;7:43928 [FREE Full text] [doi:\n10.1038/srep43928] [Medline: 28276466]\n3. Luciani T, Wentzel A, Elgohari B, Elhalawani H, Mohamed A, Canahuate G, et al. A spatial neighborhood methodology\nfor computing and analyzing lymph node carcinoma similarity in precision medicine. J Biomed Inform 2020;112S:100067\n[FREE Full text] [doi: 10.1016/j.yjbinx.2020.100067] [Medline: 34417010]\n4. Wentzel A, Luciani T, van Dijk LV, Taku N, Elgohari B, Mohamed AS, Spatial-Non-spatial Multi-Dimensional Analysis\nof Radiotherapy Treatment/Toxicity Team SMART3. Precision association of lymphatic disease spread with\nradiation-associated toxicity in oropharyngeal squamous carcinomas. Radiother Oncol 2021 Aug;161:152-158. [doi:\n10.1016/j.radonc.2021.06.016] [Medline: 34126138]\n5. Marai GE, Ma C, Burks AT, Pellolio F, Canahuate G, Vock DM, et al. Precision risk analysis of cancer therapy with\ninteractive nomograms and survival plots. IEEE Trans Vis Comput Graph 2019 Apr;25(4):1732-1745 [FREE Full text]\n[doi: 10.1109/TVCG.2018.2817557] [Medline: 29994094]\n6. Fagherazzi G. Deep digital phenotyping and digital twins for precision health: time to dig deeper. J Med Internet Res 2020\nMar 03;22(3):e16770 [FREE Full text] [doi: 10.2196/16770] [Medline: 32130138]\n7. Palmer M. The potential of the digital twin as a disruptor of healthcare: perspective from medical devices. National Institute\nof Biomedical Imaging and Bioengineering Interagency Modeling and Analysis Group Digital Twin Meeting Keynote.\n2019. URL: https://www.imagwiki.nibib.nih.gov/sites/default/files/2020-01/\n2019-10-24%20Palmer_IMAG_DigitaTwinKeynote-final_1.pdf[accessed 2022-04-06]\n8. Schulte PJ, Tsiatis AA, Laber EB, Davidian M. Q- and A-learning methods for estimating optimal dynamic treatment\nregimes. Stat Sci 2014 Nov;29(4):640-661 [FREE Full text] [doi: 10.1214/13-STS450] [Medline: 25620840]\n9. Nahum-Shani I, Qian M, Almirall D, Pelham WE, Gnagy B, Fabiano GA, et al. Q-learning: a data analysis method for\nconstructing adaptive interventions. Psychol Methods 2012 Dec;17(4):478-494 [FREE Full text] [doi: 10.1037/a0029373]\n[Medline: 23025434]\n10. Moodie EE, Chakraborty B, Kramer MS. Q-learning for estimating optimal dynamic treatment rules from observational\ndata. Can J Stat 2012 Dec 01;40(4):629-645 [FREE Full text] [doi: 10.1002/cjs.11162] [Medline: 23355757]\n11. Mnih V, Kavukcuoglu K, Silver D, Rusu AA, Veness J, Bellemare MG, et al. Human-level control through deep reinforcement\nlearning. Nature 2015 Feb 26;518(7540):529-533. [doi: 10.1038/nature14236] [Medline: 25719670]\n12. Sutton RS, Barto AG. Reinforcement learning: an introduction. 2nd edition. Cambridge, MA, USA: MIT Press; 2018.\n13. M. D. Anderson Cancer Center Head and Neck Quantitative Imaging Working Group. Investigation of radiomic signatures\nfor local recurrence using primary tumor texture analysis in oropharyngeal head and neck cancer patients. Sci Rep 2018\nJan 24;8(1):1524 [FREE Full text] [doi: 10.1038/s41598-017-14687-0] [Medline: 29367653]\n14. Elhalawani H, Lin TA, Volpe S, Mohamed AS, White AL, Zafereo J, et al. Machine learning applications in head and neck\nradiation oncology: lessons from open-source radiomics challenges. Front Oncol 2018 Aug 17;8:294 [FREE Full text] [doi:\n10.3389/fonc.2018.00294] [Medline: 30175071]\n15. -. 4. Definition of volumes. J ICRU 2010 Apr;10(1):41-53. [doi: 10.1093/jicru/ndq009] [Medline: 24173326]\nhttps://www.jmir.org/2022/4/e29455 J Med Internet Res 2022 | vol. 24 | iss. 4 | e29455 | p. 18\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Tardini et al\n16. MICCAI/M.D. Anderson Cancer Center Head and Neck Quantitative Imaging Working Group. Matched computed\ntomography segmentation and demographic data for oropharyngeal cancer radiomics challenges. Sci Data 2017 Jul\n04;4:170077 [FREE Full text] [doi: 10.1038/sdata.2017.77] [Medline: 28675381]\n17. Wentzel A, Hanula P, Luciani T, Elgohari B, Elhalawani H, Canahuate G, et al. Cohort-based T-SSIM visual computing\nfor radiation therapy prediction and exploration. IEEE Trans Vis Comput Graph 2020 Jan;26(1):949-959 [FREE Full text]\n[doi: 10.1109/TVCG.2019.2934546] [Medline: 31442988]\n18. Wentzel A, Hanula P, van Dijk LV, Elgohari B, Mohamed AS, Cardenas CE, et al. Precision toxicity correlates of tumor\nspatial proximity to organs at risk in cancer patients receiving intensity-modulated radiotherapy. Radiother Oncol 2020\nJul;148:245-251 [FREE Full text] [doi: 10.1016/j.radonc.2020.05.023] [Medline: 32422303]\n19. Tosado J, Zdilar L, Elhalawani H, Elgohari B, Vock DM, Marai GE, et al. Clustering of largely right-censored oropharyngeal\nhead and neck cancer patients for discriminative groupings to improve outcome prediction. Sci Rep 2020 Mar 02;10(1):3811\n[FREE Full text] [doi: 10.1038/s41598-020-60140-0] [Medline: 32123193]\n20. Patel H, Vock DM, Marai GE, Fuller CD, Mohamed AS, Canahuate G. Oropharyngeal cancer patient stratification using\nrandom forest based-learning over high-dimensional radiomic features. Sci Rep 2021 Jul 07;11(1):14057 [FREE Full text]\n[doi: 10.1038/s41598-021-92072-8] [Medline: 34234160]\n21. Zdilar L, Vock DM, Marai GE, Fuller CD, Mohamed AS, Elhalawani H, et al. Evaluating the effect of right-censored end\npoint transformation for radiomic feature selection of data from patients with oropharyngeal cancer. JCO Clin Cancer\nInform 2018 Dec;2:1-19 [FREE Full text] [doi: 10.1200/CCI.18.00052] [Medline: 30652615]\n22. HNC-Digital-Twin. GitHub. URL: https://github.com/ElisaTardini/HNC-Digital-Twin[accessed 2022-04-12]\n23. Voloshin C, Le HM, Jiang N, Yue Y. Empirical study of off-policy policy evaluation for reinforcement learning. arXiv\n(forthcoming) 2019.\n24. Gottesman O, Johansson F, Meier J, Dent J, Lee D, Srinivasan S, et al. Evaluating reinforcement learning algorithms in\nobservational health settings. arXiv (forthcoming) 2018.\n25. Yauney G, Shah P. Evaluating reinforcement learning algorithms in observational health settings. In: Proceedings of the\n3rd Machine Learning for Healthcare Conference. 2018 Presented at: MLHC '18; August 16-18, 2018; Stanford, CA, USA\np. 1-49.\n26. Pfister DG, Spencer S, Adelstein D, Adkins D, Anzai Y, Brizel DM, et al. Head and neck cancers, version 2.2020, NCCN\nclinical practice guidelines in oncology. J Natl Compr Canc Netw 2020 Jul;18(7):873-898. [doi: 10.6004/jnccn.2020.0031]\n[Medline: 32634781]\n27. Lin TA, Garden AS, Elhalawani H, Elgohari B, Jethanandani A, Ng SP, et al. Radiographic retropharyngeal lymph node\ninvolvement in HPV-associated oropharyngeal carcinoma: patterns of involvement and impact on patient outcomes. Cancer\n2019 May 01;125(9):1536-1546 [FREE Full text] [doi: 10.1002/cncr.31944] [Medline: 30620385]\n28. Gunn GB, Debnam JM, Fuller CD, Morrison WH, Frank SJ, Beadle BM, et al. The impact of radiographic retropharyngeal\nadenopathy in oropharyngeal cancer. Cancer 2013 Sep 01;119(17):3162-3169 [FREE Full text] [doi: 10.1002/cncr.28195]\n[Medline: 23733178]\n29. Fakhry C, Zhang Q, Gillison ML, Nguyen-T\u00e2n PF, Rosenthal DI, Weber RS, et al. Validation of NRG oncology/RTOG-0129\nrisk groups for HPV-positive and HPV-negative oropharyngeal squamous cell cancer: Implications for risk-based therapeutic\nintensity trials. Cancer 2019 Jun 15;125(12):2027-2038 [FREE Full text] [doi: 10.1002/cncr.32025] [Medline: 30913305]\n30. Ang KK, Harris J, Wheeler R, Weber R, Rosenthal DI, Nguyen-T\u00e2n PF, et al. Human papillomavirus and survival of patients\nwith oropharyngeal cancer. N Engl J Med 2010 Jul 01;363(1):24-35 [FREE Full text] [doi: 10.1056/NEJMoa0912217]\n[Medline: 20530316]\n31. Machczy\u0144ski P, Majchrzak E, Niewinski P, Marchlewska J, Golusi\u0144ski W. A review of the 8th edition of the AJCC staging\nsystem for oropharyngeal cancer according to HPV status. Eur Arch Otorhinolaryngol 2020 Sep;277(9):2407-2412 [FREE\nFull text] [doi: 10.1007/s00405-020-05979-9] [Medline: 32342197]\n32. Hoek J, Bloemendal KM, van der Velden LA, van Diessen JN, van Werkhoven E, Klop WM, et al. Nephrotoxicity as a\ndose-limiting factor in a high-dose cisplatin-based chemoradiotherapy regimen for head and neck carcinomas. Cancers\n(Basel) 2016 Feb 16;8(2):21 [FREE Full text] [doi: 10.3390/cancers8020021] [Medline: 26891330]\n33. Wong AJ, Kanwar A, Mohamed AS, Fuller CD. Radiomics in head and neck cancer: from exploration to application. Transl\nCancer Res 2016 Aug;5(4):371-382 [FREE Full text] [doi: 10.21037/tcr.2016.07.18] [Medline: 30627523]\n34. Bogowicz M, Leijenaar RT, Tanadini-Lang S, Riesterer O, Pruschy M, Studer G, et al. Post-radiochemotherapy PET\nradiomics in head and neck cancer - the influence of radiomics implementation on the reproducibility of local control tumor\nmodels. Radiother Oncol 2017 Dec;125(3):385-391. [doi: 10.1016/j.radonc.2017.10.023] [Medline: 29122358]\n35. Valli\u00e8res M, Kay-Rivest E, Perrin LJ, Liem X, Furstoss C, Aerts HJ, et al. Radiomics strategies for risk assessment of\ntumour failure in head-and-neck cancer. Sci Rep 2017 Aug 31;7(1):10117 [FREE Full text] [doi:\n10.1038/s41598-017-10371-5] [Medline: 28860628]\n36. Parmar C, Leijenaar RT, Grossmann P, Rios Velazquez E, Bussink J, Rietveld D, et al. Sci Rep 2015 Jun 05;5:11044 [FREE\nFull text] [doi: 10.1038/srep11044] [Medline: 26251068]\nhttps://www.jmir.org/2022/4/e29455 J Med Internet Res 2022 | vol. 24 | iss. 4 | e29455 | p. 19\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Tardini et al\n37. Parmar C, Grossmann P, Rietveld D, Rietbergen MM, Lambin P, Aerts HJ. Radiomic machine-learning classifiers for\nprognostic biomarkers of head and neck cancer. Front Oncol 2015;5:272 [FREE Full text] [doi: 10.3389/fonc.2015.00272]\n[Medline: 26697407]\n38. Jethanandani A, Lin TA, Volpe S, Elhalawani H, Mohamed AS, Yang P, et al. Exploring applications of radiomics in\nmagnetic resonance imaging of head and neck cancer: a systematic review. Front Oncol 2018;8:131 [FREE Full text] [doi:\n10.3389/fonc.2018.00131] [Medline: 29868465]\n39. van Dijk LV, Langendijk JA, Zhai TT, Vedelaar TA, Noordzij W, Steenbakkers RJ, et al. Delta-radiomics features during\nradiotherapy improve the prediction of late xerostomia. Sci Rep 2019 Aug 28;9(1):12483 [FREE Full text] [doi:\n10.1038/s41598-019-48184-3] [Medline: 31462719]\n40. van Dijk LV, Thor M, Steenbakkers RJ, Apte A, Zhai TT, Borra R, et al. Parotid gland fat related Magnetic Resonance\nimage biomarkers improve prediction of late radiation-induced xerostomia. Radiother Oncol 2018 Sep;128(3):459-466\n[FREE Full text] [doi: 10.1016/j.radonc.2018.06.012] [Medline: 29958772]\n41. Haddad R, O'Neill A, Rabinowits G, Tishler R, Khuri F, Adkins D, et al. Induction chemotherapy followed by concurrent\nchemoradiotherapy (sequential chemoradiotherapy) versus concurrent chemoradiotherapy alone in locally advanced head\nand neck cancer (PARADIGM): a randomised phase 3 trial. Lancet Oncol 2013 Mar;14(3):257-264. [doi:\n10.1016/S1470-2045(13)70011-1] [Medline: 23414589]\n42. Cohen EE, Karrison TG, Kocherginsky M, Mueller J, Egan R, Huang CH, et al. Phase III randomized trial of induction\nchemotherapy in patients with N2 or N3 locally advanced head and neck cancer. J Clin Oncol 2014 Sep 01;32(25):2735-2743\n[FREE Full text] [doi: 10.1200/JCO.2013.54.6309] [Medline: 25049329]\n43. Tardini E, Zhang X, Canahuate G, Wentzel A, Mohamed A, van Dijk L, et al. Data deposition for \"Optimal policy\ndetermination in sequential systemic and locoregional therapy of oropharyngeal squamous carcinomas: a patient-physician\ndigital twin dyad with deep Q-learning\". figshare. 2020. URL: https://doi.org/10.6084/m9.figshare.13235453.v2[accessed\n2022-04-06]\nAbbreviations\nAJCC: American Joint Committee on Cancer\nAR: aspiration rate\nCC: concurrent chemotherapy\nDP: dysphagia\nDQL: deep Q-learning\nFT: feeding-tube dependence\nIC: induction chemotherapy\nMDACC: MD Anderson Cancer Center\nMDP: Markov decision process\nND: neck dissection\nNN: neural network\nOS: overall survival\nRL: reinforcement learning\nRPN: retropharyngeal lymph node\nRT: radiotherapy\nSVC: support vector classifier\nTS: treatment simulator\nEdited by G Eysenbach; submitted 07.04.21; peer-reviewed by G Lim, S Kim, S You; comments to author 09.07.21; revised version\nreceived 03.09.21; accepted 09.02.22; published 20.04.22\nPlease cite as:\nTardini E, Zhang X, Canahuate G, Wentzel A, Mohamed ASR, Van Dijk L, Fuller CD, Marai GE\nOptimal Treatment Selection in Sequential Systemic and Locoregional Therapy of Oropharyngeal Squamous Carcinomas: Deep\nQ-Learning With a Patient-Physician Digital Twin Dyad\nJ Med Internet Res 2022;24(4):e29455\nURL: https://www.jmir.org/2022/4/e29455\ndoi: 10.2196/29455\nPMID:\nhttps://www.jmir.org/2022/4/e29455 J Med Internet Res 2022 | vol. 24 | iss. 4 | e29455 | p. 20\nXSL FO (page number not for citation purposes)\n\u2022\nRenderXJOURNAL OF MEDICAL INTERNET RESEARCH Tardini et al\n\u00a9Elisa Tardini, Xinhua Zhang, Guadalupe Canahuate, Andrew Wentzel, Abdallah S R Mohamed, Lisanne Van Dijk, Clifton D\nFuller, G Elisabeta Marai. Originally published in the Journal of Medical Internet Research (https://www.jmir.org), 20.04.2022.\nThis is an open-access article distributed under the terms of the Creative Commons Attribution License\n(https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium,\nprovided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic\ninformation, a link to the original publication on https://www.jmir.org/, as well as this copyright and license information must\nbe included.\nhttps://www.jmir.org/2022/4/e29455 J Med Internet Res 2022 | vol. 24 | iss. 4 | e29455 | p. 21\nXSL FO (page number not for citation purposes)\n\u2022\nRenderX"
}